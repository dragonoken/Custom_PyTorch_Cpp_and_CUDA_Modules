{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peephole LSTM Test & Performance Comparison (Speed & Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imports](#Importing-necessary-modules)\n",
    "* [Load & Definition](#Loading-and-defining-modules)\n",
    "    * [Autograd Functions](#Autograd-Functions)\n",
    "    * [Module Classes](#Module-classes-(C++,-CUDA,-PyTorch))\n",
    "* [Models](#Defining-models)\n",
    "    * [Definition](#Definition)\n",
    "    * [Instantiation](#Instantiation)\n",
    "    * [Parameter Synchronization](#Parameter-Synchronization)\n",
    "* [Fake Dataset](#Creating-a-fake-dataset)\n",
    "* [Sanity Check](#Sanity-check:-output-comparison)\n",
    "    * [Forward Outputs](#Forward-Outputs)\n",
    "    * [Backward Gradients](#Backward-Gradients)\n",
    "* [Forward Performance](#Forward-time-comparison)\n",
    "* [+Backward Performance](#+Backward-time-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing necessary modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.034957Z",
     "start_time": "2019-02-05T06:09:31.028946Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#imports"
    ]
   },
   "outputs": [],
   "source": [
    "if 'initialized' not in globals():\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils.cpp_extension import load\n",
    "    from torch.nn import functional as F\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    import math\n",
    "    from collections import OrderedDict\n",
    "    from time import sleep\n",
    "\n",
    "    initialized = [False] * 7\n",
    "    print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and defining modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Autograd Functions\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.059913Z",
     "start_time": "2019-02-05T06:09:31.037915Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "=>imports",
     "#C-autograd-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[0]:\n",
    "    _ln_peephole_lstm_layer_cpp = load('ln_peephole_lstm_layer', ['./ln_peephole_lstm_layer.cpp'])\n",
    "    _ln_peephole_lstm_layer_cuda = load('ln_peephole_lstm_layer_cuda', ['./ln_peephole_lstm_layer_cuda.cpp', './ln_peephole_lstm_layer_cuda_kernel.cu'])\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMFunctionCPP(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMFunctionCUDA(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    initialized[0] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Module classes (PyTorch, C++, CUDA)\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.114917Z",
     "start_time": "2019-02-05T06:09:31.062912Z"
    },
    "code_folding": [
     1,
     112,
     139,
     155,
     170,
     203,
     219,
     234
    ],
    "hidden": true,
    "tags": [
     "#base-modules-define",
     "=>C-autograd-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[1]:\n",
    "    class LNPeepholeLSTMTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "            super(LNPeepholeLSTMTorch, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, states):\n",
    "            assert input.dim() == 3, \"expected a 3 dimensional tensor as `input`, but te given tensor has {} dimension(s)\".format(input.dim())\n",
    "            assert len(states) == 2, \"expected a (hidden, cell) pair as `states`, but the length of the given states is {}\".format(len(states))\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "            assert states[0].size() == (input.size(1), self.hidden_size), \"expected a hidden state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[0].size()), [input.size(1), self.hidden_size])\n",
    "            assert states[1].size() == (input.size(1), self.hidden_size), \"expected a cell state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[1].size()), [input.size(1), self.hidden_size])\n",
    "\n",
    "            hidden, cell = states\n",
    "\n",
    "            hidden_size = self.hidden_size\n",
    "            hidden_size_2 = 2 * hidden_size\n",
    "            hidden_size_3 = hidden_size_2 + hidden_size\n",
    "\n",
    "            norm_shape = torch.Size((hidden_size,))\n",
    "\n",
    "            outputs = input.new_empty((input.size(0), input.size(1), hidden_size))\n",
    "            \n",
    "            ih = input.matmul(self.weight_ih.t())\n",
    "\n",
    "            weight_hc_h = torch.cat((self.weight_hh.t(),\n",
    "                                     torch.cat((self.weight_ch[:hidden_size].diag(),\n",
    "                                                self.weight_ch[hidden_size:hidden_size_2].diag(),\n",
    "                                                self.weight_ch.new_zeros(hidden_size_2, hidden_size))).t()))\n",
    "            weight_co = self.weight_ch[hidden_size_2:]\n",
    "            \n",
    "            gamma_fig = torch.stack((self.gamma_f, self.gamma_i, self.gamma_g))\n",
    "\n",
    "            bias_fig = torch.stack(self.bias[:hidden_size_3].chunk(3, dim=0))\n",
    "            bias_o = self.bias[hidden_size_3:]\n",
    "\n",
    "            for i in range(input.size(0)):\n",
    "                gates = torch.addmm(ih[i], torch.cat((hidden, cell), dim=1), weight_hc_h).view(-1, 4, hidden_size)\n",
    "                gates_fig = gates[:, :3]\n",
    "\n",
    "\n",
    "                gates_fig = F.layer_norm(gates_fig, norm_shape, eps=self.eps)\n",
    "                gates_fig = torch.addcmul(bias_fig, gates_fig, gamma_fig)\n",
    "                forget_input_gates = gates_fig[:, :2].sigmoid()\n",
    "                candidate_cell = F.dropout(gates_fig[:, 2].tanh(), p=self.dropout, training=self.training)\n",
    "\n",
    "\n",
    "                cell = F.layer_norm(torch.addcmul(forget_input_gates[:, 0] * cell,\n",
    "                                                  forget_input_gates[:, 1], candidate_cell),\n",
    "                                    norm_shape, self.gamma_cell, self.beta_cell, self.eps)\n",
    "\n",
    "                output_gate = torch.addcmul(gates[:, 3], cell, weight_co)\n",
    "\n",
    "                output_gate = F.layer_norm(output_gate, norm_shape, self.gamma_o, bias_o, self.eps).sigmoid()\n",
    "\n",
    "                hidden = output_gate * cell.tanh()\n",
    "\n",
    "                outputs[i] = hidden\n",
    "\n",
    "            if self.dropout_on_output:\n",
    "                outputs = F.dropout(outputs, p=self.dropout, training=self.training)\n",
    "                \n",
    "            if self.batch_first:\n",
    "                outputs = outputs.transpose(0, 1).contiguous()\n",
    "\n",
    "            return outputs, (hidden, cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMTorch(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCPP, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCPP.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCPP(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCUDA, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCUDA.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCUDA(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    initialized[1] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Definition\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.146918Z",
     "start_time": "2019-02-05T06:09:31.119915Z"
    },
    "code_folding": [
     1,
     35,
     69
    ],
    "hidden": true,
    "tags": [
     "#models-define",
     "=>base-modules-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[2]:\n",
    "    class LNPeepholeTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMTorch(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMTorch(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCPP(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCPP(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCUDA(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCUDA(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    initialized[2] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.158915Z",
     "start_time": "2019-02-05T06:09:31.152915Z"
    },
    "code_folding": [],
    "tags": [
     "=>models-define",
     "#models-init"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[3]:\n",
    "    device = ('cpu', 'cuda')[1]\n",
    "\n",
    "    input_size = 5 #TEST 5\n",
    "    hidden_size = 8 #TEST 8\n",
    "    output_size = 6 #TEST 6\n",
    "    n_layers = 3 #TEST 3\n",
    "    dropout = 0. #TEST 0\n",
    "    eps = 1e-05 #TEST 1e-05\n",
    "\n",
    "    model_torch = LNPeepholeTorch(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cpp = LNPeepholeCPP(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cuda = LNPeepholeCUDA(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "\n",
    "    model_torch.to(device)\n",
    "    model_cpp.to(device)\n",
    "    model_cuda.to(device)\n",
    "\n",
    "    models = (model_torch, model_cpp, model_cuda)\n",
    "    \n",
    "    initialized[3] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Parameter Synchronization\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.172916Z",
     "start_time": "2019-02-05T06:09:31.161919Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#param-sync",
     "=>models-init"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[4]:\n",
    "    named_parameter_dicts = [\n",
    "        dict(model_torch.named_parameters()),\n",
    "        dict(model_cpp.named_parameters()),\n",
    "        dict(model_cuda.named_parameters())\n",
    "    ]\n",
    "\n",
    "    print(\"Synchronized Parameters:\\n\")\n",
    "    for common_param_name in set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(common_param_name))\n",
    "        for i in range(1, len(named_parameter_dicts)):\n",
    "            if named_parameter_dicts[i][common_param_name].size() == named_parameter_dicts[0][common_param_name].size():\n",
    "                named_parameter_dicts[i][common_param_name].data = named_parameter_dicts[0][common_param_name].data\n",
    "            else:\n",
    "                raise RuntimeError(\"Size mismatch\\n0:{}\\n{i}:{}\".format(named_parameter_dicts[0][common_param_name].size(),\n",
    "                                                                        named_parameter_dicts[i][common_param_name].size()))\n",
    "    print()\n",
    "    print(\"Exclusive Parameters (Not Synchronized):\\n\")\n",
    "    for exclusive_param_name in set.union(*(set(npd.keys()) for npd in named_parameter_dicts)) - set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(exclusive_param_name))\n",
    "        \n",
    "    initialized[4] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating a fake dataset\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.182913Z",
     "start_time": "2019-02-05T06:09:31.176914Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "tags": [
     "#fake-generator",
     "=>param-sync"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[5]:\n",
    "    def create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True):\n",
    "        fake_inputs = torch.randn(dataset_size, sequence_length, input_size)\n",
    "        fake_targets = torch.randint(high=output_size, size=(dataset_size, sequence_length), dtype=torch.int64)\n",
    "\n",
    "        fake_dataset = TensorDataset(fake_inputs, fake_targets)\n",
    "\n",
    "        fake_loader = DataLoader(fake_dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "\n",
    "        return fake_loader\n",
    "    \n",
    "    initialized[5] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:31.192918Z",
     "start_time": "2019-02-05T06:09:31.185912Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#generate-fake",
     "=>fake-generator"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[6]:\n",
    "    dataset_size = 1000\n",
    "    sequence_length = 1 #TEST 20\n",
    "    batch_size = 2 #TEST 8\n",
    "\n",
    "    fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size)\n",
    "    print(next(iter(fake_loader))[0].size(), next(iter(fake_loader))[1].size())\n",
    "    \n",
    "    initialized[6] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: output comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Outputs\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:08:41.902041Z",
     "start_time": "2019-02-05T06:08:41.896039Z"
    },
    "scrolled": true,
    "tags": [
     "#forward-test-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))\n",
    "\n",
    "inputs = next(iter(fake_loader))[0].to(device)\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "del model # Removing temporary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:08:42.435085Z",
     "start_time": "2019-02-05T06:08:41.909038Z"
    },
    "scrolled": true,
    "tags": [
     "#forward-test-1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_torch]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]]],\n",
      "       device='cuda:0'), (tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_torch]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out0 = model_torch(inputs, hidden)\n",
    "    print(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:08:42.776082Z",
     "start_time": "2019-02-05T06:08:42.439082Z"
    },
    "scrolled": true,
    "tags": [
     "#forward-test-2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_cpp]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]]],\n",
      "       device='cuda:0'), (tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cpp]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out1 = model_cpp(inputs, hidden)\n",
    "    print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:08.842695Z",
     "start_time": "2019-02-05T06:09:08.532430Z"
    },
    "tags": [
     "#forward-test-3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out1[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:10.909157Z",
     "start_time": "2019-02-05T06:09:10.691156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_cuda]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]],\n",
      "\n",
      "        [[ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354],\n",
      "         [ 0.1514,  0.1963,  0.0375, -0.2102, -0.1708,  0.3354]]],\n",
      "       device='cuda:0'), (tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cuda]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out2 = model_cuda(inputs, hidden)\n",
    "    print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:22.101790Z",
     "start_time": "2019-02-05T06:09:22.095793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out2[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Gradients\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:32.142925Z",
     "start_time": "2019-02-05T06:09:31.196918Z"
    },
    "scrolled": false,
    "tags": [
     "#backward-test",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8271, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True), torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True))\n",
    "\n",
    "inputs, targets = next(iter(fake_loader))\n",
    "inputs = inputs.to(device)\n",
    "inputs.requires_grad_()\n",
    "targets = targets.to(device)\n",
    "\n",
    "inputs_grads = []\n",
    "hidden_grads = []\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "    model.zero_grad()\n",
    "    loss = criterion(model(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    inputs_grads.append(inputs.grad.clone())\n",
    "    inputs.grad.zero_()\n",
    "    hidden_grads.append((hidden[0].grad.clone(), hidden[1].grad.clone()))\n",
    "    hidden[0].grad.zero_()\n",
    "    hidden[1].grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:33.435281Z",
     "start_time": "2019-02-05T06:09:33.391280Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_torch\n",
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0')\n",
      "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'))\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"model_torch\")\n",
    "print(inputs_grads[0])\n",
    "print(hidden_grads[0])\n",
    "print(model_torch.lstm0.bias.grad)\n",
    "print(model_torch.lstm0.gamma_cell.grad)\n",
    "# print(model_torch.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:35.303214Z",
     "start_time": "2019-02-05T06:09:35.246244Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_cpp\n",
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0')\n",
      "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'))\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"model_cpp\")\n",
    "print(inputs_grads[1])\n",
    "print(hidden_grads[1])\n",
    "print(model_cpp.lstm0.bias.grad)\n",
    "print(model_cpp.lstm0.gamma_cell.grad)\n",
    "# print(model_cpp.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:09:36.171278Z",
     "start_time": "2019-02-05T06:09:36.164258Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cpp.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:06:29.530833Z",
     "start_time": "2019-02-05T06:06:29.347833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_cuda\n",
      "tensor([[[-1.3435e+02, -9.0758e+01,  1.3010e+02, -1.8043e+02, -1.9627e+01],\n",
      "         [ 6.4094e+02,  5.5853e+02, -1.1977e+03,  5.2183e+02, -1.3062e+03],\n",
      "         [ 9.3651e-01, -8.1176e-01,  1.0687e+01,  1.0211e+01,  1.3905e+01],\n",
      "         [ 1.9260e+01,  8.2067e+00,  2.1972e+01,  1.5270e+01,  4.9144e+01],\n",
      "         [ 1.0636e+02,  2.7505e+02, -5.2485e+01,  3.3555e+02,  7.8988e+01],\n",
      "         [ 7.6807e-01,  7.9251e-01, -1.4541e+00,  7.8489e-01,  4.9668e-01],\n",
      "         [-6.6669e-03,  6.2959e+00, -1.2747e-01,  3.4855e+00,  1.3992e+00],\n",
      "         [ 8.1981e+00,  6.3188e+00, -4.6396e+00,  3.2698e+00,  1.7502e+00],\n",
      "         [-3.1055e+00, -1.2235e+00,  1.0010e+00, -4.7862e-01, -1.6232e+00],\n",
      "         [-6.2164e+00, -1.6698e+00,  2.6211e+00, -6.9631e+00, -2.7720e+00],\n",
      "         [ 4.7447e-01,  1.6326e+00, -3.8679e+00, -4.5445e-01, -9.3133e-01],\n",
      "         [-8.3681e-01,  2.8994e-01, -1.3113e+00, -6.1282e-01, -2.1818e+00],\n",
      "         [-1.7802e+00, -5.5835e+00,  1.6702e+00, -4.2400e+00, -9.6119e-01],\n",
      "         [ 2.2189e+00,  1.6617e+00, -1.6960e+00,  1.7961e+00, -1.5068e-01],\n",
      "         [-2.4235e-01, -1.4179e-01, -4.7191e-02, -2.6064e-01, -2.8330e-01],\n",
      "         [-2.7176e-01, -6.4580e-02, -8.4336e-02, -2.3937e-01, -4.3333e-01],\n",
      "         [ 1.1105e-02,  3.4525e-02, -5.3953e-02, -7.2024e-03,  4.6980e-02],\n",
      "         [-1.4729e-02, -3.7239e-03,  1.2943e-02,  9.2181e-04, -5.3657e-03],\n",
      "         [-3.3692e-02, -2.1446e-02,  2.1427e-02, -1.7101e-02, -1.3916e-02],\n",
      "         [-1.4874e-03,  2.2599e-02, -1.7637e-02, -2.1662e-03, -1.1279e-02]],\n",
      "\n",
      "        [[ 3.1571e-01,  4.4111e-02, -1.1911e-01,  2.7518e-01, -1.3248e-01],\n",
      "         [-3.1732e-01,  2.6097e-01,  4.9295e-01,  1.0188e-01,  1.6901e-01],\n",
      "         [ 4.0284e-01,  1.3367e+00, -7.1156e-01,  1.8327e+00, -4.2827e-01],\n",
      "         [-1.9071e-01,  1.4245e-02, -8.3648e-02, -2.9048e-01, -3.7700e-01],\n",
      "         [-1.2473e-01, -3.1855e-01,  1.2091e-02, -2.8719e-01, -2.7508e-01],\n",
      "         [-3.6703e-02, -1.3864e-01,  7.8796e-01,  1.8444e-01,  4.5698e-01],\n",
      "         [ 3.6634e-02, -4.1468e-02,  9.0352e-02,  2.2078e-02,  7.4218e-02],\n",
      "         [-1.8082e-02,  6.5642e-02, -5.0753e-02, -6.5507e-03, -3.3040e-02],\n",
      "         [-1.9000e-03,  2.5848e-04, -1.3467e-03, -4.9424e-03,  1.0751e-02],\n",
      "         [-1.6794e-03, -1.4824e-02,  1.3086e-02, -3.3688e-02,  6.1126e-03],\n",
      "         [-1.5516e-02,  2.1121e-02, -6.5592e-03,  2.7688e-03, -2.1783e-02],\n",
      "         [-1.0592e-02, -6.3117e-03,  3.0495e-03, -8.6428e-03, -1.1763e-02],\n",
      "         [-8.5122e-03, -1.4208e-02,  3.5467e-02, -1.8686e-02,  8.2320e-03],\n",
      "         [-5.9650e-03, -1.1025e-02, -1.0317e-02, -1.2176e-02, -1.3166e-02],\n",
      "         [ 2.0483e-02,  1.5013e-02,  4.7706e-03,  3.2374e-02,  4.7532e-02],\n",
      "         [-1.4257e-02,  6.3165e-03,  1.7519e-02,  5.2023e-03,  1.0211e-02],\n",
      "         [-7.8867e-03, -7.3149e-04, -3.1497e-03, -3.4385e-03, -1.5233e-02],\n",
      "         [-2.2693e-02, -9.5709e-03,  2.8577e-02,  1.4614e-03,  2.5394e-02],\n",
      "         [-1.0268e-03, -4.5459e-04, -3.4528e-03, -2.8013e-03, -4.3068e-03],\n",
      "         [-5.6598e-04, -3.7836e-04, -3.8242e-04, -5.9371e-04, -7.0149e-04]],\n",
      "\n",
      "        [[-3.0871e+01,  5.5121e+01,  6.8551e+00,  1.7077e+01,  3.8072e+00],\n",
      "         [ 2.4714e+00,  3.0797e-01, -2.3515e+00, -8.5248e-01,  1.9049e+00],\n",
      "         [-2.3579e+00, -2.3653e+00,  2.9261e+00, -1.2296e+00, -1.3352e+00],\n",
      "         [-3.0073e+00,  2.2010e+00, -3.7935e+00, -4.5955e+00, -3.1579e+00],\n",
      "         [ 1.3068e-01, -1.6234e-01,  1.0677e-02,  1.2737e-02, -1.7790e-01],\n",
      "         [-2.9517e-02, -8.6926e-02, -1.0156e-01,  9.3240e-04, -7.5972e-02],\n",
      "         [ 6.5187e-01, -7.0115e-02, -4.3306e-01,  5.3073e-01,  7.2984e-01],\n",
      "         [ 5.4358e-02, -2.1045e-02,  3.1466e-02,  3.9894e-02,  5.2145e-02],\n",
      "         [ 2.0309e-02,  7.5832e-03, -3.1135e-02,  7.9890e-04, -8.3829e-03],\n",
      "         [-4.0320e-02, -1.9956e-02,  2.6361e-02, -2.7692e-02, -8.4874e-03],\n",
      "         [ 2.0090e-02, -1.5515e-03,  4.0355e-02,  3.8915e-02,  5.7656e-02],\n",
      "         [ 7.2943e-05,  1.6056e-02,  1.7201e-02,  1.0218e-02,  5.1338e-02],\n",
      "         [-2.0150e-02, -3.0787e-03,  3.7947e-02,  4.8039e-03,  7.5795e-03],\n",
      "         [ 1.0995e-02, -3.5068e-03,  2.1344e-02,  2.2999e-02,  3.7200e-02],\n",
      "         [ 1.6805e-03,  1.2747e-03,  1.2759e-02,  6.7798e-03,  6.3723e-03],\n",
      "         [-2.3166e-02, -3.4518e-02,  4.1847e-02,  6.3282e-03,  1.8645e-02],\n",
      "         [ 1.7176e-02,  2.0448e-02, -4.6330e-03,  2.0742e-02,  1.9893e-02],\n",
      "         [ 9.1326e-03,  6.3841e-03,  2.4210e-04,  1.1173e-02,  1.4383e-02],\n",
      "         [-6.8540e-02, -6.5511e-02,  4.6369e-02, -9.9836e-02,  1.9567e-02],\n",
      "         [ 2.0485e-03,  1.2980e-03,  8.1171e-04,  3.0193e-03,  4.8640e-03]],\n",
      "\n",
      "        [[ 3.2865e-02, -5.8512e-02, -3.1551e-02,  1.9934e-03,  3.4480e-02],\n",
      "         [-4.8775e-02,  2.9201e-02,  2.7626e-03,  1.2672e-02,  2.8029e-02],\n",
      "         [-2.9547e-02,  4.9928e-03,  1.4491e-02, -2.4913e-02,  6.7318e-03],\n",
      "         [ 6.0876e-02,  7.0090e-01,  1.1534e-01,  6.0950e-01,  5.0660e-01],\n",
      "         [-9.5090e-01,  1.2395e-01,  8.1705e-01,  3.3117e-01,  2.6098e-02],\n",
      "         [-1.6652e-01, -1.1225e-01,  1.5572e-01, -9.3976e-02, -9.6583e-02],\n",
      "         [-5.8900e-02,  5.2732e-02, -1.1783e-01, -1.7222e-02, -1.4180e-01],\n",
      "         [ 2.0470e-02, -1.1884e-01,  1.1477e-03, -2.0046e-02,  1.9006e-02],\n",
      "         [-1.4059e-01, -1.2323e-01, -7.7128e-02, -2.2507e-01, -2.6011e-01],\n",
      "         [ 2.1936e-01,  4.0567e-02, -1.5702e-01,  6.5409e-03,  1.9383e-02],\n",
      "         [-3.1102e-01, -1.7603e-01,  2.1748e-01, -1.3272e-01, -1.2924e-01],\n",
      "         [-2.1768e-02, -2.2034e-02,  5.1236e-02,  4.4054e-03, -8.8836e-03],\n",
      "         [ 2.8961e-03,  8.7755e-03, -2.2413e-02, -2.1137e-02,  1.4247e-03],\n",
      "         [-4.4589e-02, -1.0697e-02,  1.0657e-01,  2.4352e-02,  2.2289e-02],\n",
      "         [-2.2060e-03, -3.7393e-04,  3.0500e-03, -2.7879e-03, -2.2776e-04],\n",
      "         [-1.0666e-03, -3.6373e-04, -8.0662e-04, -4.5306e-04, -1.5292e-03],\n",
      "         [ 1.8842e-04, -1.7379e-03, -5.0861e-03, -2.4623e-04, -5.9536e-03],\n",
      "         [-5.0880e-04, -8.2615e-04,  3.0526e-03,  3.3754e-04,  1.4291e-03],\n",
      "         [-1.7610e-03, -8.9381e-04,  6.5911e-04, -2.7765e-04,  3.4294e-04],\n",
      "         [ 1.3678e-03, -6.0534e-04,  8.3873e-04,  1.3625e-03,  2.0698e-03]],\n",
      "\n",
      "        [[-4.9154e-01, -3.8766e-01,  1.0075e-01, -5.4739e-01, -8.8968e-01],\n",
      "         [-2.0645e-01, -4.0053e-01, -8.3295e-01, -1.0677e-01, -6.4199e-01],\n",
      "         [ 1.6584e+00,  6.4286e-01, -6.9084e-01,  2.6966e-01,  1.4149e+00],\n",
      "         [-1.0820e+00, -1.0367e+00,  9.2464e-01, -8.2736e-01, -1.9216e-01],\n",
      "         [ 7.9776e-01,  8.3019e-01, -5.5199e-01,  3.1871e-01,  1.7333e-03],\n",
      "         [-9.8439e-01, -9.6168e-01,  7.6575e-01, -1.5577e-02,  1.0927e-01],\n",
      "         [-2.4138e-02,  1.4954e-03, -2.0842e-02, -2.3081e-02, -4.5035e-02],\n",
      "         [ 4.4426e-03,  6.0502e-03,  4.0822e-03,  6.8190e-03,  8.7777e-03],\n",
      "         [ 1.0641e-02,  6.1794e-03, -2.0095e-03,  6.3420e-03,  5.8338e-03],\n",
      "         [ 8.3630e-04,  6.4857e-04, -5.7616e-03, -2.3541e-03, -4.6303e-03],\n",
      "         [ 1.6435e-03,  1.5062e-03, -1.9291e-03,  1.7652e-03, -2.0006e-03],\n",
      "         [-1.8816e-02, -1.1103e-02, -1.2150e-02, -1.9227e-02, -2.7571e-02],\n",
      "         [ 1.4480e-02,  8.2050e-03, -6.6940e-03,  8.9119e-03,  5.9695e-03],\n",
      "         [-4.0041e-02, -1.4341e-02,  2.1083e-02, -7.5868e-03, -9.6845e-03],\n",
      "         [ 6.2313e-02,  3.0634e-02, -4.9252e-02,  2.0897e-02,  1.2729e-02],\n",
      "         [-3.5821e-03, -1.0679e-03,  7.7972e-04, -1.9052e-03, -2.2804e-03],\n",
      "         [ 6.3081e-03, -2.3296e-03, -3.9893e-03, -6.3211e-04,  8.3991e-04],\n",
      "         [-1.0315e-02, -9.5746e-03,  4.2207e-03, -1.1063e-02, -3.3609e-04],\n",
      "         [ 4.0740e-04,  1.0981e-04,  2.2246e-05,  2.7888e-04,  3.6087e-04],\n",
      "         [-1.7801e-04, -4.9460e-05, -7.3092e-05, -1.8421e-04, -2.8123e-04]],\n",
      "\n",
      "        [[-3.0645e-01,  2.1699e+00, -5.2351e-01, -9.1679e-01, -1.3326e+00],\n",
      "         [ 1.4177e-02,  1.0324e-02, -1.9145e-02, -5.9879e-03,  3.5099e-03],\n",
      "         [ 1.1628e-02,  8.5478e-03, -9.2475e-03,  1.1202e-03, -8.0328e-04],\n",
      "         [-1.8475e-03, -1.2984e-03, -2.8530e-03, -1.0962e-02,  3.7556e-03],\n",
      "         [-8.7848e-03,  4.2031e-03, -1.8102e-03, -2.4658e-03, -7.4527e-03],\n",
      "         [-1.7206e-02, -4.3365e-03,  1.2675e-02, -1.4280e-03, -5.4342e-04],\n",
      "         [ 1.9155e-02, -2.4431e-03, -5.7060e-02, -1.4264e-02, -4.0817e-02],\n",
      "         [-5.0561e-02, -1.4252e-02,  3.1496e-03, -3.9797e-02, -3.5764e-02],\n",
      "         [-4.0406e-02, -4.4969e-02, -7.3907e-03, -5.0782e-02, -4.6009e-02],\n",
      "         [-7.9291e-02, -6.2643e-02,  5.2592e-02, -3.8867e-02,  4.5961e-02],\n",
      "         [ 3.0251e-03,  1.3188e-03, -9.6392e-03, -1.1081e-03, -2.0233e-03],\n",
      "         [ 2.7352e-02,  1.0032e-02, -1.4881e-02, -2.9847e-04, -1.2291e-02],\n",
      "         [-6.1278e-03,  3.8766e-02, -2.5453e-02,  9.3164e-03, -1.1466e-02],\n",
      "         [-4.2434e-03,  2.2860e-03, -1.8055e-04, -1.0100e-02, -1.3039e-02],\n",
      "         [-2.1954e-02, -1.9245e-02,  3.8225e-02, -1.0371e-02,  2.4794e-02],\n",
      "         [ 3.6246e-02,  6.3831e-02, -4.3503e-02,  1.1386e-01, -5.9671e-02],\n",
      "         [ 1.5680e-02, -8.9163e-03, -1.0020e-02,  6.5033e-03,  8.3759e-03],\n",
      "         [-1.0970e-02,  2.4968e-03, -1.0510e-02, -9.0018e-03, -1.9449e-02],\n",
      "         [ 1.8452e-02, -1.0736e-02, -2.6323e-02, -1.5162e-02, -6.7364e-03],\n",
      "         [ 1.2683e-08,  7.9134e-08,  1.0464e-07,  1.6211e-07,  1.8911e-07]],\n",
      "\n",
      "        [[-6.3019e-01,  8.9136e-01,  7.1141e-02,  1.9167e-02, -2.3483e-01],\n",
      "         [ 6.4831e-01, -2.6755e+00,  1.4292e+00,  7.3069e-02,  9.1231e-01],\n",
      "         [ 1.7353e+00,  1.0088e+00, -8.1115e-02,  1.5169e+00,  3.8703e-01],\n",
      "         [-8.0304e-01,  8.7662e-01, -6.0130e-02, -4.8654e-01, -1.0282e+00],\n",
      "         [-1.1058e+00, -1.0131e+00,  1.9498e+00, -1.8933e+00,  2.7047e+00],\n",
      "         [-6.2123e-02, -3.7757e-02, -1.6577e-01, -1.4190e-01, -3.2617e-01],\n",
      "         [-3.7664e-01, -2.4874e-01, -1.6581e-01, -1.0220e-01, -5.0918e-01],\n",
      "         [-6.3415e-01,  3.8827e-01, -6.3773e-01, -1.4028e-01, -5.3428e-01],\n",
      "         [ 3.1899e-01,  5.6897e-02, -9.3913e-02,  9.1507e-02,  1.4974e-01],\n",
      "         [-2.2543e-01, -1.6690e-02, -7.1514e-02, -7.0574e-02, -4.5327e-01],\n",
      "         [ 2.1753e-01,  4.8791e-02, -3.8843e-01, -7.5426e-02, -1.3907e-01],\n",
      "         [ 7.6472e-03,  6.4586e-03, -9.2146e-03,  5.0207e-03,  5.9447e-03],\n",
      "         [-4.6821e-02, -9.5229e-03,  1.2285e-02,  2.3826e-02, -1.8922e-02],\n",
      "         [-8.4831e-03, -1.6304e-02, -2.9349e-02,  3.8555e-02,  2.0421e-01],\n",
      "         [ 5.3880e-02,  1.8803e-02, -3.9227e-02,  4.1336e-03, -8.7446e-03],\n",
      "         [ 2.7072e-02,  5.6978e-02,  2.3447e-02,  4.4182e-02,  9.2353e-02],\n",
      "         [-4.4116e-02, -3.3145e-03,  5.8900e-02, -9.0107e-03,  9.4201e-02],\n",
      "         [ 1.0239e-03,  1.4432e-03,  1.1974e-03,  2.1420e-03,  1.4193e-03],\n",
      "         [ 1.1903e-03,  4.9906e-04,  1.3246e-04,  1.1738e-03,  1.4859e-03],\n",
      "         [-2.4229e-07, -4.4742e-07,  4.2152e-07,  1.8574e-07,  1.8317e-07]],\n",
      "\n",
      "        [[-1.2984e-02, -1.5670e-02,  9.9145e-03, -1.6749e-02, -4.8682e-02],\n",
      "         [-1.6282e-02, -6.1180e-03,  1.9296e-02,  2.9363e-03,  6.8472e-03],\n",
      "         [-8.8213e-03,  1.9298e-02,  7.8794e-02,  4.6760e-02,  4.8036e-02],\n",
      "         [ 1.9003e-03,  3.9506e-03, -5.1081e-03,  4.0172e-04, -1.8885e-03],\n",
      "         [-7.4064e-03, -2.4391e-03,  2.6504e-03, -4.7581e-03,  1.0844e-03],\n",
      "         [ 1.1906e-02,  2.0512e-03, -4.5812e-03, -1.4255e-02,  1.4206e-02],\n",
      "         [-3.0267e-03, -3.7745e-03, -2.5502e-03, -7.7258e-03, -9.6359e-03],\n",
      "         [-2.0362e-04,  5.8486e-04,  2.4565e-04,  6.8394e-04,  1.2375e-03],\n",
      "         [ 2.4493e-03, -4.4293e-03, -1.0754e-03,  2.7264e-03,  9.1696e-03],\n",
      "         [ 8.7099e-03,  3.6856e-03,  4.7273e-03,  4.9434e-03,  1.1068e-02],\n",
      "         [-1.5568e-02, -1.3082e-02,  1.8837e-02, -2.4482e-03,  8.8116e-03],\n",
      "         [ 1.8640e-02,  3.2127e-02, -5.6531e-02,  1.5735e-02, -7.3809e-02],\n",
      "         [-6.9779e-04,  2.1689e-04,  9.1682e-03, -3.5624e-03,  1.8484e-02],\n",
      "         [ 3.2368e-03,  2.3725e-03, -2.0538e-03,  3.5995e-03,  2.3541e-04],\n",
      "         [-1.0576e-02, -8.5321e-03,  7.0017e-03, -7.4372e-03, -6.4753e-03],\n",
      "         [ 9.2236e-03,  8.6539e-03, -1.3175e-03,  1.1144e-02,  1.2179e-02],\n",
      "         [ 2.5817e-03,  1.3928e-03,  1.6863e-03,  5.4142e-03,  4.8353e-03],\n",
      "         [-4.1644e-03, -4.0774e-03,  2.9064e-03, -4.4018e-03, -3.7660e-03],\n",
      "         [ 1.4290e-03,  8.4581e-04, -1.8783e-03,  3.0736e-05,  5.6669e-04],\n",
      "         [ 2.8347e-08,  1.6338e-08, -3.6770e-08, -1.4941e-08, -6.2226e-08]]],\n",
      "       device='cuda:0')\n",
      "(tensor([[[ 1.9760e+02,  7.4943e+01,  2.1206e+02, -2.9756e+02, -4.8763e+01,\n",
      "          -2.6574e+01, -2.3525e+01, -7.0305e+01],\n",
      "         [-3.6102e-01, -9.7199e-02, -1.5918e-01,  5.9213e-01, -3.4652e-02,\n",
      "           1.2984e-01,  7.5848e-02, -1.1253e-01],\n",
      "         [-9.7694e+00, -2.7638e+01, -9.1618e-01,  5.5242e-01, -8.5372e+00,\n",
      "          -6.2141e+00, -4.1529e+01,  2.3043e+00],\n",
      "         [ 8.7350e-03, -6.3691e-03, -4.3891e-02,  3.7378e-02,  8.2931e-03,\n",
      "          -4.7945e-03,  5.3897e-02,  3.0412e-02],\n",
      "         [-1.8632e-01, -2.9127e-01,  1.9983e-01, -5.9680e-01, -3.6889e-01,\n",
      "           5.5635e-01, -6.3678e-02, -3.9210e-01],\n",
      "         [-5.1433e-01, -2.9143e-01,  1.1682e+00, -2.9252e-01,  4.1971e-01,\n",
      "          -5.7392e-01, -2.9817e-01,  1.3693e+00],\n",
      "         [-1.7478e-01, -3.4252e-01,  9.7080e-02, -4.0680e-01,  6.8468e-03,\n",
      "          -8.8043e-03, -6.8509e-01,  1.7034e-01],\n",
      "         [-1.7822e-02, -1.7424e-02,  1.7040e-02, -5.0363e-03, -2.8083e-02,\n",
      "           3.0046e-02, -3.9254e-03, -3.5786e-02]],\n",
      "\n",
      "        [[ 8.5339e+01, -2.6449e+01, -5.7116e+01, -5.9988e+02,  4.0958e+00,\n",
      "           1.6690e+02, -3.3250e+02, -2.0805e+02],\n",
      "         [ 5.4656e-01, -3.1601e+00, -4.1090e+00, -1.5450e+00,  3.6659e+00,\n",
      "          -2.3292e+00, -7.9099e-01,  1.9471e+00],\n",
      "         [ 1.6770e+02, -6.3349e+01, -2.6984e+02, -1.0386e+02,  2.7555e+02,\n",
      "          -1.5621e+02, -5.9031e+01, -2.6151e+01],\n",
      "         [ 1.6270e-01, -5.9244e-02, -1.5570e-01, -2.5006e-01,  1.0828e-01,\n",
      "          -5.3773e-02, -1.3652e-01, -1.2207e-01],\n",
      "         [-5.6126e-01,  1.2764e+00,  1.3306e+00,  9.7064e-02, -1.1449e+00,\n",
      "           3.2178e-01,  1.1578e+00, -5.0417e-01],\n",
      "         [ 2.1043e+00, -1.4715e+00, -4.9620e+00,  5.1881e-01,  5.0106e+00,\n",
      "          -4.1729e+00, -1.8122e-01,  1.1970e+00],\n",
      "         [-9.9072e+00, -6.8334e+00,  1.1973e+00,  1.0817e+01, -1.4332e+00,\n",
      "          -2.2398e+00,  3.3796e+00,  1.3531e+01],\n",
      "         [-2.5156e-01, -2.8524e-01, -2.8996e-01,  1.4458e-01,  2.2010e-01,\n",
      "          -4.4829e-01,  3.6836e-01,  4.4816e-01]],\n",
      "\n",
      "        [[ 6.0292e+01,  3.6296e+00,  1.7972e+01,  8.4214e+01, -3.1569e+01,\n",
      "          -3.9157e+01, -2.4082e+01,  2.8617e+01],\n",
      "         [ 2.2819e-01,  7.9542e-02, -7.0050e-02,  2.9554e-01, -2.2296e-01,\n",
      "           2.2088e-01,  1.2147e-01,  2.8062e-01],\n",
      "         [-1.3070e+01,  8.0209e+00, -1.0295e+01, -2.3671e+01, -1.0905e+00,\n",
      "           1.8584e+01,  6.5637e+00,  7.4004e+00],\n",
      "         [-7.9692e-03,  6.1636e-03, -2.1415e-03, -1.8445e-02, -1.5831e-03,\n",
      "           4.1014e-03, -1.3088e-02, -1.6217e-03],\n",
      "         [ 5.8224e-02,  2.3791e-01, -1.4697e-01, -1.6214e-01, -1.7385e-01,\n",
      "           4.7360e-01, -1.4559e-02,  5.5018e-02],\n",
      "         [-4.1385e-01, -1.6799e-01, -1.2263e-01, -5.2289e-01,  2.3829e-01,\n",
      "           4.7662e-01,  2.0626e-01, -2.5999e-01],\n",
      "         [-6.8345e-01,  3.7300e-01, -4.6424e-02, -1.3551e+00,  1.7478e-01,\n",
      "           2.2035e+00,  1.3723e+00,  3.6088e-01],\n",
      "         [-1.2042e-02, -1.4729e-02, -1.7629e-02, -9.3922e-03,  5.6280e-03,\n",
      "           5.7841e-02,  3.3603e-02, -6.9808e-03]]], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'))\n",
      "tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   1.1288, -10.2912, -11.1282, 177.6075,\n",
      "        -40.1252,  26.7488,   5.3151, -22.4914], device='cuda:0')\n",
      "tensor([-145.3430,  547.4063,  161.9053, -549.7189,  100.3175,   54.3009,\n",
      "         143.7099, -161.7525], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"model_cuda\")\n",
    "print(inputs_grads[2])\n",
    "print(hidden_grads[2])\n",
    "print(model_cuda.lstm0.bias.grad)\n",
    "print(model_cuda.lstm0.gamma_cell.grad)\n",
    "# print(model_cuda.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:06:34.495022Z",
     "start_time": "2019-02-05T06:06:34.485022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35781.4258, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cuda.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:09:13.911079Z",
     "start_time": "2019-02-04T07:09:13.903075Z"
    },
    "tags": [
     "#forward-time-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_size = 1000\n",
    "sequence_length = 20\n",
    "batch_size = 32\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "del model\n",
    "\n",
    "fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True)\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:10:30.393818Z",
     "start_time": "2019-02-04T07:09:14.261824Z"
    },
    "tags": [
     "#forward-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.81 s ± 177 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_torch(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:12:21.618816Z",
     "start_time": "2019-02-04T07:10:30.556852Z"
    },
    "scrolled": true,
    "tags": [
     "#forward-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.55 s ± 66.8 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cpp(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:12:48.934522Z",
     "start_time": "2019-02-04T07:12:21.621819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.37 s ± 54.1 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cuda(inputs, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +Backward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:12:49.099563Z",
     "start_time": "2019-02-04T07:12:49.083522Z"
    },
    "tags": [
     "#overall-time-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'executed'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\"executed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:17:49.012291Z",
     "start_time": "2019-02-04T07:12:49.244525Z"
    },
    "tags": [
     "#overall-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3 s ± 367 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_torch.zero_grad()\n",
    "    criterion(model_torch(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:21:18.454664Z",
     "start_time": "2019-02-04T07:17:49.223253Z"
    },
    "tags": [
     "#overall-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.94 s ± 307 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cpp.zero_grad()\n",
    "    criterion(model_cpp(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T07:23:22.777546Z",
     "start_time": "2019-02-04T07:21:18.456664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.92 s ± 207 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cuda.zero_grad()\n",
    "    criterion(model_cuda(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 807,
   "position": {
    "height": "548px",
    "left": "1116px",
    "right": "20px",
    "top": "99px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
