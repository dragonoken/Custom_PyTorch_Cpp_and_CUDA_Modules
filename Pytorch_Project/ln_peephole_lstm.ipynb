{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peephole LSTM Test & Performance Comparison (Speed & Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imports](#Importing-necessary-modules)\n",
    "* [Load & Definition](#Loading-and-defining-modules)\n",
    "    * [Autograd Functions](#Autograd-Functions)\n",
    "    * [Module Classes](#Module-classes-(C++,-CUDA,-PyTorch))\n",
    "* [Models](#Defining-models)\n",
    "    * [Definition](#Definition)\n",
    "    * [Instantiation](#Instantiation)\n",
    "    * [Parameter Synchronization](#Parameter-Synchronization)\n",
    "* [Fake Dataset](#Creating-a-fake-dataset)\n",
    "* [Sanity Check](#Sanity-check:-output-comparison)\n",
    "    * [Forward Outputs](#Forward-Outputs)\n",
    "    * [Backward Gradients](#Backward-Gradients)\n",
    "* [Forward Performance](#Forward-time-comparison)\n",
    "* [+Backward Performance](#+Backward-time-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing necessary modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:12.392075Z",
     "start_time": "2019-02-09T23:27:11.081543Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#imports"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "if 'initialized' not in globals():\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils.cpp_extension import load\n",
    "    from torch.nn import functional as F\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    import math\n",
    "    from collections import OrderedDict\n",
    "    from time import sleep\n",
    "\n",
    "    initialized = [False] * 7\n",
    "    print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and defining modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Autograd Functions\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:13.785114Z",
     "start_time": "2019-02-09T23:27:12.396072Z"
    },
    "code_folding": [
     10,
     49,
     88
    ],
    "hidden": true,
    "scrolled": true,
    "tags": [
     "=>imports",
     "#C-autograd-define"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\utils\\cpp_extension.py:184: UserWarning: Error checking compiler version for c++: Command 'c++' returned non-zero exit status 1.\n",
      "  warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n"
     ]
    }
   ],
   "source": [
    "if not initialized[0]:\n",
    "    _ln_peephole_lstm_layer_cpp = load('ln_peephole_lstm_layer',\n",
    "                                       ['./ln_peephole_lstm_layer.cpp'])\n",
    "    _ln_peephole_lstm_layer_cuda = load('ln_peephole_lstm_layer_cuda',\n",
    "                                        ['./ln_peephole_lstm_layer_cuda.cpp', './ln_peephole_lstm_layer_cuda_kernel.cu'])\n",
    "    _ln_peephole_lstm_layer_cuda_less_mem = load('ln_peephole_lstm_layer_cuda_less_mem',\n",
    "                                                 ['./ln_peephole_lstm_layer_cuda_less_mem.cpp', './ln_peephole_lstm_layer_cuda_kernel_less_mem.cu'])\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMFunctionCPP(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMFunctionCUDA(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMFunctionCUDALM(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cuda_less_mem.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch, bias,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cuda_less_mem.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    initialized[0] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Module classes (PyTorch, C++, CUDA)\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:13.856101Z",
     "start_time": "2019-02-09T23:27:13.786105Z"
    },
    "code_folding": [
     1,
     111,
     112,
     139,
     155,
     170,
     175,
     176,
     203,
     219,
     234,
     239,
     267,
     283,
     298
    ],
    "hidden": true,
    "tags": [
     "#base-modules-define",
     "=>C-autograd-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[1]:\n",
    "    class LNPeepholeLSTMTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "            super(LNPeepholeLSTMTorch, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, states):\n",
    "            assert input.dim() == 3, \"expected a 3 dimensional tensor as `input`, but te given tensor has {} dimension(s)\".format(input.dim())\n",
    "            assert len(states) == 2, \"expected a (hidden, cell) pair as `states`, but the length of the given states is {}\".format(len(states))\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "            assert states[0].size() == (input.size(1), self.hidden_size), \"expected a hidden state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[0].size()), [input.size(1), self.hidden_size])\n",
    "            assert states[1].size() == (input.size(1), self.hidden_size), \"expected a cell state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[1].size()), [input.size(1), self.hidden_size])\n",
    "\n",
    "            hidden, cell = states\n",
    "\n",
    "            hidden_size = self.hidden_size\n",
    "            hidden_size_2 = 2 * hidden_size\n",
    "            hidden_size_3 = hidden_size_2 + hidden_size\n",
    "\n",
    "            norm_shape = torch.Size((hidden_size,))\n",
    "\n",
    "            outputs = input.new_empty((input.size(0), input.size(1), hidden_size))\n",
    "            \n",
    "            ih = input.matmul(self.weight_ih.t())\n",
    "\n",
    "            weight_hc_h = torch.cat((self.weight_hh.t(),\n",
    "                                     torch.cat((self.weight_ch[:hidden_size].diag(),\n",
    "                                                self.weight_ch[hidden_size:hidden_size_2].diag(),\n",
    "                                                self.weight_ch.new_zeros(hidden_size_2, hidden_size))).t()))\n",
    "            weight_co = self.weight_ch[hidden_size_2:]\n",
    "            \n",
    "            gamma_fig = torch.stack((self.gamma_f, self.gamma_i, self.gamma_g))\n",
    "\n",
    "            bias_fig = torch.stack(self.bias[:hidden_size_3].chunk(3, dim=0))\n",
    "            bias_o = self.bias[hidden_size_3:]\n",
    "\n",
    "            for i in range(input.size(0)):\n",
    "                gates = torch.addmm(ih[i], torch.cat((hidden, cell), dim=1), weight_hc_h).view(-1, 4, hidden_size)\n",
    "                gates_fig = gates[:, :3]\n",
    "\n",
    "\n",
    "                gates_fig = F.layer_norm(gates_fig, norm_shape, eps=self.eps)\n",
    "                gates_fig = torch.addcmul(bias_fig, gates_fig, gamma_fig)\n",
    "                forget_input_gates = gates_fig[:, :2].sigmoid()\n",
    "                candidate_cell = F.dropout(gates_fig[:, 2].tanh(), p=self.dropout, training=self.training)\n",
    "\n",
    "\n",
    "                cell = F.layer_norm(torch.addcmul(forget_input_gates[:, 0] * cell,\n",
    "                                                  forget_input_gates[:, 1], candidate_cell),\n",
    "                                    norm_shape, self.gamma_cell, self.beta_cell, self.eps)\n",
    "\n",
    "                output_gate = torch.addcmul(gates[:, 3], cell, weight_co)\n",
    "\n",
    "                output_gate = F.layer_norm(output_gate, norm_shape, self.gamma_o, bias_o, self.eps).sigmoid()\n",
    "\n",
    "                hidden = output_gate * cell.tanh()\n",
    "\n",
    "                outputs[i] = hidden\n",
    "\n",
    "            if self.dropout_on_output:\n",
    "                outputs = F.dropout(outputs, p=self.dropout, training=self.training)\n",
    "                \n",
    "            if self.batch_first:\n",
    "                outputs = outputs.transpose(0, 1).contiguous()\n",
    "\n",
    "            return outputs, (hidden, cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMTorch(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCPP, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCPP.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCPP(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCUDA, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCUDA.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCUDA(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMCUDALM(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCUDALM, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCUDALM.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCUDALM(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    initialized[1] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Definition\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:13.893080Z",
     "start_time": "2019-02-09T23:27:13.861066Z"
    },
    "code_folding": [
     1,
     35,
     69,
     103,
     104,
     119
    ],
    "hidden": true,
    "tags": [
     "#models-define",
     "=>base-modules-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[2]:\n",
    "    class LNPeepholeTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMTorch(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMTorch(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCPP(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCPP(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCUDA(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCUDA(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeCUDALM(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCUDALM(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCUDALM(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    initialized[2] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Instantiation\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:16.072064Z",
     "start_time": "2019-02-09T23:27:13.898068Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "=>models-define",
     "#models-init"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[3]:\n",
    "    device = ('cpu', 'cuda')[1]\n",
    "\n",
    "    input_size = 5 #TEST 5\n",
    "    hidden_size = 8 #TEST 8\n",
    "    output_size = 6 #TEST 6\n",
    "    n_layers = 3 #TEST 3\n",
    "    dropout = 0. #TEST 0\n",
    "    eps = 1e-05 #TEST 1e-05\n",
    "\n",
    "    model_torch = LNPeepholeTorch(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cpp = LNPeepholeCPP(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cuda = LNPeepholeCUDA(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cuda_less_mem = LNPeepholeCUDALM(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "\n",
    "    model_torch.to(device)\n",
    "    model_cpp.to(device)\n",
    "    model_cuda.to(device)\n",
    "    model_cuda_less_mem.to(device)\n",
    "\n",
    "    models = (model_torch, model_cpp, model_cuda, model_cuda_less_mem)\n",
    "    \n",
    "    initialized[3] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Parameter Synchronization\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:16.088079Z",
     "start_time": "2019-02-09T23:27:16.074066Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#param-sync",
     "=>models-init"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronized Parameters:\n",
      "\n",
      "\tlstm1.gamma_o\n",
      "\tlstm2.weight_ch\n",
      "\tlstm1.gamma_cell\n",
      "\tlstm0.weight_ch\n",
      "\tlstm0.weight_ih\n",
      "\tlstm0.bias\n",
      "\tlstm0.gamma_i\n",
      "\tlstm2.bias\n",
      "\tlstm2.beta_cell\n",
      "\tlstm0.gamma_o\n",
      "\tlstm2.gamma_f\n",
      "\tlstm2.gamma_i\n",
      "\tlstm0.gamma_g\n",
      "\tlstm1.beta_cell\n",
      "\tlstm2.gamma_o\n",
      "\tfc.weight\n",
      "\tlstm0.beta_cell\n",
      "\tlstm2.weight_hh\n",
      "\tlstm0.gamma_cell\n",
      "\tlstm1.bias\n",
      "\tlstm1.gamma_g\n",
      "\tlstm2.gamma_cell\n",
      "\tlstm1.weight_hh\n",
      "\tlstm1.weight_ch\n",
      "\tlstm2.gamma_g\n",
      "\tfc.bias\n",
      "\tlstm1.gamma_i\n",
      "\tlstm1.weight_ih\n",
      "\tlstm0.weight_hh\n",
      "\tlstm2.weight_ih\n",
      "\tlstm0.gamma_f\n",
      "\tlstm1.gamma_f\n",
      "\n",
      "Exclusive Parameters (Not Synchronized):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not initialized[4]:\n",
    "    named_parameter_dicts = [\n",
    "        dict(model_torch.named_parameters()),\n",
    "        dict(model_cpp.named_parameters()),\n",
    "        dict(model_cuda.named_parameters()),\n",
    "        dict(model_cuda_less_mem.named_parameters())\n",
    "    ]\n",
    "\n",
    "    print(\"Synchronized Parameters:\\n\")\n",
    "    for common_param_name in set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(common_param_name))\n",
    "        for i in range(1, len(named_parameter_dicts)):\n",
    "            if named_parameter_dicts[i][common_param_name].size() == named_parameter_dicts[0][common_param_name].size():\n",
    "                named_parameter_dicts[i][common_param_name].data = named_parameter_dicts[0][common_param_name].data\n",
    "            else:\n",
    "                raise RuntimeError(\"Size mismatch\\n0:{}\\n{i}:{}\".format(named_parameter_dicts[0][common_param_name].size(),\n",
    "                                                                        named_parameter_dicts[i][common_param_name].size()))\n",
    "    print()\n",
    "    print(\"Exclusive Parameters (Not Synchronized):\\n\")\n",
    "    for exclusive_param_name in set.union(*(set(npd.keys()) for npd in named_parameter_dicts)) - set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(exclusive_param_name))\n",
    "        \n",
    "    initialized[4] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating a fake dataset\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:16.098066Z",
     "start_time": "2019-02-09T23:27:16.091066Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#fake-generator",
     "=>param-sync"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[5]:\n",
    "    def create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True):\n",
    "        fake_inputs = torch.randn(dataset_size, sequence_length, input_size)\n",
    "        fake_targets = torch.randint(high=output_size, size=(dataset_size, sequence_length), dtype=torch.int64)\n",
    "\n",
    "        fake_dataset = TensorDataset(fake_inputs, fake_targets)\n",
    "\n",
    "        fake_loader = DataLoader(fake_dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "\n",
    "        return fake_loader\n",
    "    \n",
    "    initialized[5] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:16.112076Z",
     "start_time": "2019-02-09T23:27:16.100071Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#generate-fake",
     "=>fake-generator"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 20, 5]) torch.Size([8, 20])\n"
     ]
    }
   ],
   "source": [
    "if not initialized[6]:\n",
    "    dataset_size = 1000\n",
    "    sequence_length = 20 #TEST 20\n",
    "    batch_size = 8 #TEST 8\n",
    "\n",
    "    fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size)\n",
    "    print(next(iter(fake_loader))[0].size(), next(iter(fake_loader))[1].size())\n",
    "    \n",
    "    initialized[6] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: output comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Forward Outputs\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:23.956207Z",
     "start_time": "2019-02-09T20:35:23.948212Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))\n",
    "\n",
    "inputs = next(iter(fake_loader))[0].to(device)\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "del model # Removing temporary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:10:02.634593Z",
     "start_time": "2019-02-09T06:10:02.324588Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_cuda(inputs, hidden)\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:10:02.705587Z",
     "start_time": "2019-02-09T06:10:02.641585Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_cuda_less_mem(inputs, hidden)\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:24.581204Z",
     "start_time": "2019-02-09T20:35:23.958205Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-1"
    ]
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_torch]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out0 = model_torch(inputs, hidden)\n",
    "    print(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:25.040204Z",
     "start_time": "2019-02-09T20:35:24.583205Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-2"
    ]
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cpp]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out1 = model_cpp(inputs, hidden)\n",
    "    print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:25.053204Z",
     "start_time": "2019-02-09T20:35:25.042214Z"
    },
    "hidden": true,
    "tags": [
     "#forward-test-3"
    ]
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out1[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:25.385203Z",
     "start_time": "2019-02-09T20:35:25.056209Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cuda]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out2 = model_cuda(inputs, hidden)\n",
    "    print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:25.397207Z",
     "start_time": "2019-02-09T20:35:25.387207Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out2[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:25.716204Z",
     "start_time": "2019-02-09T20:35:25.400205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cuda_less_mem]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out3 = model_cuda_less_mem(inputs, hidden)\n",
    "    print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:35:25.726234Z",
     "start_time": "2019-02-09T20:35:25.717206Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out3[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Backward Gradients\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T22:48:14.791531Z",
     "start_time": "2019-02-09T22:48:14.271495Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#backward-test",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True), torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True))\n",
    "\n",
    "inputs, targets = next(iter(fake_loader))\n",
    "inputs = inputs.to(device)\n",
    "inputs.requires_grad_()\n",
    "targets = targets.to(device)\n",
    "\n",
    "inputs_grads = []\n",
    "hidden_grads = []\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "    model.zero_grad()\n",
    "    loss = criterion(model(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    inputs_grads.append(inputs.grad.clone())\n",
    "    inputs.grad.zero_()\n",
    "    hidden_grads.append((hidden[0].grad.clone(), hidden[1].grad.clone()))\n",
    "    hidden[0].grad.zero_()\n",
    "    hidden[1].grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T22:33:46.173906Z",
     "start_time": "2019-02-09T22:33:45.557899Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    loss = criterion(model_cuda(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss, end='\\n\\n')\n",
    "    loss.backward()\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T22:33:46.206902Z",
     "start_time": "2019-02-09T22:33:46.175902Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    loss = criterion(model_cuda_less_mem(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss, end='\\n\\n')\n",
    "    loss.backward()\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:38:34.212287Z",
     "start_time": "2019-02-09T20:38:33.964292Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"model_torch\")\n",
    "print(inputs_grads[0])\n",
    "print(hidden_grads[0])\n",
    "print(model_torch.lstm0.bias.grad)\n",
    "print(model_torch.lstm0.gamma_cell.grad)\n",
    "# print(model_torch.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:38:34.796218Z",
     "start_time": "2019-02-09T20:38:34.560211Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"model_cpp\")\n",
    "print(inputs_grads[1])\n",
    "print(hidden_grads[1])\n",
    "print(model_cpp.lstm0.bias.grad)\n",
    "print(model_cpp.lstm0.gamma_cell.grad)\n",
    "# print(model_cpp.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T22:48:14.803544Z",
     "start_time": "2019-02-09T22:48:14.792492Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.1734e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cpp.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:38:36.322331Z",
     "start_time": "2019-02-09T20:38:36.079358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"model_cuda\")\n",
    "print(inputs_grads[2])\n",
    "print(hidden_grads[2])\n",
    "print(model_cuda.lstm0.bias.grad)\n",
    "print(model_cuda.lstm0.gamma_cell.grad)\n",
    "# print(model_cuda.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T22:48:14.814595Z",
     "start_time": "2019-02-09T22:48:14.805545Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3895e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cuda.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T20:38:38.517386Z",
     "start_time": "2019-02-09T20:38:38.306386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"model_cuda_less_mem\")\n",
    "print(inputs_grads[3])\n",
    "print(hidden_grads[3])\n",
    "print(model_cuda_less_mem.lstm0.bias.grad)\n",
    "print(model_cuda_less_mem.lstm0.gamma_cell.grad)\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T22:48:14.825606Z",
     "start_time": "2019-02-09T22:48:14.816539Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1477e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cuda_less_mem.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:16.122069Z",
     "start_time": "2019-02-09T23:27:16.115066Z"
    },
    "tags": [
     "#forward-time-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_size = 1000 #Test 1000\n",
    "sequence_length = 20 #Test 20\n",
    "batch_size = 32 #Test 32\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "del model\n",
    "\n",
    "fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True)\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T22:59:16.799762Z",
     "start_time": "2019-02-09T22:57:21.081808Z"
    },
    "tags": [
     "#forward-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.86 s ± 241 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 30\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_torch(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:02:03.975631Z",
     "start_time": "2019-02-09T22:59:17.001763Z"
    },
    "scrolled": true,
    "tags": [
     "#forward-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.57 s ± 122 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 30\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cpp(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:02:44.246688Z",
     "start_time": "2019-02-09T23:02:03.978602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34 s ± 47.8 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 30\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cuda(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:03:25.013662Z",
     "start_time": "2019-02-09T23:02:44.248702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36 s ± 55.2 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 30\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cuda_less_mem(inputs, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +Backward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:27:16.133067Z",
     "start_time": "2019-02-09T23:27:16.124094Z"
    },
    "tags": [
     "=>forward-time-prep",
     "#overall-time-prep"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'executed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\"executed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:10:58.989176Z",
     "start_time": "2019-02-09T23:03:25.458673Z"
    },
    "tags": [
     "#overall-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.6 s ± 272 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 30\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_torch.zero_grad()\n",
    "    criterion(model_torch(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:16:31.587177Z",
     "start_time": "2019-02-09T23:10:59.172175Z"
    },
    "tags": [
     "#overall-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.7 s ± 226 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 30\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cpp.zero_grad()\n",
    "    criterion(model_cpp(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:29:58.012065Z",
     "start_time": "2019-02-09T23:28:37.143066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61 s ± 43.7 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 30\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cuda.zero_grad()\n",
    "    criterion(model_cuda(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T23:28:37.138067Z",
     "start_time": "2019-02-09T23:27:16.135066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6 s ± 29.5 ms per loop (mean ± std. dev. of 30 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 30\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cuda_less_mem.zero_grad()\n",
    "    criterion(model_cuda_less_mem(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 807,
   "position": {
    "height": "548px",
    "left": "1116px",
    "right": "20px",
    "top": "99px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
