{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peephole LSTM Test & Performance Comparison (Speed & Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imports](#Importing-necessary-modules)\n",
    "* [Load & Definition](#Loading-and-defining-modules)\n",
    "    * [Autograd Functions](#Autograd-Functions)\n",
    "    * [Module Classes](#Module-classes-(C++,-CUDA,-PyTorch))\n",
    "* [Models](#Defining-models)\n",
    "    * [Definition](#Definition)\n",
    "    * [Instantiation](#Instantiation)\n",
    "    * [Parameter Synchronization](#Parameter-Synchronization)\n",
    "* [Fake Dataset](#Creating-a-fake-dataset)\n",
    "* [Sanity Check](#Sanity-check:-output-comparison)\n",
    "    * [Forward Outputs](#Forward-Outputs)\n",
    "    * [Backward Gradients](#Backward-Gradients)\n",
    "* [Forward Performance](#Forward-time-comparison)\n",
    "* [+Backward Performance](#+Backward-time-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing necessary modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.398524Z",
     "start_time": "2019-02-09T06:41:15.394524Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#imports"
    ]
   },
   "outputs": [],
   "source": [
    "if 'initialized' not in globals():\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils.cpp_extension import load\n",
    "    from torch.nn import functional as F\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    import math\n",
    "    from collections import OrderedDict\n",
    "    from time import sleep\n",
    "\n",
    "    initialized = [False] * 7\n",
    "    print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and defining modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Autograd Functions\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.426535Z",
     "start_time": "2019-02-09T06:41:15.401525Z"
    },
    "code_folding": [
     10,
     49,
     88
    ],
    "hidden": true,
    "scrolled": true,
    "tags": [
     "=>imports",
     "#C-autograd-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[0]:\n",
    "    _ln_peephole_lstm_layer_cpp = load('ln_peephole_lstm_layer',\n",
    "                                       ['./ln_peephole_lstm_layer.cpp'])\n",
    "    _ln_peephole_lstm_layer_cuda = load('ln_peephole_lstm_layer_cuda',\n",
    "                                        ['./ln_peephole_lstm_layer_cuda.cpp', './ln_peephole_lstm_layer_cuda_kernel.cu'])\n",
    "    _ln_peephole_lstm_layer_cuda_less_mem = load('ln_peephole_lstm_layer_cuda_less_mem',\n",
    "                                                 ['./ln_peephole_lstm_layer_cuda_less_mem.cpp', './ln_peephole_lstm_layer_cuda_kernel_less_mem.cu'])\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMFunctionCPP(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMFunctionCUDA(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMFunctionCUDALM(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cuda_less_mem.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch, bias,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cuda_less_mem.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    initialized[0] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Module classes (PyTorch, C++, CUDA)\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.516526Z",
     "start_time": "2019-02-09T06:41:15.428524Z"
    },
    "code_folding": [
     1,
     111,
     112,
     139,
     155,
     170,
     175,
     176,
     203,
     219,
     234,
     239,
     267,
     283,
     298
    ],
    "hidden": true,
    "tags": [
     "#base-modules-define",
     "=>C-autograd-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[1]:\n",
    "    class LNPeepholeLSTMTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "            super(LNPeepholeLSTMTorch, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, states):\n",
    "            assert input.dim() == 3, \"expected a 3 dimensional tensor as `input`, but te given tensor has {} dimension(s)\".format(input.dim())\n",
    "            assert len(states) == 2, \"expected a (hidden, cell) pair as `states`, but the length of the given states is {}\".format(len(states))\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "            assert states[0].size() == (input.size(1), self.hidden_size), \"expected a hidden state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[0].size()), [input.size(1), self.hidden_size])\n",
    "            assert states[1].size() == (input.size(1), self.hidden_size), \"expected a cell state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[1].size()), [input.size(1), self.hidden_size])\n",
    "\n",
    "            hidden, cell = states\n",
    "\n",
    "            hidden_size = self.hidden_size\n",
    "            hidden_size_2 = 2 * hidden_size\n",
    "            hidden_size_3 = hidden_size_2 + hidden_size\n",
    "\n",
    "            norm_shape = torch.Size((hidden_size,))\n",
    "\n",
    "            outputs = input.new_empty((input.size(0), input.size(1), hidden_size))\n",
    "            \n",
    "            ih = input.matmul(self.weight_ih.t())\n",
    "\n",
    "            weight_hc_h = torch.cat((self.weight_hh.t(),\n",
    "                                     torch.cat((self.weight_ch[:hidden_size].diag(),\n",
    "                                                self.weight_ch[hidden_size:hidden_size_2].diag(),\n",
    "                                                self.weight_ch.new_zeros(hidden_size_2, hidden_size))).t()))\n",
    "            weight_co = self.weight_ch[hidden_size_2:]\n",
    "            \n",
    "            gamma_fig = torch.stack((self.gamma_f, self.gamma_i, self.gamma_g))\n",
    "\n",
    "            bias_fig = torch.stack(self.bias[:hidden_size_3].chunk(3, dim=0))\n",
    "            bias_o = self.bias[hidden_size_3:]\n",
    "\n",
    "            for i in range(input.size(0)):\n",
    "                gates = torch.addmm(ih[i], torch.cat((hidden, cell), dim=1), weight_hc_h).view(-1, 4, hidden_size)\n",
    "                gates_fig = gates[:, :3]\n",
    "\n",
    "\n",
    "                gates_fig = F.layer_norm(gates_fig, norm_shape, eps=self.eps)\n",
    "                gates_fig = torch.addcmul(bias_fig, gates_fig, gamma_fig)\n",
    "                forget_input_gates = gates_fig[:, :2].sigmoid()\n",
    "                candidate_cell = F.dropout(gates_fig[:, 2].tanh(), p=self.dropout, training=self.training)\n",
    "\n",
    "\n",
    "                cell = F.layer_norm(torch.addcmul(forget_input_gates[:, 0] * cell,\n",
    "                                                  forget_input_gates[:, 1], candidate_cell),\n",
    "                                    norm_shape, self.gamma_cell, self.beta_cell, self.eps)\n",
    "\n",
    "                output_gate = torch.addcmul(gates[:, 3], cell, weight_co)\n",
    "\n",
    "                output_gate = F.layer_norm(output_gate, norm_shape, self.gamma_o, bias_o, self.eps).sigmoid()\n",
    "\n",
    "                hidden = output_gate * cell.tanh()\n",
    "\n",
    "                outputs[i] = hidden\n",
    "\n",
    "            if self.dropout_on_output:\n",
    "                outputs = F.dropout(outputs, p=self.dropout, training=self.training)\n",
    "                \n",
    "            if self.batch_first:\n",
    "                outputs = outputs.transpose(0, 1).contiguous()\n",
    "\n",
    "            return outputs, (hidden, cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMTorch(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCPP, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCPP.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCPP(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCUDA, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCUDA.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCUDA(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMCUDALM(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCUDALM, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCUDALM.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCUDALM(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    initialized[1] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Definition\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.556519Z",
     "start_time": "2019-02-09T06:41:15.519518Z"
    },
    "code_folding": [
     1,
     35,
     69,
     103,
     104,
     119
    ],
    "hidden": true,
    "tags": [
     "#models-define",
     "=>base-modules-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[2]:\n",
    "    class LNPeepholeTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMTorch(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMTorch(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCPP(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCPP(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCUDA(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCUDA(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeCUDALM(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCUDALM(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCUDALM(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    initialized[2] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Instantiation\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.568527Z",
     "start_time": "2019-02-09T06:41:15.558523Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "=>models-define",
     "#models-init"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[3]:\n",
    "    device = ('cpu', 'cuda')[1]\n",
    "\n",
    "    input_size = 5 #TEST 5\n",
    "    hidden_size = 8 #TEST 8\n",
    "    output_size = 6 #TEST 6\n",
    "    n_layers = 3 #TEST 3\n",
    "    dropout = 0. #TEST 0\n",
    "    eps = 1e-05 #TEST 1e-05\n",
    "\n",
    "    model_torch = LNPeepholeTorch(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cpp = LNPeepholeCPP(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cuda = LNPeepholeCUDA(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cuda_less_mem = LNPeepholeCUDALM(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "\n",
    "    model_torch.to(device)\n",
    "    model_cpp.to(device)\n",
    "    model_cuda.to(device)\n",
    "    model_cuda_less_mem.to(device)\n",
    "\n",
    "    models = (model_torch, model_cpp, model_cuda, model_cuda_less_mem)\n",
    "    \n",
    "    initialized[3] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Parameter Synchronization\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.578522Z",
     "start_time": "2019-02-09T06:41:15.570524Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#param-sync",
     "=>models-init"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[4]:\n",
    "    named_parameter_dicts = [\n",
    "        dict(model_torch.named_parameters()),\n",
    "        dict(model_cpp.named_parameters()),\n",
    "        dict(model_cuda.named_parameters()),\n",
    "        dict(model_cuda_less_mem.named_parameters())\n",
    "    ]\n",
    "\n",
    "    print(\"Synchronized Parameters:\\n\")\n",
    "    for common_param_name in set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(common_param_name))\n",
    "        for i in range(1, len(named_parameter_dicts)):\n",
    "            if named_parameter_dicts[i][common_param_name].size() == named_parameter_dicts[0][common_param_name].size():\n",
    "                named_parameter_dicts[i][common_param_name].data = named_parameter_dicts[0][common_param_name].data\n",
    "            else:\n",
    "                raise RuntimeError(\"Size mismatch\\n0:{}\\n{i}:{}\".format(named_parameter_dicts[0][common_param_name].size(),\n",
    "                                                                        named_parameter_dicts[i][common_param_name].size()))\n",
    "    print()\n",
    "    print(\"Exclusive Parameters (Not Synchronized):\\n\")\n",
    "    for exclusive_param_name in set.union(*(set(npd.keys()) for npd in named_parameter_dicts)) - set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(exclusive_param_name))\n",
    "        \n",
    "    initialized[4] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating a fake dataset\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.589520Z",
     "start_time": "2019-02-09T06:41:15.580524Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#fake-generator",
     "=>param-sync"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[5]:\n",
    "    def create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True):\n",
    "        fake_inputs = torch.randn(dataset_size, sequence_length, input_size)\n",
    "        fake_targets = torch.randint(high=output_size, size=(dataset_size, sequence_length), dtype=torch.int64)\n",
    "\n",
    "        fake_dataset = TensorDataset(fake_inputs, fake_targets)\n",
    "\n",
    "        fake_loader = DataLoader(fake_dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "\n",
    "        return fake_loader\n",
    "    \n",
    "    initialized[5] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.597527Z",
     "start_time": "2019-02-09T06:41:15.590523Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#generate-fake",
     "=>fake-generator"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[6]:\n",
    "    dataset_size = 1000\n",
    "    sequence_length = 20 #TEST 20\n",
    "    batch_size = 8 #TEST 8\n",
    "\n",
    "    fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size)\n",
    "    print(next(iter(fake_loader))[0].size(), next(iter(fake_loader))[1].size())\n",
    "    \n",
    "    initialized[6] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: output comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Forward Outputs\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:33.280427Z",
     "start_time": "2019-02-09T06:29:33.273418Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))\n",
    "\n",
    "inputs = next(iter(fake_loader))[0].to(device)\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "del model # Removing temporary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:10:02.634593Z",
     "start_time": "2019-02-09T06:10:02.324588Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_cuda(inputs, hidden)\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:10:02.705587Z",
     "start_time": "2019-02-09T06:10:02.641585Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_cuda_less_mem(inputs, hidden)\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:33.881415Z",
     "start_time": "2019-02-09T06:29:33.283422Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_torch]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[-0.1924,  0.1772,  0.1920,  0.2721, -0.0711, -0.1628],\n",
      "         [-0.2024,  0.1879,  0.1943,  0.2760, -0.0489, -0.1875],\n",
      "         [-0.1229,  0.1609,  0.1858,  0.2821, -0.0407, -0.1944],\n",
      "         [-0.0112,  0.1333,  0.1726,  0.2726,  0.0202, -0.1900],\n",
      "         [ 0.0533,  0.1244,  0.1589,  0.2618,  0.0700, -0.1806],\n",
      "         [ 0.0826,  0.1220,  0.1525,  0.2573,  0.0941, -0.1707],\n",
      "         [ 0.0963,  0.1217,  0.1496,  0.2545,  0.1071, -0.1642],\n",
      "         [ 0.1030,  0.1223,  0.1476,  0.2525,  0.1137, -0.1604],\n",
      "         [ 0.1066,  0.1231,  0.1467,  0.2511,  0.1187, -0.1579],\n",
      "         [ 0.1106,  0.1223,  0.1481,  0.2506,  0.1226, -0.1558],\n",
      "         [ 0.1134,  0.1222,  0.1468,  0.2510,  0.1222, -0.1538],\n",
      "         [ 0.1126,  0.1238,  0.1463,  0.2496,  0.1254, -0.1539],\n",
      "         [ 0.1144,  0.1233,  0.1477,  0.2496,  0.1276, -0.1530],\n",
      "         [ 0.1151,  0.1237,  0.1462,  0.2497,  0.1265, -0.1527],\n",
      "         [ 0.1138,  0.1255,  0.1473,  0.2484,  0.1320, -0.1526],\n",
      "         [ 0.1148,  0.1258,  0.1472,  0.2487,  0.1335, -0.1517],\n",
      "         [ 0.1163,  0.1255,  0.1461,  0.2493,  0.1317, -0.1508],\n",
      "         [ 0.1152,  0.1271,  0.1462,  0.2485,  0.1353, -0.1506],\n",
      "         [ 0.1166,  0.1275,  0.1462,  0.2487,  0.1366, -0.1491],\n",
      "         [ 0.1161,  0.1291,  0.1453,  0.2482,  0.1391, -0.1483]],\n",
      "\n",
      "        [[-0.3093,  0.3269,  0.0712,  0.1895,  0.0944, -0.2019],\n",
      "         [-0.3480,  0.3216,  0.1167,  0.2166,  0.0831, -0.2145],\n",
      "         [-0.3773,  0.3332,  0.1193,  0.2227,  0.0880, -0.2418],\n",
      "         [-0.3910,  0.3448,  0.1137,  0.2326,  0.1015, -0.2603],\n",
      "         [-0.3862,  0.3537,  0.0975,  0.2449,  0.1149, -0.2722],\n",
      "         [-0.3548,  0.3456,  0.0845,  0.2624,  0.1211, -0.2808],\n",
      "         [-0.2792,  0.3099,  0.0848,  0.2759,  0.1324, -0.2805],\n",
      "         [-0.1489,  0.2594,  0.0803,  0.2704,  0.1538, -0.2599],\n",
      "         [-0.0244,  0.2136,  0.0824,  0.2577,  0.1589, -0.2138],\n",
      "         [ 0.0333,  0.1928,  0.0881,  0.2481,  0.1693, -0.1884],\n",
      "         [ 0.0693,  0.1707,  0.1022,  0.2457,  0.1610, -0.1694],\n",
      "         [ 0.0926,  0.1517,  0.1166,  0.2465,  0.1487, -0.1571],\n",
      "         [ 0.1044,  0.1400,  0.1259,  0.2474,  0.1369, -0.1507],\n",
      "         [ 0.1102,  0.1332,  0.1316,  0.2476,  0.1297, -0.1490],\n",
      "         [ 0.1122,  0.1298,  0.1347,  0.2478,  0.1248, -0.1488],\n",
      "         [ 0.1165,  0.1252,  0.1396,  0.2480,  0.1229, -0.1479],\n",
      "         [ 0.1193,  0.1219,  0.1418,  0.2487,  0.1187, -0.1478],\n",
      "         [ 0.1205,  0.1206,  0.1433,  0.2503,  0.1178, -0.1471],\n",
      "         [ 0.1219,  0.1189,  0.1457,  0.2504,  0.1184, -0.1469],\n",
      "         [ 0.1210,  0.1193,  0.1448,  0.2507,  0.1173, -0.1478]],\n",
      "\n",
      "        [[ 0.0540,  0.2297,  0.0942,  0.1879,  0.3388, -0.0460],\n",
      "         [ 0.0847,  0.2271,  0.0972,  0.1678,  0.3563, -0.0160],\n",
      "         [ 0.0952,  0.2343,  0.0896,  0.1541,  0.3666, -0.0025],\n",
      "         [ 0.0956,  0.2477,  0.0769,  0.1440,  0.3810,  0.0042],\n",
      "         [ 0.0904,  0.2666,  0.0598,  0.1332,  0.4027,  0.0086],\n",
      "         [ 0.0790,  0.2862,  0.0450,  0.1210,  0.4252,  0.0097],\n",
      "         [ 0.0660,  0.3176,  0.0149,  0.1046,  0.4613,  0.0121],\n",
      "         [ 0.0423,  0.3537, -0.0174,  0.0840,  0.4960,  0.0081],\n",
      "         [ 0.0060,  0.3958, -0.0503,  0.0600,  0.5330, -0.0027],\n",
      "         [-0.0318,  0.4429, -0.0850,  0.0353,  0.5769, -0.0107],\n",
      "         [-0.0772,  0.4842, -0.1102,  0.0185,  0.6054, -0.0239],\n",
      "         [-0.1218,  0.5152, -0.1271,  0.0125,  0.6147, -0.0361],\n",
      "         [-0.1476,  0.5147, -0.1156,  0.0302,  0.5755, -0.0288],\n",
      "         [-0.1974,  0.5056, -0.0911,  0.0480,  0.5218, -0.0458],\n",
      "         [-0.2293,  0.4863, -0.0577,  0.0729,  0.4591, -0.0517],\n",
      "         [-0.2561,  0.4740, -0.0331,  0.0872,  0.4204, -0.0618],\n",
      "         [-0.2586,  0.4612, -0.0131,  0.1017,  0.3915, -0.0537],\n",
      "         [-0.2699,  0.4635, -0.0090,  0.1037,  0.3899, -0.0635],\n",
      "         [-0.2780,  0.4610, -0.0038,  0.1063,  0.3833, -0.0693],\n",
      "         [-0.2860,  0.4504,  0.0087,  0.1118,  0.3640, -0.0743]],\n",
      "\n",
      "        [[-0.3371,  0.3528,  0.0549,  0.1787,  0.1194, -0.2123],\n",
      "         [-0.4075,  0.3747,  0.0868,  0.1939,  0.1291, -0.2288],\n",
      "         [-0.4446,  0.3926,  0.0861,  0.1900,  0.1423, -0.2547],\n",
      "         [-0.4636,  0.4110,  0.0743,  0.1913,  0.1672, -0.2687],\n",
      "         [-0.4738,  0.4324,  0.0534,  0.1948,  0.1982, -0.2790],\n",
      "         [-0.4687,  0.4474,  0.0331,  0.2020,  0.2276, -0.2808],\n",
      "         [-0.4578,  0.4701, -0.0011,  0.2097,  0.2709, -0.2845],\n",
      "         [-0.4062,  0.4764, -0.0372,  0.2203,  0.3151, -0.2763],\n",
      "         [-0.3297,  0.4801, -0.0914,  0.2215,  0.3794, -0.2946],\n",
      "         [-0.1722,  0.4222, -0.0963,  0.2105,  0.3808, -0.2405],\n",
      "         [-0.0352,  0.3194, -0.0269,  0.2237,  0.3014, -0.1759],\n",
      "         [ 0.0242,  0.2630,  0.0203,  0.2320,  0.2668, -0.1617],\n",
      "         [ 0.0617,  0.2162,  0.0635,  0.2408,  0.2295, -0.1509],\n",
      "         [ 0.0854,  0.1812,  0.0972,  0.2481,  0.1977, -0.1434],\n",
      "         [ 0.1015,  0.1561,  0.1224,  0.2525,  0.1745, -0.1379],\n",
      "         [ 0.1104,  0.1387,  0.1402,  0.2588,  0.1569, -0.1377],\n",
      "         [ 0.1163,  0.1258,  0.1540,  0.2630,  0.1439, -0.1369],\n",
      "         [ 0.1188,  0.1183,  0.1625,  0.2663,  0.1354, -0.1375],\n",
      "         [ 0.1214,  0.1110,  0.1715,  0.2684,  0.1304, -0.1373],\n",
      "         [ 0.1256,  0.1034,  0.1797,  0.2714,  0.1256, -0.1361]],\n",
      "\n",
      "        [[-0.1599,  0.3311, -0.0024,  0.1483,  0.2346, -0.1685],\n",
      "         [-0.1950,  0.3680, -0.0024,  0.1300,  0.2878, -0.1616],\n",
      "         [-0.2795,  0.4266, -0.0081,  0.1149,  0.3327, -0.1670],\n",
      "         [-0.3498,  0.4580,  0.0069,  0.1262,  0.3249, -0.1567],\n",
      "         [-0.3714,  0.4598,  0.0245,  0.1345,  0.3131, -0.1424],\n",
      "         [-0.3688,  0.4479,  0.0397,  0.1397,  0.3006, -0.1303],\n",
      "         [-0.3621,  0.4373,  0.0496,  0.1415,  0.2929, -0.1213],\n",
      "         [-0.3613,  0.4321,  0.0538,  0.1373,  0.2897, -0.1185],\n",
      "         [-0.3587,  0.4262,  0.0587,  0.1362,  0.2826, -0.1155],\n",
      "         [-0.3626,  0.4228,  0.0627,  0.1316,  0.2756, -0.1168],\n",
      "         [-0.3644,  0.4173,  0.0694,  0.1319,  0.2631, -0.1170],\n",
      "         [-0.3674,  0.4121,  0.0770,  0.1338,  0.2529, -0.1194],\n",
      "         [-0.3724,  0.4099,  0.0808,  0.1320,  0.2521, -0.1248],\n",
      "         [-0.3743,  0.4070,  0.0842,  0.1315,  0.2498, -0.1281],\n",
      "         [-0.3770,  0.4038,  0.0877,  0.1298,  0.2461, -0.1317],\n",
      "         [-0.3798,  0.3970,  0.0960,  0.1322,  0.2314, -0.1349],\n",
      "         [-0.3878,  0.3883,  0.1088,  0.1359,  0.2115, -0.1431],\n",
      "         [-0.3949,  0.3911,  0.1078,  0.1335,  0.2252, -0.1521],\n",
      "         [-0.3929,  0.3807,  0.1187,  0.1401,  0.2050, -0.1546],\n",
      "         [-0.3982,  0.3840,  0.1160,  0.1369,  0.2192, -0.1618]],\n",
      "\n",
      "        [[-0.3663,  0.4274,  0.0439,  0.1573,  0.4143, -0.3325],\n",
      "         [-0.2349,  0.3073,  0.1398,  0.1812,  0.3786, -0.2512],\n",
      "         [-0.1056,  0.2505,  0.1552,  0.1798,  0.3654, -0.1657],\n",
      "         [-0.0024,  0.2186,  0.1545,  0.1713,  0.3460, -0.0789],\n",
      "         [ 0.0471,  0.2245,  0.1286,  0.1599,  0.3428, -0.0335],\n",
      "         [ 0.0641,  0.2421,  0.1012,  0.1514,  0.3505, -0.0177],\n",
      "         [ 0.0710,  0.2532,  0.0847,  0.1491,  0.3565, -0.0143],\n",
      "         [ 0.0729,  0.2589,  0.0758,  0.1493,  0.3588, -0.0152],\n",
      "         [ 0.0723,  0.2605,  0.0723,  0.1533,  0.3578, -0.0196],\n",
      "         [ 0.0784,  0.2498,  0.0782,  0.1587,  0.3459, -0.0216],\n",
      "         [ 0.0837,  0.2437,  0.0812,  0.1619,  0.3384, -0.0196],\n",
      "         [ 0.0881,  0.2376,  0.0854,  0.1654,  0.3307, -0.0188],\n",
      "         [ 0.0926,  0.2318,  0.0895,  0.1686,  0.3232, -0.0181],\n",
      "         [ 0.0961,  0.2281,  0.0920,  0.1709,  0.3178, -0.0174],\n",
      "         [ 0.0992,  0.2244,  0.0945,  0.1738,  0.3123, -0.0177],\n",
      "         [ 0.1060,  0.2170,  0.0982,  0.1798,  0.3023, -0.0188],\n",
      "         [ 0.1098,  0.2145,  0.0986,  0.1814,  0.2983, -0.0172],\n",
      "         [ 0.1118,  0.2114,  0.1004,  0.1843,  0.2934, -0.0186],\n",
      "         [ 0.1139,  0.2078,  0.1029,  0.1872,  0.2883, -0.0196],\n",
      "         [ 0.1153,  0.2047,  0.1056,  0.1903,  0.2832, -0.0211]],\n",
      "\n",
      "        [[ 0.0458,  0.1051,  0.2396,  0.1994,  0.1965, -0.0887],\n",
      "         [ 0.1330,  0.1297,  0.1845,  0.2053,  0.2261, -0.0160],\n",
      "         [ 0.1574,  0.1455,  0.1533,  0.2060,  0.2315, -0.0028],\n",
      "         [ 0.1617,  0.1557,  0.1389,  0.2083,  0.2325, -0.0054],\n",
      "         [ 0.1608,  0.1590,  0.1349,  0.2124,  0.2286, -0.0126],\n",
      "         [ 0.1594,  0.1588,  0.1354,  0.2181,  0.2223, -0.0206],\n",
      "         [ 0.1592,  0.1539,  0.1390,  0.2228,  0.2129, -0.0276],\n",
      "         [ 0.1597,  0.1489,  0.1436,  0.2274,  0.2049, -0.0324],\n",
      "         [ 0.1599,  0.1440,  0.1485,  0.2313,  0.1975, -0.0365],\n",
      "         [ 0.1616,  0.1372,  0.1538,  0.2362,  0.1882, -0.0404],\n",
      "         [ 0.1617,  0.1352,  0.1558,  0.2383,  0.1845, -0.0434],\n",
      "         [ 0.1593,  0.1357,  0.1558,  0.2373,  0.1840, -0.0467],\n",
      "         [ 0.1557,  0.1388,  0.1552,  0.2361,  0.1861, -0.0490],\n",
      "         [ 0.1549,  0.1389,  0.1560,  0.2389,  0.1841, -0.0523],\n",
      "         [ 0.1538,  0.1388,  0.1557,  0.2382,  0.1837, -0.0537],\n",
      "         [ 0.1521,  0.1405,  0.1549,  0.2374,  0.1855, -0.0545],\n",
      "         [ 0.1498,  0.1431,  0.1548,  0.2376,  0.1874, -0.0553],\n",
      "         [ 0.1488,  0.1445,  0.1541,  0.2378,  0.1885, -0.0565],\n",
      "         [ 0.1476,  0.1460,  0.1525,  0.2362,  0.1902, -0.0560],\n",
      "         [ 0.1506,  0.1429,  0.1539,  0.2381,  0.1871, -0.0547]],\n",
      "\n",
      "        [[ 0.0373,  0.1055,  0.2312,  0.2289,  0.1674, -0.1129],\n",
      "         [ 0.1607,  0.0963,  0.1980,  0.2325,  0.1752, -0.0225],\n",
      "         [ 0.1881,  0.1057,  0.1731,  0.2335,  0.1756, -0.0129],\n",
      "         [ 0.1893,  0.1120,  0.1640,  0.2370,  0.1733, -0.0223],\n",
      "         [ 0.1836,  0.1115,  0.1653,  0.2430,  0.1646, -0.0368],\n",
      "         [ 0.1770,  0.1106,  0.1680,  0.2456,  0.1596, -0.0479],\n",
      "         [ 0.1717,  0.1107,  0.1703,  0.2478,  0.1568, -0.0558],\n",
      "         [ 0.1632,  0.1157,  0.1686,  0.2470,  0.1598, -0.0624],\n",
      "         [ 0.1626,  0.1135,  0.1709,  0.2504,  0.1553, -0.0651],\n",
      "         [ 0.1590,  0.1159,  0.1699,  0.2489,  0.1578, -0.0668],\n",
      "         [ 0.1599,  0.1141,  0.1711,  0.2512,  0.1552, -0.0668],\n",
      "         [ 0.1549,  0.1199,  0.1676,  0.2481,  0.1622, -0.0666],\n",
      "         [ 0.1521,  0.1241,  0.1649,  0.2458,  0.1678, -0.0644],\n",
      "         [ 0.1496,  0.1288,  0.1616,  0.2443,  0.1733, -0.0619],\n",
      "         [ 0.1496,  0.1312,  0.1596,  0.2419,  0.1775, -0.0582],\n",
      "         [ 0.1510,  0.1320,  0.1577,  0.2424,  0.1785, -0.0570],\n",
      "         [ 0.1514,  0.1326,  0.1570,  0.2412,  0.1802, -0.0553],\n",
      "         [ 0.1504,  0.1358,  0.1555,  0.2371,  0.1857, -0.0513],\n",
      "         [ 0.1509,  0.1376,  0.1536,  0.2366,  0.1877, -0.0499],\n",
      "         [ 0.1483,  0.1423,  0.1511,  0.2330,  0.1940, -0.0472]]],\n",
      "       device='cuda:0'), (tensor([[[-5.2217e-01, -1.1236e-03, -1.2801e-02,  4.5314e-02,  1.0696e-02,\n",
      "           7.6920e-03,  1.3954e-01,  7.5384e-02],\n",
      "         [ 4.3892e-01, -7.2033e-03, -2.3726e-01, -6.5286e-02, -1.3376e-01,\n",
      "          -1.0229e-01,  1.7927e-01,  4.9708e-02],\n",
      "         [-5.1896e-01,  3.2933e-03,  3.6618e-02,  2.8058e-02, -9.3617e-02,\n",
      "           1.4323e-01,  4.9164e-01, -6.5861e-02],\n",
      "         [ 4.3159e-01,  4.0894e-04, -4.6276e-02, -5.5760e-02,  6.4458e-02,\n",
      "           1.4291e-02, -6.2669e-01,  6.7342e-02],\n",
      "         [ 4.4173e-02, -9.6873e-03, -1.7931e-01,  2.8432e-03, -1.5870e-01,\n",
      "           8.3298e-02,  5.2621e-01, -1.6443e-01],\n",
      "         [ 4.1071e-01, -2.4306e-03,  2.9700e-02,  5.3761e-02, -7.3411e-02,\n",
      "           3.3684e-02, -6.0949e-01,  4.5786e-02],\n",
      "         [-5.5558e-01,  1.8244e-03,  1.6906e-01, -5.9008e-04,  2.4987e-02,\n",
      "          -4.6794e-02,  4.3210e-01,  1.3903e-02],\n",
      "         [ 3.7426e-01,  1.6717e-03,  4.3125e-02,  3.6186e-02, -1.0372e-01,\n",
      "           1.0293e-01, -7.4226e-01, -1.8094e-02]],\n",
      "\n",
      "        [[ 3.0063e-01, -2.1729e-04, -1.4830e-02, -6.5788e-01,  4.3874e-03,\n",
      "          -1.6909e-02,  4.0584e-01, -8.7769e-03],\n",
      "         [ 1.1392e-01, -3.5901e-04, -1.0953e-03, -5.4127e-01,  1.1149e-02,\n",
      "          -3.5242e-02,  4.8017e-01, -5.6344e-02],\n",
      "         [ 3.8739e-01, -1.1109e-04, -1.5600e-02, -6.5556e-01, -3.7146e-03,\n",
      "          -5.0859e-02,  2.3491e-01,  2.2417e-02],\n",
      "         [ 1.0253e-01,  4.0264e-04,  8.4015e-02, -5.3595e-01, -1.0773e-02,\n",
      "           2.2031e-01, -3.8498e-01,  4.6772e-02],\n",
      "         [ 1.4269e-01, -3.0840e-04, -3.9566e-03, -6.4289e-01,  7.6703e-03,\n",
      "          -6.3565e-02,  4.7348e-01, -3.4137e-02],\n",
      "         [-1.4450e-01, -5.9369e-04,  1.2924e-01,  2.4726e-01, -1.1608e-02,\n",
      "          -1.0547e-01, -3.7662e-01, -1.2425e-02],\n",
      "         [-1.0781e-01, -3.3089e-04, -1.1632e-01,  1.9478e-01, -1.7184e-02,\n",
      "          -1.0187e-01, -2.6459e-01,  2.5443e-02],\n",
      "         [-1.1432e-01, -6.2426e-04,  1.2892e-01,  2.9334e-01, -1.2737e-02,\n",
      "          -1.0610e-01, -3.8267e-01, -1.0049e-02]],\n",
      "\n",
      "        [[ 1.7078e-01, -3.7921e-02, -8.7001e-02, -9.4890e-02, -5.6862e-01,\n",
      "           6.3925e-03,  4.1027e-01,  9.4136e-02],\n",
      "         [ 1.3294e-01, -1.1641e-02, -4.4392e-02, -6.6663e-02, -6.2991e-01,\n",
      "           4.6387e-03,  3.9057e-01,  1.0406e-01],\n",
      "         [-1.6559e-01, -7.0554e-02, -2.3218e-01, -1.3294e-01,  3.5105e-01,\n",
      "          -1.1598e-02, -1.7488e-01,  8.0153e-02],\n",
      "         [ 1.0182e-01,  4.7492e-02,  3.9469e-02, -1.6625e-02, -6.3354e-01,\n",
      "           3.7954e-04,  4.0383e-01, -2.1284e-02],\n",
      "         [ 6.0272e-02, -1.4368e-01, -1.4742e-01, -3.9993e-02,  3.9779e-01,\n",
      "           2.9805e-04, -3.5360e-01,  9.8486e-02],\n",
      "         [-2.0732e-01, -4.0423e-02,  5.6306e-02, -1.4748e-02, -2.9595e-01,\n",
      "          -3.4902e-02,  4.4113e-01, -8.2723e-02],\n",
      "         [-4.9601e-02, -4.3352e-02, -6.2432e-03, -4.3534e-03, -5.1146e-01,\n",
      "          -8.5033e-03,  4.3753e-01, -7.1027e-02],\n",
      "         [-8.8459e-02, -4.0524e-02,  4.9922e-02, -4.3955e-03, -4.8214e-01,\n",
      "          -2.3192e-02,  4.3794e-01, -6.9807e-02]]], device='cuda:0'), tensor([[[-2.1144e+00, -3.9284e-03, -4.1578e-02,  7.5421e-02,  1.8845e-02,\n",
      "           1.3149e-02,  1.6433e+00,  1.1641e-01],\n",
      "         [ 1.0656e+00, -1.0555e-02, -8.1226e-01, -1.1339e-01, -4.8479e-01,\n",
      "          -2.1765e-01,  1.9653e+00,  9.3539e-02],\n",
      "         [-1.9708e+00,  4.0186e-03,  8.7776e-02,  9.8506e-02, -2.6076e-01,\n",
      "           2.6518e-01,  1.5392e+00, -1.7510e-01],\n",
      "         [ 1.5980e+00,  6.9324e-04, -5.8963e-02, -8.8068e-02,  1.1541e-01,\n",
      "           6.1636e-02, -2.1320e+00,  1.9672e-01],\n",
      "         [ 9.7176e-02, -1.2258e-02, -9.0067e-01,  8.4514e-03, -2.5629e-01,\n",
      "           1.3809e-01,  2.2671e+00, -2.7336e-01],\n",
      "         [ 1.3658e+00, -3.2968e-03,  1.9855e-01,  8.7845e-02, -1.4006e-01,\n",
      "           9.4720e-02, -2.3353e+00,  6.9818e-02],\n",
      "         [-2.0751e+00,  3.5501e-03,  2.9532e-01, -1.3717e-03,  9.7392e-02,\n",
      "          -8.9750e-02,  1.6826e+00,  3.8214e-02],\n",
      "         [ 1.2702e+00,  2.1936e-03,  1.3879e-01,  8.0371e-02, -1.7104e-01,\n",
      "           2.4188e-01, -2.3249e+00, -3.2223e-02]],\n",
      "\n",
      "        [[ 7.6905e-01, -3.3661e-04, -9.8593e-02, -1.4729e+00,  7.9891e-03,\n",
      "          -4.0098e-02,  1.1594e+00, -1.7173e-02],\n",
      "         [ 1.6795e-01, -9.7107e-04, -9.5938e-03, -1.2147e+00,  2.2566e-02,\n",
      "          -7.1038e-02,  1.8186e+00, -1.1155e-01],\n",
      "         [ 1.0773e+00, -1.8978e-04, -8.7294e-02, -1.4115e+00, -6.3018e-03,\n",
      "          -9.8337e-02,  5.2174e-01,  4.4901e-02],\n",
      "         [ 4.2863e-01,  6.5274e-04,  2.6080e-01, -1.3025e+00, -2.5839e-02,\n",
      "           3.4538e-01, -1.0255e+00,  9.2975e-02],\n",
      "         [ 2.3009e-01, -7.0563e-04, -3.8305e-02, -1.2537e+00,  1.3578e-02,\n",
      "          -1.2142e-01,  1.8445e+00, -6.8556e-02],\n",
      "         [-4.1538e-01, -1.2048e-03,  1.6550e-01,  1.6261e+00, -2.8601e-02,\n",
      "          -2.0167e-01, -9.4624e-01, -2.4970e-02],\n",
      "         [-1.7487e-01, -6.6211e-04, -1.5328e-01,  1.7963e+00, -2.8164e-02,\n",
      "          -2.2492e-01, -6.0044e-01,  5.1205e-02],\n",
      "         [-3.8442e-01, -1.1477e-03,  1.6941e-01,  1.6131e+00, -3.1578e-02,\n",
      "          -2.0726e-01, -9.7236e-01, -2.0248e-02]],\n",
      "\n",
      "        [[ 2.4696e-01, -1.7208e-01, -3.4541e-01, -2.2653e-01, -1.4306e+00,\n",
      "           9.4850e-03,  1.2022e+00,  1.5235e-01],\n",
      "         [ 1.9610e-01, -4.3513e-02, -2.1215e-01, -1.8028e-01, -1.7042e+00,\n",
      "           7.4458e-03,  1.0747e+00,  1.5799e-01],\n",
      "         [-3.2858e-01, -4.7968e-01, -4.3529e-01, -1.9177e-01,  1.9190e+00,\n",
      "          -1.8955e-02, -3.5560e-01,  1.6233e-01],\n",
      "         [ 1.5224e-01,  1.3403e-01,  1.3743e-01, -4.6180e-02, -1.8176e+00,\n",
      "           5.0346e-04,  1.1873e+00, -4.6768e-02],\n",
      "         [ 1.4091e-01, -8.5326e-01, -2.9628e-01, -5.8831e-02,  1.6011e+00,\n",
      "           7.3917e-04, -8.2557e-01,  1.8131e-01],\n",
      "         [-4.0031e-01, -6.1539e-02,  1.1663e-01, -4.7155e-02, -5.3675e-01,\n",
      "          -4.9210e-02,  1.6315e+00, -1.5532e-01],\n",
      "         [-8.3222e-02, -7.7332e-02, -1.3573e-02, -1.3802e-02, -1.0932e+00,\n",
      "          -1.2443e-02,  1.5820e+00, -1.2399e-01],\n",
      "         [-1.5233e-01, -6.3871e-02,  1.1590e-01, -1.5403e-02, -1.0542e+00,\n",
      "          -3.2286e-02,  1.5652e+00, -1.3323e-01]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_torch]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out0 = model_torch(inputs, hidden)\n",
    "    print(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:34.302417Z",
     "start_time": "2019-02-09T06:29:33.883422Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_cpp]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[-0.1924,  0.1772,  0.1920,  0.2721, -0.0711, -0.1628],\n",
      "         [-0.2024,  0.1879,  0.1943,  0.2760, -0.0489, -0.1875],\n",
      "         [-0.1229,  0.1609,  0.1858,  0.2821, -0.0407, -0.1944],\n",
      "         [-0.0112,  0.1333,  0.1726,  0.2726,  0.0202, -0.1900],\n",
      "         [ 0.0533,  0.1244,  0.1589,  0.2618,  0.0700, -0.1806],\n",
      "         [ 0.0826,  0.1220,  0.1525,  0.2573,  0.0941, -0.1707],\n",
      "         [ 0.0963,  0.1217,  0.1496,  0.2545,  0.1071, -0.1642],\n",
      "         [ 0.1030,  0.1223,  0.1476,  0.2525,  0.1137, -0.1604],\n",
      "         [ 0.1066,  0.1231,  0.1467,  0.2511,  0.1187, -0.1579],\n",
      "         [ 0.1106,  0.1223,  0.1481,  0.2506,  0.1226, -0.1558],\n",
      "         [ 0.1134,  0.1222,  0.1468,  0.2510,  0.1222, -0.1538],\n",
      "         [ 0.1126,  0.1238,  0.1463,  0.2496,  0.1254, -0.1539],\n",
      "         [ 0.1144,  0.1233,  0.1477,  0.2496,  0.1276, -0.1530],\n",
      "         [ 0.1151,  0.1237,  0.1462,  0.2497,  0.1265, -0.1527],\n",
      "         [ 0.1138,  0.1255,  0.1473,  0.2484,  0.1320, -0.1526],\n",
      "         [ 0.1148,  0.1258,  0.1472,  0.2487,  0.1335, -0.1517],\n",
      "         [ 0.1163,  0.1255,  0.1461,  0.2493,  0.1317, -0.1508],\n",
      "         [ 0.1152,  0.1271,  0.1462,  0.2485,  0.1353, -0.1506],\n",
      "         [ 0.1166,  0.1275,  0.1462,  0.2487,  0.1366, -0.1491],\n",
      "         [ 0.1161,  0.1291,  0.1453,  0.2482,  0.1391, -0.1483]],\n",
      "\n",
      "        [[-0.3093,  0.3269,  0.0712,  0.1895,  0.0944, -0.2019],\n",
      "         [-0.3480,  0.3216,  0.1167,  0.2166,  0.0831, -0.2145],\n",
      "         [-0.3773,  0.3332,  0.1193,  0.2227,  0.0880, -0.2418],\n",
      "         [-0.3910,  0.3448,  0.1137,  0.2326,  0.1015, -0.2603],\n",
      "         [-0.3862,  0.3537,  0.0975,  0.2449,  0.1149, -0.2722],\n",
      "         [-0.3548,  0.3456,  0.0845,  0.2624,  0.1211, -0.2808],\n",
      "         [-0.2792,  0.3099,  0.0848,  0.2759,  0.1324, -0.2805],\n",
      "         [-0.1489,  0.2594,  0.0803,  0.2704,  0.1538, -0.2599],\n",
      "         [-0.0244,  0.2136,  0.0824,  0.2577,  0.1589, -0.2138],\n",
      "         [ 0.0333,  0.1928,  0.0881,  0.2481,  0.1693, -0.1884],\n",
      "         [ 0.0693,  0.1707,  0.1022,  0.2457,  0.1610, -0.1694],\n",
      "         [ 0.0926,  0.1517,  0.1166,  0.2465,  0.1487, -0.1571],\n",
      "         [ 0.1044,  0.1400,  0.1259,  0.2474,  0.1369, -0.1507],\n",
      "         [ 0.1102,  0.1332,  0.1316,  0.2476,  0.1297, -0.1490],\n",
      "         [ 0.1122,  0.1298,  0.1347,  0.2478,  0.1248, -0.1488],\n",
      "         [ 0.1165,  0.1252,  0.1396,  0.2480,  0.1229, -0.1479],\n",
      "         [ 0.1193,  0.1219,  0.1418,  0.2487,  0.1187, -0.1478],\n",
      "         [ 0.1205,  0.1206,  0.1433,  0.2503,  0.1178, -0.1471],\n",
      "         [ 0.1219,  0.1189,  0.1457,  0.2504,  0.1184, -0.1469],\n",
      "         [ 0.1210,  0.1193,  0.1448,  0.2507,  0.1173, -0.1478]],\n",
      "\n",
      "        [[ 0.0540,  0.2297,  0.0942,  0.1879,  0.3388, -0.0460],\n",
      "         [ 0.0847,  0.2271,  0.0972,  0.1678,  0.3563, -0.0160],\n",
      "         [ 0.0952,  0.2343,  0.0896,  0.1541,  0.3666, -0.0025],\n",
      "         [ 0.0956,  0.2477,  0.0769,  0.1440,  0.3810,  0.0042],\n",
      "         [ 0.0904,  0.2666,  0.0598,  0.1332,  0.4027,  0.0086],\n",
      "         [ 0.0790,  0.2862,  0.0450,  0.1210,  0.4252,  0.0097],\n",
      "         [ 0.0660,  0.3176,  0.0149,  0.1046,  0.4613,  0.0121],\n",
      "         [ 0.0423,  0.3537, -0.0174,  0.0840,  0.4960,  0.0081],\n",
      "         [ 0.0060,  0.3958, -0.0503,  0.0600,  0.5330, -0.0027],\n",
      "         [-0.0318,  0.4429, -0.0850,  0.0353,  0.5769, -0.0107],\n",
      "         [-0.0772,  0.4842, -0.1102,  0.0185,  0.6054, -0.0239],\n",
      "         [-0.1218,  0.5152, -0.1271,  0.0125,  0.6147, -0.0361],\n",
      "         [-0.1476,  0.5147, -0.1156,  0.0302,  0.5755, -0.0288],\n",
      "         [-0.1974,  0.5056, -0.0911,  0.0480,  0.5218, -0.0458],\n",
      "         [-0.2293,  0.4863, -0.0577,  0.0729,  0.4591, -0.0517],\n",
      "         [-0.2561,  0.4740, -0.0331,  0.0872,  0.4204, -0.0618],\n",
      "         [-0.2586,  0.4612, -0.0131,  0.1017,  0.3915, -0.0537],\n",
      "         [-0.2699,  0.4635, -0.0090,  0.1037,  0.3899, -0.0635],\n",
      "         [-0.2780,  0.4610, -0.0038,  0.1063,  0.3833, -0.0693],\n",
      "         [-0.2860,  0.4504,  0.0087,  0.1118,  0.3640, -0.0743]],\n",
      "\n",
      "        [[-0.3371,  0.3528,  0.0549,  0.1787,  0.1194, -0.2123],\n",
      "         [-0.4075,  0.3747,  0.0868,  0.1939,  0.1291, -0.2288],\n",
      "         [-0.4446,  0.3926,  0.0861,  0.1900,  0.1423, -0.2547],\n",
      "         [-0.4636,  0.4110,  0.0743,  0.1913,  0.1672, -0.2687],\n",
      "         [-0.4738,  0.4324,  0.0534,  0.1948,  0.1982, -0.2790],\n",
      "         [-0.4687,  0.4474,  0.0331,  0.2020,  0.2276, -0.2808],\n",
      "         [-0.4578,  0.4701, -0.0011,  0.2097,  0.2709, -0.2845],\n",
      "         [-0.4062,  0.4764, -0.0372,  0.2203,  0.3151, -0.2763],\n",
      "         [-0.3297,  0.4801, -0.0914,  0.2215,  0.3794, -0.2946],\n",
      "         [-0.1721,  0.4222, -0.0963,  0.2105,  0.3808, -0.2405],\n",
      "         [-0.0352,  0.3194, -0.0269,  0.2237,  0.3014, -0.1759],\n",
      "         [ 0.0242,  0.2630,  0.0203,  0.2320,  0.2668, -0.1617],\n",
      "         [ 0.0617,  0.2162,  0.0635,  0.2408,  0.2295, -0.1509],\n",
      "         [ 0.0854,  0.1812,  0.0972,  0.2481,  0.1977, -0.1434],\n",
      "         [ 0.1015,  0.1561,  0.1224,  0.2525,  0.1745, -0.1379],\n",
      "         [ 0.1104,  0.1387,  0.1402,  0.2588,  0.1569, -0.1377],\n",
      "         [ 0.1163,  0.1258,  0.1540,  0.2630,  0.1439, -0.1369],\n",
      "         [ 0.1188,  0.1183,  0.1625,  0.2663,  0.1354, -0.1375],\n",
      "         [ 0.1214,  0.1110,  0.1715,  0.2684,  0.1304, -0.1373],\n",
      "         [ 0.1256,  0.1034,  0.1797,  0.2714,  0.1256, -0.1361]],\n",
      "\n",
      "        [[-0.1599,  0.3311, -0.0024,  0.1483,  0.2346, -0.1685],\n",
      "         [-0.1950,  0.3680, -0.0024,  0.1300,  0.2878, -0.1616],\n",
      "         [-0.2795,  0.4266, -0.0081,  0.1149,  0.3327, -0.1670],\n",
      "         [-0.3498,  0.4580,  0.0069,  0.1262,  0.3249, -0.1567],\n",
      "         [-0.3714,  0.4598,  0.0245,  0.1345,  0.3131, -0.1424],\n",
      "         [-0.3688,  0.4479,  0.0397,  0.1397,  0.3006, -0.1303],\n",
      "         [-0.3621,  0.4373,  0.0496,  0.1415,  0.2929, -0.1213],\n",
      "         [-0.3613,  0.4321,  0.0538,  0.1373,  0.2897, -0.1185],\n",
      "         [-0.3587,  0.4262,  0.0587,  0.1362,  0.2826, -0.1155],\n",
      "         [-0.3626,  0.4228,  0.0627,  0.1316,  0.2756, -0.1168],\n",
      "         [-0.3644,  0.4173,  0.0694,  0.1319,  0.2631, -0.1170],\n",
      "         [-0.3674,  0.4121,  0.0770,  0.1338,  0.2529, -0.1194],\n",
      "         [-0.3724,  0.4099,  0.0808,  0.1320,  0.2521, -0.1248],\n",
      "         [-0.3743,  0.4070,  0.0842,  0.1315,  0.2498, -0.1281],\n",
      "         [-0.3770,  0.4038,  0.0877,  0.1298,  0.2461, -0.1317],\n",
      "         [-0.3798,  0.3970,  0.0960,  0.1322,  0.2314, -0.1349],\n",
      "         [-0.3878,  0.3883,  0.1088,  0.1359,  0.2115, -0.1431],\n",
      "         [-0.3949,  0.3911,  0.1078,  0.1335,  0.2252, -0.1521],\n",
      "         [-0.3929,  0.3807,  0.1187,  0.1401,  0.2050, -0.1546],\n",
      "         [-0.3982,  0.3840,  0.1160,  0.1369,  0.2192, -0.1618]],\n",
      "\n",
      "        [[-0.3663,  0.4274,  0.0439,  0.1573,  0.4143, -0.3325],\n",
      "         [-0.2349,  0.3073,  0.1398,  0.1812,  0.3786, -0.2512],\n",
      "         [-0.1056,  0.2505,  0.1552,  0.1798,  0.3654, -0.1657],\n",
      "         [-0.0024,  0.2186,  0.1545,  0.1713,  0.3460, -0.0789],\n",
      "         [ 0.0471,  0.2245,  0.1286,  0.1599,  0.3428, -0.0335],\n",
      "         [ 0.0641,  0.2421,  0.1012,  0.1514,  0.3505, -0.0177],\n",
      "         [ 0.0710,  0.2532,  0.0847,  0.1491,  0.3565, -0.0143],\n",
      "         [ 0.0729,  0.2589,  0.0758,  0.1493,  0.3588, -0.0152],\n",
      "         [ 0.0723,  0.2605,  0.0723,  0.1533,  0.3578, -0.0196],\n",
      "         [ 0.0784,  0.2498,  0.0782,  0.1587,  0.3459, -0.0216],\n",
      "         [ 0.0837,  0.2437,  0.0812,  0.1619,  0.3384, -0.0196],\n",
      "         [ 0.0881,  0.2376,  0.0854,  0.1654,  0.3307, -0.0188],\n",
      "         [ 0.0926,  0.2318,  0.0895,  0.1686,  0.3232, -0.0181],\n",
      "         [ 0.0961,  0.2281,  0.0920,  0.1709,  0.3178, -0.0174],\n",
      "         [ 0.0992,  0.2244,  0.0945,  0.1738,  0.3123, -0.0177],\n",
      "         [ 0.1060,  0.2170,  0.0982,  0.1798,  0.3023, -0.0188],\n",
      "         [ 0.1098,  0.2145,  0.0986,  0.1814,  0.2983, -0.0172],\n",
      "         [ 0.1118,  0.2114,  0.1004,  0.1843,  0.2934, -0.0186],\n",
      "         [ 0.1139,  0.2078,  0.1029,  0.1872,  0.2883, -0.0196],\n",
      "         [ 0.1153,  0.2047,  0.1056,  0.1903,  0.2832, -0.0211]],\n",
      "\n",
      "        [[ 0.0458,  0.1051,  0.2396,  0.1994,  0.1965, -0.0887],\n",
      "         [ 0.1330,  0.1297,  0.1845,  0.2053,  0.2261, -0.0160],\n",
      "         [ 0.1574,  0.1455,  0.1533,  0.2060,  0.2315, -0.0028],\n",
      "         [ 0.1617,  0.1557,  0.1389,  0.2083,  0.2325, -0.0054],\n",
      "         [ 0.1608,  0.1590,  0.1349,  0.2124,  0.2286, -0.0126],\n",
      "         [ 0.1594,  0.1588,  0.1354,  0.2181,  0.2223, -0.0206],\n",
      "         [ 0.1592,  0.1539,  0.1390,  0.2228,  0.2129, -0.0276],\n",
      "         [ 0.1597,  0.1489,  0.1436,  0.2274,  0.2049, -0.0324],\n",
      "         [ 0.1599,  0.1440,  0.1485,  0.2313,  0.1975, -0.0365],\n",
      "         [ 0.1616,  0.1372,  0.1538,  0.2362,  0.1882, -0.0404],\n",
      "         [ 0.1617,  0.1352,  0.1558,  0.2383,  0.1845, -0.0434],\n",
      "         [ 0.1593,  0.1357,  0.1558,  0.2373,  0.1840, -0.0467],\n",
      "         [ 0.1557,  0.1388,  0.1552,  0.2361,  0.1861, -0.0490],\n",
      "         [ 0.1549,  0.1389,  0.1560,  0.2389,  0.1841, -0.0523],\n",
      "         [ 0.1538,  0.1388,  0.1557,  0.2382,  0.1837, -0.0537],\n",
      "         [ 0.1521,  0.1405,  0.1549,  0.2374,  0.1855, -0.0545],\n",
      "         [ 0.1498,  0.1431,  0.1548,  0.2376,  0.1874, -0.0553],\n",
      "         [ 0.1488,  0.1445,  0.1541,  0.2378,  0.1885, -0.0565],\n",
      "         [ 0.1476,  0.1460,  0.1525,  0.2362,  0.1902, -0.0560],\n",
      "         [ 0.1506,  0.1429,  0.1539,  0.2381,  0.1871, -0.0547]],\n",
      "\n",
      "        [[ 0.0373,  0.1055,  0.2312,  0.2289,  0.1674, -0.1129],\n",
      "         [ 0.1607,  0.0963,  0.1980,  0.2325,  0.1752, -0.0225],\n",
      "         [ 0.1881,  0.1057,  0.1731,  0.2335,  0.1756, -0.0129],\n",
      "         [ 0.1893,  0.1120,  0.1640,  0.2370,  0.1733, -0.0223],\n",
      "         [ 0.1836,  0.1115,  0.1653,  0.2430,  0.1646, -0.0368],\n",
      "         [ 0.1770,  0.1106,  0.1680,  0.2456,  0.1596, -0.0479],\n",
      "         [ 0.1717,  0.1107,  0.1703,  0.2478,  0.1568, -0.0558],\n",
      "         [ 0.1632,  0.1157,  0.1686,  0.2470,  0.1598, -0.0624],\n",
      "         [ 0.1626,  0.1135,  0.1709,  0.2504,  0.1553, -0.0651],\n",
      "         [ 0.1590,  0.1159,  0.1699,  0.2489,  0.1578, -0.0668],\n",
      "         [ 0.1599,  0.1141,  0.1711,  0.2512,  0.1552, -0.0668],\n",
      "         [ 0.1549,  0.1199,  0.1676,  0.2481,  0.1622, -0.0666],\n",
      "         [ 0.1521,  0.1241,  0.1649,  0.2458,  0.1678, -0.0644],\n",
      "         [ 0.1496,  0.1288,  0.1616,  0.2443,  0.1733, -0.0619],\n",
      "         [ 0.1496,  0.1312,  0.1596,  0.2419,  0.1775, -0.0582],\n",
      "         [ 0.1510,  0.1320,  0.1577,  0.2424,  0.1785, -0.0570],\n",
      "         [ 0.1514,  0.1326,  0.1570,  0.2412,  0.1802, -0.0553],\n",
      "         [ 0.1504,  0.1358,  0.1555,  0.2371,  0.1857, -0.0513],\n",
      "         [ 0.1509,  0.1376,  0.1536,  0.2366,  0.1877, -0.0499],\n",
      "         [ 0.1483,  0.1423,  0.1511,  0.2330,  0.1940, -0.0472]]],\n",
      "       device='cuda:0'), (tensor([[[-5.2217e-01, -1.1236e-03, -1.2801e-02,  4.5314e-02,  1.0696e-02,\n",
      "           7.6920e-03,  1.3954e-01,  7.5384e-02],\n",
      "         [ 4.3892e-01, -7.2033e-03, -2.3726e-01, -6.5286e-02, -1.3376e-01,\n",
      "          -1.0229e-01,  1.7927e-01,  4.9708e-02],\n",
      "         [-5.1896e-01,  3.2933e-03,  3.6618e-02,  2.8058e-02, -9.3617e-02,\n",
      "           1.4323e-01,  4.9164e-01, -6.5861e-02],\n",
      "         [ 4.3159e-01,  4.0894e-04, -4.6276e-02, -5.5760e-02,  6.4458e-02,\n",
      "           1.4291e-02, -6.2669e-01,  6.7342e-02],\n",
      "         [ 4.4172e-02, -9.6873e-03, -1.7931e-01,  2.8432e-03, -1.5870e-01,\n",
      "           8.3298e-02,  5.2621e-01, -1.6443e-01],\n",
      "         [ 4.1071e-01, -2.4306e-03,  2.9700e-02,  5.3761e-02, -7.3411e-02,\n",
      "           3.3684e-02, -6.0949e-01,  4.5786e-02],\n",
      "         [-5.5558e-01,  1.8244e-03,  1.6906e-01, -5.9008e-04,  2.4987e-02,\n",
      "          -4.6794e-02,  4.3210e-01,  1.3903e-02],\n",
      "         [ 3.7426e-01,  1.6717e-03,  4.3125e-02,  3.6186e-02, -1.0372e-01,\n",
      "           1.0293e-01, -7.4226e-01, -1.8094e-02]],\n",
      "\n",
      "        [[ 3.0063e-01, -2.1729e-04, -1.4830e-02, -6.5788e-01,  4.3874e-03,\n",
      "          -1.6909e-02,  4.0584e-01, -8.7770e-03],\n",
      "         [ 1.1392e-01, -3.5901e-04, -1.0953e-03, -5.4127e-01,  1.1149e-02,\n",
      "          -3.5242e-02,  4.8017e-01, -5.6344e-02],\n",
      "         [ 3.8739e-01, -1.1109e-04, -1.5600e-02, -6.5556e-01, -3.7146e-03,\n",
      "          -5.0859e-02,  2.3491e-01,  2.2417e-02],\n",
      "         [ 1.0253e-01,  4.0264e-04,  8.4015e-02, -5.3595e-01, -1.0773e-02,\n",
      "           2.2031e-01, -3.8498e-01,  4.6772e-02],\n",
      "         [ 1.4269e-01, -3.0840e-04, -3.9566e-03, -6.4289e-01,  7.6703e-03,\n",
      "          -6.3565e-02,  4.7348e-01, -3.4137e-02],\n",
      "         [-1.4450e-01, -5.9369e-04,  1.2924e-01,  2.4726e-01, -1.1608e-02,\n",
      "          -1.0547e-01, -3.7662e-01, -1.2425e-02],\n",
      "         [-1.0781e-01, -3.3089e-04, -1.1632e-01,  1.9478e-01, -1.7184e-02,\n",
      "          -1.0187e-01, -2.6459e-01,  2.5443e-02],\n",
      "         [-1.1432e-01, -6.2426e-04,  1.2892e-01,  2.9334e-01, -1.2737e-02,\n",
      "          -1.0610e-01, -3.8267e-01, -1.0049e-02]],\n",
      "\n",
      "        [[ 1.7078e-01, -3.7921e-02, -8.7001e-02, -9.4889e-02, -5.6862e-01,\n",
      "           6.3925e-03,  4.1027e-01,  9.4136e-02],\n",
      "         [ 1.3294e-01, -1.1641e-02, -4.4392e-02, -6.6663e-02, -6.2991e-01,\n",
      "           4.6387e-03,  3.9057e-01,  1.0406e-01],\n",
      "         [-1.6559e-01, -7.0554e-02, -2.3218e-01, -1.3294e-01,  3.5105e-01,\n",
      "          -1.1598e-02, -1.7488e-01,  8.0153e-02],\n",
      "         [ 1.0182e-01,  4.7492e-02,  3.9469e-02, -1.6625e-02, -6.3354e-01,\n",
      "           3.7953e-04,  4.0383e-01, -2.1284e-02],\n",
      "         [ 6.0272e-02, -1.4368e-01, -1.4742e-01, -3.9993e-02,  3.9779e-01,\n",
      "           2.9805e-04, -3.5360e-01,  9.8486e-02],\n",
      "         [-2.0732e-01, -4.0423e-02,  5.6306e-02, -1.4748e-02, -2.9595e-01,\n",
      "          -3.4902e-02,  4.4113e-01, -8.2723e-02],\n",
      "         [-4.9601e-02, -4.3352e-02, -6.2432e-03, -4.3534e-03, -5.1146e-01,\n",
      "          -8.5033e-03,  4.3753e-01, -7.1027e-02],\n",
      "         [-8.8459e-02, -4.0524e-02,  4.9922e-02, -4.3955e-03, -4.8214e-01,\n",
      "          -2.3192e-02,  4.3794e-01, -6.9807e-02]]], device='cuda:0'), tensor([[[-2.1144e+00, -3.9284e-03, -4.1578e-02,  7.5421e-02,  1.8845e-02,\n",
      "           1.3149e-02,  1.6433e+00,  1.1641e-01],\n",
      "         [ 1.0656e+00, -1.0555e-02, -8.1226e-01, -1.1339e-01, -4.8479e-01,\n",
      "          -2.1765e-01,  1.9653e+00,  9.3539e-02],\n",
      "         [-1.9708e+00,  4.0186e-03,  8.7775e-02,  9.8506e-02, -2.6076e-01,\n",
      "           2.6518e-01,  1.5392e+00, -1.7510e-01],\n",
      "         [ 1.5980e+00,  6.9323e-04, -5.8963e-02, -8.8068e-02,  1.1541e-01,\n",
      "           6.1636e-02, -2.1320e+00,  1.9672e-01],\n",
      "         [ 9.7175e-02, -1.2258e-02, -9.0067e-01,  8.4514e-03, -2.5629e-01,\n",
      "           1.3809e-01,  2.2671e+00, -2.7336e-01],\n",
      "         [ 1.3658e+00, -3.2968e-03,  1.9855e-01,  8.7845e-02, -1.4006e-01,\n",
      "           9.4720e-02, -2.3353e+00,  6.9818e-02],\n",
      "         [-2.0751e+00,  3.5501e-03,  2.9532e-01, -1.3717e-03,  9.7392e-02,\n",
      "          -8.9750e-02,  1.6826e+00,  3.8214e-02],\n",
      "         [ 1.2702e+00,  2.1936e-03,  1.3879e-01,  8.0371e-02, -1.7104e-01,\n",
      "           2.4188e-01, -2.3249e+00, -3.2223e-02]],\n",
      "\n",
      "        [[ 7.6905e-01, -3.3661e-04, -9.8593e-02, -1.4729e+00,  7.9891e-03,\n",
      "          -4.0099e-02,  1.1594e+00, -1.7173e-02],\n",
      "         [ 1.6795e-01, -9.7107e-04, -9.5939e-03, -1.2147e+00,  2.2566e-02,\n",
      "          -7.1038e-02,  1.8186e+00, -1.1155e-01],\n",
      "         [ 1.0773e+00, -1.8978e-04, -8.7294e-02, -1.4115e+00, -6.3018e-03,\n",
      "          -9.8337e-02,  5.2174e-01,  4.4901e-02],\n",
      "         [ 4.2863e-01,  6.5274e-04,  2.6080e-01, -1.3025e+00, -2.5839e-02,\n",
      "           3.4538e-01, -1.0255e+00,  9.2975e-02],\n",
      "         [ 2.3009e-01, -7.0563e-04, -3.8305e-02, -1.2537e+00,  1.3578e-02,\n",
      "          -1.2142e-01,  1.8445e+00, -6.8556e-02],\n",
      "         [-4.1538e-01, -1.2048e-03,  1.6550e-01,  1.6261e+00, -2.8601e-02,\n",
      "          -2.0167e-01, -9.4624e-01, -2.4970e-02],\n",
      "         [-1.7487e-01, -6.6211e-04, -1.5328e-01,  1.7963e+00, -2.8164e-02,\n",
      "          -2.2492e-01, -6.0044e-01,  5.1205e-02],\n",
      "         [-3.8442e-01, -1.1477e-03,  1.6941e-01,  1.6131e+00, -3.1578e-02,\n",
      "          -2.0726e-01, -9.7236e-01, -2.0248e-02]],\n",
      "\n",
      "        [[ 2.4696e-01, -1.7208e-01, -3.4541e-01, -2.2653e-01, -1.4306e+00,\n",
      "           9.4850e-03,  1.2022e+00,  1.5235e-01],\n",
      "         [ 1.9610e-01, -4.3513e-02, -2.1215e-01, -1.8028e-01, -1.7042e+00,\n",
      "           7.4458e-03,  1.0747e+00,  1.5799e-01],\n",
      "         [-3.2858e-01, -4.7968e-01, -4.3529e-01, -1.9177e-01,  1.9190e+00,\n",
      "          -1.8955e-02, -3.5560e-01,  1.6233e-01],\n",
      "         [ 1.5224e-01,  1.3403e-01,  1.3743e-01, -4.6180e-02, -1.8176e+00,\n",
      "           5.0345e-04,  1.1873e+00, -4.6768e-02],\n",
      "         [ 1.4091e-01, -8.5326e-01, -2.9628e-01, -5.8831e-02,  1.6011e+00,\n",
      "           7.3917e-04, -8.2557e-01,  1.8131e-01],\n",
      "         [-4.0031e-01, -6.1539e-02,  1.1663e-01, -4.7155e-02, -5.3675e-01,\n",
      "          -4.9210e-02,  1.6315e+00, -1.5532e-01],\n",
      "         [-8.3223e-02, -7.7332e-02, -1.3573e-02, -1.3802e-02, -1.0932e+00,\n",
      "          -1.2443e-02,  1.5820e+00, -1.2399e-01],\n",
      "         [-1.5233e-01, -6.3871e-02,  1.1590e-01, -1.5403e-02, -1.0542e+00,\n",
      "          -3.2286e-02,  1.5652e+00, -1.3323e-01]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cpp]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out1 = model_cpp(inputs, hidden)\n",
    "    print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:34.315417Z",
     "start_time": "2019-02-09T06:29:34.305418Z"
    },
    "hidden": true,
    "tags": [
     "#forward-test-3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.4017e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out1[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:34.615427Z",
     "start_time": "2019-02-09T06:29:34.317419Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_cuda]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[-0.1924,  0.1772,  0.1920,  0.2721, -0.0711, -0.1628],\n",
      "         [-0.2024,  0.1879,  0.1943,  0.2760, -0.0489, -0.1875],\n",
      "         [-0.1229,  0.1609,  0.1858,  0.2821, -0.0407, -0.1944],\n",
      "         [-0.0112,  0.1333,  0.1726,  0.2726,  0.0202, -0.1900],\n",
      "         [ 0.0533,  0.1244,  0.1589,  0.2618,  0.0700, -0.1806],\n",
      "         [ 0.0826,  0.1220,  0.1525,  0.2573,  0.0941, -0.1707],\n",
      "         [ 0.0963,  0.1217,  0.1496,  0.2545,  0.1071, -0.1642],\n",
      "         [ 0.1030,  0.1223,  0.1476,  0.2525,  0.1137, -0.1604],\n",
      "         [ 0.1066,  0.1231,  0.1467,  0.2511,  0.1187, -0.1579],\n",
      "         [ 0.1106,  0.1223,  0.1481,  0.2506,  0.1226, -0.1558],\n",
      "         [ 0.1134,  0.1222,  0.1468,  0.2510,  0.1222, -0.1538],\n",
      "         [ 0.1126,  0.1238,  0.1463,  0.2496,  0.1254, -0.1539],\n",
      "         [ 0.1144,  0.1233,  0.1477,  0.2496,  0.1276, -0.1530],\n",
      "         [ 0.1151,  0.1237,  0.1462,  0.2497,  0.1265, -0.1527],\n",
      "         [ 0.1138,  0.1255,  0.1473,  0.2484,  0.1320, -0.1526],\n",
      "         [ 0.1148,  0.1258,  0.1472,  0.2487,  0.1335, -0.1517],\n",
      "         [ 0.1163,  0.1255,  0.1461,  0.2493,  0.1317, -0.1508],\n",
      "         [ 0.1152,  0.1271,  0.1462,  0.2485,  0.1353, -0.1506],\n",
      "         [ 0.1166,  0.1275,  0.1462,  0.2487,  0.1366, -0.1491],\n",
      "         [ 0.1161,  0.1291,  0.1453,  0.2482,  0.1391, -0.1483]],\n",
      "\n",
      "        [[-0.3093,  0.3269,  0.0712,  0.1895,  0.0944, -0.2019],\n",
      "         [-0.3480,  0.3216,  0.1167,  0.2166,  0.0831, -0.2145],\n",
      "         [-0.3773,  0.3332,  0.1193,  0.2227,  0.0880, -0.2418],\n",
      "         [-0.3910,  0.3448,  0.1137,  0.2326,  0.1015, -0.2603],\n",
      "         [-0.3862,  0.3537,  0.0975,  0.2449,  0.1149, -0.2722],\n",
      "         [-0.3548,  0.3456,  0.0845,  0.2624,  0.1211, -0.2808],\n",
      "         [-0.2792,  0.3099,  0.0848,  0.2759,  0.1324, -0.2805],\n",
      "         [-0.1489,  0.2594,  0.0803,  0.2704,  0.1538, -0.2599],\n",
      "         [-0.0244,  0.2136,  0.0824,  0.2577,  0.1589, -0.2138],\n",
      "         [ 0.0333,  0.1928,  0.0881,  0.2481,  0.1693, -0.1884],\n",
      "         [ 0.0693,  0.1707,  0.1022,  0.2457,  0.1610, -0.1694],\n",
      "         [ 0.0926,  0.1517,  0.1166,  0.2465,  0.1487, -0.1571],\n",
      "         [ 0.1044,  0.1400,  0.1259,  0.2474,  0.1369, -0.1507],\n",
      "         [ 0.1102,  0.1332,  0.1316,  0.2476,  0.1297, -0.1490],\n",
      "         [ 0.1122,  0.1298,  0.1347,  0.2478,  0.1248, -0.1488],\n",
      "         [ 0.1165,  0.1252,  0.1396,  0.2480,  0.1229, -0.1479],\n",
      "         [ 0.1193,  0.1219,  0.1418,  0.2487,  0.1187, -0.1478],\n",
      "         [ 0.1205,  0.1206,  0.1433,  0.2503,  0.1178, -0.1471],\n",
      "         [ 0.1219,  0.1189,  0.1457,  0.2504,  0.1184, -0.1469],\n",
      "         [ 0.1210,  0.1193,  0.1448,  0.2507,  0.1173, -0.1478]],\n",
      "\n",
      "        [[ 0.0540,  0.2297,  0.0942,  0.1879,  0.3388, -0.0460],\n",
      "         [ 0.0847,  0.2271,  0.0972,  0.1678,  0.3563, -0.0160],\n",
      "         [ 0.0952,  0.2343,  0.0896,  0.1541,  0.3666, -0.0025],\n",
      "         [ 0.0956,  0.2477,  0.0769,  0.1440,  0.3810,  0.0042],\n",
      "         [ 0.0904,  0.2666,  0.0598,  0.1332,  0.4027,  0.0086],\n",
      "         [ 0.0790,  0.2862,  0.0450,  0.1210,  0.4252,  0.0097],\n",
      "         [ 0.0660,  0.3176,  0.0149,  0.1046,  0.4613,  0.0121],\n",
      "         [ 0.0423,  0.3537, -0.0174,  0.0840,  0.4960,  0.0081],\n",
      "         [ 0.0060,  0.3958, -0.0503,  0.0600,  0.5330, -0.0027],\n",
      "         [-0.0318,  0.4429, -0.0850,  0.0353,  0.5769, -0.0107],\n",
      "         [-0.0772,  0.4842, -0.1102,  0.0185,  0.6054, -0.0239],\n",
      "         [-0.1218,  0.5152, -0.1271,  0.0125,  0.6147, -0.0361],\n",
      "         [-0.1476,  0.5147, -0.1156,  0.0302,  0.5755, -0.0288],\n",
      "         [-0.1974,  0.5056, -0.0911,  0.0480,  0.5218, -0.0458],\n",
      "         [-0.2293,  0.4863, -0.0577,  0.0729,  0.4591, -0.0517],\n",
      "         [-0.2561,  0.4740, -0.0331,  0.0872,  0.4204, -0.0618],\n",
      "         [-0.2586,  0.4612, -0.0131,  0.1017,  0.3915, -0.0537],\n",
      "         [-0.2699,  0.4635, -0.0090,  0.1037,  0.3899, -0.0635],\n",
      "         [-0.2780,  0.4610, -0.0038,  0.1063,  0.3833, -0.0693],\n",
      "         [-0.2860,  0.4504,  0.0087,  0.1118,  0.3640, -0.0743]],\n",
      "\n",
      "        [[-0.3371,  0.3528,  0.0549,  0.1787,  0.1194, -0.2123],\n",
      "         [-0.4075,  0.3747,  0.0868,  0.1939,  0.1291, -0.2288],\n",
      "         [-0.4446,  0.3926,  0.0861,  0.1900,  0.1423, -0.2547],\n",
      "         [-0.4636,  0.4110,  0.0743,  0.1913,  0.1672, -0.2687],\n",
      "         [-0.4738,  0.4324,  0.0534,  0.1948,  0.1982, -0.2790],\n",
      "         [-0.4687,  0.4474,  0.0331,  0.2020,  0.2276, -0.2808],\n",
      "         [-0.4578,  0.4701, -0.0011,  0.2097,  0.2709, -0.2845],\n",
      "         [-0.4062,  0.4764, -0.0372,  0.2203,  0.3151, -0.2763],\n",
      "         [-0.3297,  0.4801, -0.0914,  0.2215,  0.3794, -0.2946],\n",
      "         [-0.1721,  0.4222, -0.0963,  0.2105,  0.3808, -0.2405],\n",
      "         [-0.0352,  0.3194, -0.0269,  0.2237,  0.3014, -0.1759],\n",
      "         [ 0.0242,  0.2630,  0.0203,  0.2320,  0.2668, -0.1617],\n",
      "         [ 0.0617,  0.2162,  0.0635,  0.2408,  0.2295, -0.1509],\n",
      "         [ 0.0854,  0.1812,  0.0972,  0.2481,  0.1977, -0.1434],\n",
      "         [ 0.1015,  0.1561,  0.1224,  0.2525,  0.1745, -0.1379],\n",
      "         [ 0.1104,  0.1387,  0.1402,  0.2588,  0.1569, -0.1377],\n",
      "         [ 0.1163,  0.1258,  0.1540,  0.2630,  0.1439, -0.1369],\n",
      "         [ 0.1188,  0.1183,  0.1625,  0.2663,  0.1354, -0.1375],\n",
      "         [ 0.1214,  0.1110,  0.1715,  0.2684,  0.1304, -0.1373],\n",
      "         [ 0.1256,  0.1034,  0.1797,  0.2714,  0.1256, -0.1361]],\n",
      "\n",
      "        [[-0.1599,  0.3311, -0.0024,  0.1483,  0.2346, -0.1685],\n",
      "         [-0.1950,  0.3680, -0.0024,  0.1300,  0.2878, -0.1616],\n",
      "         [-0.2795,  0.4266, -0.0081,  0.1149,  0.3327, -0.1670],\n",
      "         [-0.3498,  0.4580,  0.0069,  0.1262,  0.3249, -0.1567],\n",
      "         [-0.3714,  0.4598,  0.0245,  0.1345,  0.3131, -0.1424],\n",
      "         [-0.3688,  0.4479,  0.0397,  0.1397,  0.3006, -0.1303],\n",
      "         [-0.3621,  0.4373,  0.0496,  0.1415,  0.2929, -0.1213],\n",
      "         [-0.3613,  0.4321,  0.0538,  0.1373,  0.2897, -0.1185],\n",
      "         [-0.3587,  0.4262,  0.0587,  0.1362,  0.2826, -0.1155],\n",
      "         [-0.3626,  0.4228,  0.0627,  0.1316,  0.2756, -0.1168],\n",
      "         [-0.3644,  0.4173,  0.0694,  0.1319,  0.2631, -0.1170],\n",
      "         [-0.3674,  0.4121,  0.0770,  0.1338,  0.2529, -0.1194],\n",
      "         [-0.3724,  0.4099,  0.0808,  0.1320,  0.2521, -0.1248],\n",
      "         [-0.3743,  0.4070,  0.0842,  0.1315,  0.2498, -0.1281],\n",
      "         [-0.3770,  0.4038,  0.0877,  0.1298,  0.2461, -0.1317],\n",
      "         [-0.3798,  0.3970,  0.0960,  0.1322,  0.2314, -0.1349],\n",
      "         [-0.3878,  0.3883,  0.1088,  0.1359,  0.2115, -0.1431],\n",
      "         [-0.3949,  0.3911,  0.1078,  0.1335,  0.2252, -0.1521],\n",
      "         [-0.3929,  0.3807,  0.1187,  0.1401,  0.2050, -0.1546],\n",
      "         [-0.3982,  0.3840,  0.1160,  0.1369,  0.2192, -0.1618]],\n",
      "\n",
      "        [[-0.3663,  0.4274,  0.0439,  0.1573,  0.4143, -0.3325],\n",
      "         [-0.2349,  0.3073,  0.1398,  0.1812,  0.3786, -0.2512],\n",
      "         [-0.1056,  0.2505,  0.1552,  0.1798,  0.3654, -0.1657],\n",
      "         [-0.0024,  0.2186,  0.1545,  0.1713,  0.3460, -0.0789],\n",
      "         [ 0.0471,  0.2245,  0.1286,  0.1599,  0.3428, -0.0335],\n",
      "         [ 0.0641,  0.2421,  0.1012,  0.1514,  0.3505, -0.0177],\n",
      "         [ 0.0710,  0.2532,  0.0847,  0.1491,  0.3565, -0.0143],\n",
      "         [ 0.0729,  0.2589,  0.0758,  0.1493,  0.3588, -0.0152],\n",
      "         [ 0.0723,  0.2605,  0.0723,  0.1533,  0.3578, -0.0196],\n",
      "         [ 0.0784,  0.2498,  0.0782,  0.1587,  0.3459, -0.0216],\n",
      "         [ 0.0837,  0.2437,  0.0812,  0.1619,  0.3384, -0.0196],\n",
      "         [ 0.0881,  0.2376,  0.0854,  0.1654,  0.3307, -0.0188],\n",
      "         [ 0.0926,  0.2318,  0.0895,  0.1686,  0.3232, -0.0181],\n",
      "         [ 0.0961,  0.2281,  0.0920,  0.1709,  0.3178, -0.0174],\n",
      "         [ 0.0992,  0.2244,  0.0945,  0.1738,  0.3123, -0.0177],\n",
      "         [ 0.1060,  0.2170,  0.0982,  0.1798,  0.3023, -0.0188],\n",
      "         [ 0.1098,  0.2145,  0.0986,  0.1814,  0.2983, -0.0172],\n",
      "         [ 0.1118,  0.2114,  0.1004,  0.1843,  0.2934, -0.0186],\n",
      "         [ 0.1139,  0.2078,  0.1029,  0.1872,  0.2883, -0.0196],\n",
      "         [ 0.1153,  0.2047,  0.1056,  0.1903,  0.2832, -0.0211]],\n",
      "\n",
      "        [[ 0.0458,  0.1051,  0.2396,  0.1994,  0.1965, -0.0887],\n",
      "         [ 0.1330,  0.1297,  0.1845,  0.2053,  0.2261, -0.0160],\n",
      "         [ 0.1574,  0.1455,  0.1533,  0.2060,  0.2315, -0.0028],\n",
      "         [ 0.1617,  0.1557,  0.1389,  0.2083,  0.2325, -0.0054],\n",
      "         [ 0.1608,  0.1590,  0.1349,  0.2124,  0.2286, -0.0126],\n",
      "         [ 0.1594,  0.1588,  0.1354,  0.2181,  0.2223, -0.0206],\n",
      "         [ 0.1592,  0.1539,  0.1390,  0.2228,  0.2129, -0.0276],\n",
      "         [ 0.1597,  0.1489,  0.1436,  0.2274,  0.2049, -0.0324],\n",
      "         [ 0.1599,  0.1440,  0.1485,  0.2313,  0.1975, -0.0365],\n",
      "         [ 0.1616,  0.1372,  0.1538,  0.2362,  0.1882, -0.0404],\n",
      "         [ 0.1617,  0.1352,  0.1558,  0.2383,  0.1845, -0.0434],\n",
      "         [ 0.1593,  0.1357,  0.1558,  0.2373,  0.1840, -0.0467],\n",
      "         [ 0.1557,  0.1388,  0.1552,  0.2361,  0.1861, -0.0490],\n",
      "         [ 0.1549,  0.1389,  0.1560,  0.2389,  0.1841, -0.0523],\n",
      "         [ 0.1538,  0.1388,  0.1557,  0.2382,  0.1837, -0.0537],\n",
      "         [ 0.1521,  0.1405,  0.1549,  0.2374,  0.1855, -0.0545],\n",
      "         [ 0.1498,  0.1431,  0.1548,  0.2376,  0.1874, -0.0553],\n",
      "         [ 0.1488,  0.1445,  0.1541,  0.2378,  0.1885, -0.0565],\n",
      "         [ 0.1476,  0.1460,  0.1525,  0.2362,  0.1902, -0.0560],\n",
      "         [ 0.1506,  0.1429,  0.1539,  0.2381,  0.1871, -0.0547]],\n",
      "\n",
      "        [[ 0.0373,  0.1055,  0.2312,  0.2289,  0.1674, -0.1129],\n",
      "         [ 0.1607,  0.0963,  0.1980,  0.2325,  0.1752, -0.0225],\n",
      "         [ 0.1881,  0.1057,  0.1731,  0.2335,  0.1756, -0.0129],\n",
      "         [ 0.1893,  0.1120,  0.1640,  0.2370,  0.1733, -0.0223],\n",
      "         [ 0.1836,  0.1115,  0.1653,  0.2430,  0.1646, -0.0368],\n",
      "         [ 0.1770,  0.1106,  0.1680,  0.2456,  0.1596, -0.0479],\n",
      "         [ 0.1717,  0.1107,  0.1703,  0.2478,  0.1568, -0.0558],\n",
      "         [ 0.1632,  0.1157,  0.1686,  0.2470,  0.1598, -0.0624],\n",
      "         [ 0.1626,  0.1135,  0.1709,  0.2504,  0.1553, -0.0651],\n",
      "         [ 0.1590,  0.1159,  0.1699,  0.2489,  0.1578, -0.0668],\n",
      "         [ 0.1599,  0.1141,  0.1711,  0.2512,  0.1552, -0.0668],\n",
      "         [ 0.1549,  0.1199,  0.1676,  0.2481,  0.1622, -0.0666],\n",
      "         [ 0.1521,  0.1241,  0.1649,  0.2458,  0.1678, -0.0644],\n",
      "         [ 0.1496,  0.1288,  0.1616,  0.2443,  0.1733, -0.0619],\n",
      "         [ 0.1496,  0.1312,  0.1596,  0.2419,  0.1775, -0.0582],\n",
      "         [ 0.1510,  0.1320,  0.1577,  0.2424,  0.1785, -0.0570],\n",
      "         [ 0.1514,  0.1326,  0.1570,  0.2412,  0.1802, -0.0553],\n",
      "         [ 0.1504,  0.1358,  0.1555,  0.2371,  0.1857, -0.0513],\n",
      "         [ 0.1509,  0.1376,  0.1536,  0.2366,  0.1877, -0.0499],\n",
      "         [ 0.1483,  0.1423,  0.1511,  0.2330,  0.1940, -0.0472]]],\n",
      "       device='cuda:0'), (tensor([[[-5.2217e-01, -1.1236e-03, -1.2801e-02,  4.5314e-02,  1.0696e-02,\n",
      "           7.6920e-03,  1.3954e-01,  7.5384e-02],\n",
      "         [ 4.3892e-01, -7.2033e-03, -2.3726e-01, -6.5286e-02, -1.3376e-01,\n",
      "          -1.0229e-01,  1.7927e-01,  4.9708e-02],\n",
      "         [-5.1896e-01,  3.2933e-03,  3.6618e-02,  2.8058e-02, -9.3617e-02,\n",
      "           1.4323e-01,  4.9164e-01, -6.5861e-02],\n",
      "         [ 4.3159e-01,  4.0894e-04, -4.6276e-02, -5.5760e-02,  6.4458e-02,\n",
      "           1.4291e-02, -6.2669e-01,  6.7342e-02],\n",
      "         [ 4.4172e-02, -9.6873e-03, -1.7931e-01,  2.8432e-03, -1.5870e-01,\n",
      "           8.3298e-02,  5.2621e-01, -1.6443e-01],\n",
      "         [ 4.1071e-01, -2.4306e-03,  2.9700e-02,  5.3761e-02, -7.3411e-02,\n",
      "           3.3684e-02, -6.0949e-01,  4.5786e-02],\n",
      "         [-5.5558e-01,  1.8244e-03,  1.6906e-01, -5.9008e-04,  2.4987e-02,\n",
      "          -4.6794e-02,  4.3210e-01,  1.3903e-02],\n",
      "         [ 3.7426e-01,  1.6717e-03,  4.3125e-02,  3.6186e-02, -1.0372e-01,\n",
      "           1.0293e-01, -7.4226e-01, -1.8094e-02]],\n",
      "\n",
      "        [[ 3.0063e-01, -2.1729e-04, -1.4830e-02, -6.5788e-01,  4.3874e-03,\n",
      "          -1.6909e-02,  4.0584e-01, -8.7769e-03],\n",
      "         [ 1.1392e-01, -3.5901e-04, -1.0953e-03, -5.4127e-01,  1.1149e-02,\n",
      "          -3.5242e-02,  4.8017e-01, -5.6344e-02],\n",
      "         [ 3.8739e-01, -1.1109e-04, -1.5600e-02, -6.5556e-01, -3.7146e-03,\n",
      "          -5.0859e-02,  2.3491e-01,  2.2417e-02],\n",
      "         [ 1.0253e-01,  4.0264e-04,  8.4015e-02, -5.3595e-01, -1.0773e-02,\n",
      "           2.2031e-01, -3.8498e-01,  4.6772e-02],\n",
      "         [ 1.4269e-01, -3.0840e-04, -3.9566e-03, -6.4289e-01,  7.6703e-03,\n",
      "          -6.3565e-02,  4.7348e-01, -3.4137e-02],\n",
      "         [-1.4450e-01, -5.9369e-04,  1.2924e-01,  2.4726e-01, -1.1608e-02,\n",
      "          -1.0547e-01, -3.7662e-01, -1.2425e-02],\n",
      "         [-1.0781e-01, -3.3089e-04, -1.1632e-01,  1.9478e-01, -1.7184e-02,\n",
      "          -1.0187e-01, -2.6459e-01,  2.5443e-02],\n",
      "         [-1.1432e-01, -6.2426e-04,  1.2892e-01,  2.9334e-01, -1.2737e-02,\n",
      "          -1.0610e-01, -3.8267e-01, -1.0049e-02]],\n",
      "\n",
      "        [[ 1.7078e-01, -3.7921e-02, -8.7001e-02, -9.4889e-02, -5.6862e-01,\n",
      "           6.3925e-03,  4.1027e-01,  9.4136e-02],\n",
      "         [ 1.3294e-01, -1.1641e-02, -4.4392e-02, -6.6663e-02, -6.2991e-01,\n",
      "           4.6387e-03,  3.9057e-01,  1.0406e-01],\n",
      "         [-1.6559e-01, -7.0554e-02, -2.3218e-01, -1.3294e-01,  3.5105e-01,\n",
      "          -1.1598e-02, -1.7488e-01,  8.0153e-02],\n",
      "         [ 1.0182e-01,  4.7492e-02,  3.9469e-02, -1.6625e-02, -6.3354e-01,\n",
      "           3.7953e-04,  4.0383e-01, -2.1284e-02],\n",
      "         [ 6.0272e-02, -1.4368e-01, -1.4742e-01, -3.9993e-02,  3.9779e-01,\n",
      "           2.9805e-04, -3.5360e-01,  9.8486e-02],\n",
      "         [-2.0732e-01, -4.0423e-02,  5.6306e-02, -1.4748e-02, -2.9595e-01,\n",
      "          -3.4902e-02,  4.4113e-01, -8.2723e-02],\n",
      "         [-4.9601e-02, -4.3352e-02, -6.2432e-03, -4.3534e-03, -5.1146e-01,\n",
      "          -8.5033e-03,  4.3753e-01, -7.1027e-02],\n",
      "         [-8.8459e-02, -4.0524e-02,  4.9922e-02, -4.3955e-03, -4.8214e-01,\n",
      "          -2.3192e-02,  4.3794e-01, -6.9807e-02]]], device='cuda:0'), tensor([[[-2.1144e+00, -3.9284e-03, -4.1578e-02,  7.5421e-02,  1.8845e-02,\n",
      "           1.3149e-02,  1.6433e+00,  1.1641e-01],\n",
      "         [ 1.0656e+00, -1.0555e-02, -8.1226e-01, -1.1339e-01, -4.8479e-01,\n",
      "          -2.1765e-01,  1.9653e+00,  9.3539e-02],\n",
      "         [-1.9708e+00,  4.0186e-03,  8.7776e-02,  9.8506e-02, -2.6076e-01,\n",
      "           2.6518e-01,  1.5392e+00, -1.7510e-01],\n",
      "         [ 1.5980e+00,  6.9323e-04, -5.8963e-02, -8.8068e-02,  1.1541e-01,\n",
      "           6.1635e-02, -2.1320e+00,  1.9672e-01],\n",
      "         [ 9.7175e-02, -1.2258e-02, -9.0067e-01,  8.4514e-03, -2.5629e-01,\n",
      "           1.3809e-01,  2.2671e+00, -2.7336e-01],\n",
      "         [ 1.3658e+00, -3.2968e-03,  1.9855e-01,  8.7845e-02, -1.4006e-01,\n",
      "           9.4720e-02, -2.3353e+00,  6.9818e-02],\n",
      "         [-2.0751e+00,  3.5501e-03,  2.9532e-01, -1.3717e-03,  9.7392e-02,\n",
      "          -8.9750e-02,  1.6826e+00,  3.8214e-02],\n",
      "         [ 1.2702e+00,  2.1936e-03,  1.3879e-01,  8.0371e-02, -1.7104e-01,\n",
      "           2.4188e-01, -2.3249e+00, -3.2223e-02]],\n",
      "\n",
      "        [[ 7.6905e-01, -3.3661e-04, -9.8593e-02, -1.4729e+00,  7.9891e-03,\n",
      "          -4.0098e-02,  1.1594e+00, -1.7173e-02],\n",
      "         [ 1.6795e-01, -9.7107e-04, -9.5939e-03, -1.2147e+00,  2.2566e-02,\n",
      "          -7.1038e-02,  1.8186e+00, -1.1155e-01],\n",
      "         [ 1.0773e+00, -1.8978e-04, -8.7294e-02, -1.4115e+00, -6.3018e-03,\n",
      "          -9.8337e-02,  5.2174e-01,  4.4901e-02],\n",
      "         [ 4.2863e-01,  6.5274e-04,  2.6080e-01, -1.3025e+00, -2.5839e-02,\n",
      "           3.4538e-01, -1.0255e+00,  9.2975e-02],\n",
      "         [ 2.3009e-01, -7.0563e-04, -3.8305e-02, -1.2537e+00,  1.3578e-02,\n",
      "          -1.2142e-01,  1.8445e+00, -6.8556e-02],\n",
      "         [-4.1538e-01, -1.2048e-03,  1.6550e-01,  1.6261e+00, -2.8601e-02,\n",
      "          -2.0167e-01, -9.4624e-01, -2.4970e-02],\n",
      "         [-1.7487e-01, -6.6211e-04, -1.5328e-01,  1.7963e+00, -2.8164e-02,\n",
      "          -2.2492e-01, -6.0044e-01,  5.1205e-02],\n",
      "         [-3.8442e-01, -1.1477e-03,  1.6941e-01,  1.6131e+00, -3.1578e-02,\n",
      "          -2.0726e-01, -9.7236e-01, -2.0248e-02]],\n",
      "\n",
      "        [[ 2.4696e-01, -1.7208e-01, -3.4541e-01, -2.2653e-01, -1.4306e+00,\n",
      "           9.4850e-03,  1.2022e+00,  1.5235e-01],\n",
      "         [ 1.9610e-01, -4.3513e-02, -2.1215e-01, -1.8028e-01, -1.7042e+00,\n",
      "           7.4458e-03,  1.0747e+00,  1.5799e-01],\n",
      "         [-3.2858e-01, -4.7968e-01, -4.3529e-01, -1.9177e-01,  1.9190e+00,\n",
      "          -1.8955e-02, -3.5560e-01,  1.6233e-01],\n",
      "         [ 1.5224e-01,  1.3403e-01,  1.3743e-01, -4.6180e-02, -1.8176e+00,\n",
      "           5.0345e-04,  1.1873e+00, -4.6768e-02],\n",
      "         [ 1.4091e-01, -8.5326e-01, -2.9628e-01, -5.8831e-02,  1.6011e+00,\n",
      "           7.3917e-04, -8.2557e-01,  1.8131e-01],\n",
      "         [-4.0031e-01, -6.1539e-02,  1.1663e-01, -4.7155e-02, -5.3675e-01,\n",
      "          -4.9210e-02,  1.6315e+00, -1.5532e-01],\n",
      "         [-8.3223e-02, -7.7332e-02, -1.3573e-02, -1.3802e-02, -1.0932e+00,\n",
      "          -1.2443e-02,  1.5820e+00, -1.2399e-01],\n",
      "         [-1.5233e-01, -6.3871e-02,  1.1590e-01, -1.5403e-02, -1.0542e+00,\n",
      "          -3.2286e-02,  1.5652e+00, -1.3323e-01]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cuda]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out2 = model_cuda(inputs, hidden)\n",
    "    print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:34.626446Z",
     "start_time": "2019-02-09T06:29:34.617418Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7460e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out2[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:35.061434Z",
     "start_time": "2019-02-09T06:29:34.628421Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_cuda_less_mem]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[-0.1924,  0.1772,  0.1920,  0.2721, -0.0711, -0.1628],\n",
      "         [-0.2024,  0.1879,  0.1943,  0.2760, -0.0489, -0.1875],\n",
      "         [-0.1229,  0.1609,  0.1858,  0.2821, -0.0407, -0.1944],\n",
      "         [-0.0112,  0.1333,  0.1726,  0.2726,  0.0202, -0.1900],\n",
      "         [ 0.0533,  0.1244,  0.1589,  0.2618,  0.0700, -0.1806],\n",
      "         [ 0.0826,  0.1220,  0.1525,  0.2573,  0.0941, -0.1707],\n",
      "         [ 0.0963,  0.1217,  0.1496,  0.2545,  0.1071, -0.1642],\n",
      "         [ 0.1030,  0.1223,  0.1476,  0.2525,  0.1137, -0.1604],\n",
      "         [ 0.1066,  0.1231,  0.1467,  0.2511,  0.1187, -0.1579],\n",
      "         [ 0.1106,  0.1223,  0.1481,  0.2506,  0.1226, -0.1558],\n",
      "         [ 0.1134,  0.1222,  0.1468,  0.2510,  0.1222, -0.1538],\n",
      "         [ 0.1126,  0.1238,  0.1463,  0.2496,  0.1254, -0.1539],\n",
      "         [ 0.1144,  0.1233,  0.1477,  0.2496,  0.1276, -0.1530],\n",
      "         [ 0.1151,  0.1237,  0.1462,  0.2497,  0.1265, -0.1527],\n",
      "         [ 0.1138,  0.1255,  0.1473,  0.2484,  0.1320, -0.1526],\n",
      "         [ 0.1148,  0.1258,  0.1472,  0.2487,  0.1335, -0.1517],\n",
      "         [ 0.1163,  0.1255,  0.1461,  0.2493,  0.1317, -0.1508],\n",
      "         [ 0.1152,  0.1271,  0.1462,  0.2485,  0.1353, -0.1506],\n",
      "         [ 0.1166,  0.1275,  0.1462,  0.2487,  0.1366, -0.1491],\n",
      "         [ 0.1161,  0.1291,  0.1453,  0.2482,  0.1391, -0.1483]],\n",
      "\n",
      "        [[-0.3093,  0.3269,  0.0712,  0.1895,  0.0944, -0.2019],\n",
      "         [-0.3480,  0.3216,  0.1167,  0.2166,  0.0831, -0.2145],\n",
      "         [-0.3773,  0.3332,  0.1193,  0.2227,  0.0880, -0.2418],\n",
      "         [-0.3910,  0.3448,  0.1137,  0.2326,  0.1015, -0.2603],\n",
      "         [-0.3862,  0.3537,  0.0975,  0.2449,  0.1149, -0.2722],\n",
      "         [-0.3548,  0.3456,  0.0845,  0.2624,  0.1211, -0.2808],\n",
      "         [-0.2792,  0.3099,  0.0848,  0.2759,  0.1324, -0.2805],\n",
      "         [-0.1489,  0.2594,  0.0803,  0.2704,  0.1538, -0.2599],\n",
      "         [-0.0244,  0.2136,  0.0824,  0.2577,  0.1589, -0.2138],\n",
      "         [ 0.0333,  0.1928,  0.0881,  0.2481,  0.1693, -0.1884],\n",
      "         [ 0.0693,  0.1707,  0.1022,  0.2457,  0.1610, -0.1694],\n",
      "         [ 0.0926,  0.1517,  0.1166,  0.2465,  0.1487, -0.1571],\n",
      "         [ 0.1044,  0.1400,  0.1259,  0.2474,  0.1369, -0.1507],\n",
      "         [ 0.1102,  0.1332,  0.1316,  0.2476,  0.1297, -0.1490],\n",
      "         [ 0.1122,  0.1298,  0.1347,  0.2478,  0.1248, -0.1488],\n",
      "         [ 0.1165,  0.1252,  0.1396,  0.2480,  0.1229, -0.1479],\n",
      "         [ 0.1193,  0.1219,  0.1418,  0.2487,  0.1187, -0.1478],\n",
      "         [ 0.1205,  0.1206,  0.1433,  0.2503,  0.1178, -0.1471],\n",
      "         [ 0.1219,  0.1189,  0.1457,  0.2504,  0.1184, -0.1469],\n",
      "         [ 0.1210,  0.1193,  0.1448,  0.2507,  0.1173, -0.1478]],\n",
      "\n",
      "        [[ 0.0540,  0.2297,  0.0942,  0.1879,  0.3388, -0.0460],\n",
      "         [ 0.0847,  0.2271,  0.0972,  0.1678,  0.3563, -0.0160],\n",
      "         [ 0.0952,  0.2343,  0.0896,  0.1541,  0.3666, -0.0025],\n",
      "         [ 0.0956,  0.2477,  0.0769,  0.1440,  0.3810,  0.0042],\n",
      "         [ 0.0904,  0.2666,  0.0598,  0.1332,  0.4027,  0.0086],\n",
      "         [ 0.0790,  0.2862,  0.0450,  0.1210,  0.4252,  0.0097],\n",
      "         [ 0.0660,  0.3176,  0.0149,  0.1046,  0.4613,  0.0121],\n",
      "         [ 0.0423,  0.3537, -0.0174,  0.0840,  0.4960,  0.0081],\n",
      "         [ 0.0060,  0.3958, -0.0503,  0.0600,  0.5330, -0.0027],\n",
      "         [-0.0318,  0.4429, -0.0850,  0.0353,  0.5769, -0.0107],\n",
      "         [-0.0772,  0.4842, -0.1102,  0.0185,  0.6054, -0.0239],\n",
      "         [-0.1218,  0.5152, -0.1271,  0.0125,  0.6147, -0.0361],\n",
      "         [-0.1476,  0.5147, -0.1156,  0.0302,  0.5755, -0.0288],\n",
      "         [-0.1974,  0.5056, -0.0911,  0.0480,  0.5218, -0.0458],\n",
      "         [-0.2293,  0.4863, -0.0577,  0.0729,  0.4591, -0.0517],\n",
      "         [-0.2561,  0.4740, -0.0331,  0.0872,  0.4204, -0.0618],\n",
      "         [-0.2586,  0.4612, -0.0131,  0.1017,  0.3915, -0.0537],\n",
      "         [-0.2699,  0.4635, -0.0090,  0.1037,  0.3899, -0.0635],\n",
      "         [-0.2780,  0.4610, -0.0038,  0.1063,  0.3833, -0.0693],\n",
      "         [-0.2860,  0.4504,  0.0087,  0.1118,  0.3640, -0.0743]],\n",
      "\n",
      "        [[-0.3371,  0.3528,  0.0549,  0.1787,  0.1194, -0.2123],\n",
      "         [-0.4075,  0.3747,  0.0868,  0.1939,  0.1291, -0.2288],\n",
      "         [-0.4446,  0.3926,  0.0861,  0.1900,  0.1423, -0.2547],\n",
      "         [-0.4636,  0.4110,  0.0743,  0.1913,  0.1672, -0.2687],\n",
      "         [-0.4738,  0.4324,  0.0534,  0.1948,  0.1982, -0.2790],\n",
      "         [-0.4687,  0.4474,  0.0331,  0.2020,  0.2276, -0.2808],\n",
      "         [-0.4578,  0.4701, -0.0011,  0.2097,  0.2709, -0.2845],\n",
      "         [-0.4062,  0.4764, -0.0372,  0.2203,  0.3151, -0.2763],\n",
      "         [-0.3297,  0.4801, -0.0914,  0.2215,  0.3794, -0.2946],\n",
      "         [-0.1721,  0.4222, -0.0963,  0.2105,  0.3808, -0.2405],\n",
      "         [-0.0352,  0.3194, -0.0269,  0.2237,  0.3014, -0.1759],\n",
      "         [ 0.0242,  0.2630,  0.0203,  0.2320,  0.2668, -0.1617],\n",
      "         [ 0.0617,  0.2162,  0.0635,  0.2408,  0.2295, -0.1509],\n",
      "         [ 0.0854,  0.1812,  0.0972,  0.2481,  0.1977, -0.1434],\n",
      "         [ 0.1015,  0.1561,  0.1224,  0.2525,  0.1745, -0.1379],\n",
      "         [ 0.1104,  0.1387,  0.1402,  0.2588,  0.1569, -0.1377],\n",
      "         [ 0.1163,  0.1258,  0.1540,  0.2630,  0.1439, -0.1369],\n",
      "         [ 0.1188,  0.1183,  0.1625,  0.2663,  0.1354, -0.1375],\n",
      "         [ 0.1214,  0.1110,  0.1715,  0.2684,  0.1304, -0.1373],\n",
      "         [ 0.1256,  0.1034,  0.1797,  0.2714,  0.1256, -0.1361]],\n",
      "\n",
      "        [[-0.1599,  0.3311, -0.0024,  0.1483,  0.2346, -0.1685],\n",
      "         [-0.1950,  0.3680, -0.0024,  0.1300,  0.2878, -0.1616],\n",
      "         [-0.2795,  0.4266, -0.0081,  0.1149,  0.3327, -0.1670],\n",
      "         [-0.3498,  0.4580,  0.0069,  0.1262,  0.3249, -0.1567],\n",
      "         [-0.3714,  0.4598,  0.0245,  0.1345,  0.3131, -0.1424],\n",
      "         [-0.3688,  0.4479,  0.0397,  0.1397,  0.3006, -0.1303],\n",
      "         [-0.3621,  0.4373,  0.0496,  0.1415,  0.2929, -0.1213],\n",
      "         [-0.3613,  0.4321,  0.0538,  0.1373,  0.2897, -0.1185],\n",
      "         [-0.3587,  0.4262,  0.0587,  0.1362,  0.2826, -0.1155],\n",
      "         [-0.3626,  0.4228,  0.0627,  0.1316,  0.2756, -0.1168],\n",
      "         [-0.3644,  0.4173,  0.0694,  0.1319,  0.2631, -0.1170],\n",
      "         [-0.3674,  0.4121,  0.0770,  0.1338,  0.2529, -0.1194],\n",
      "         [-0.3724,  0.4099,  0.0808,  0.1320,  0.2521, -0.1248],\n",
      "         [-0.3743,  0.4070,  0.0842,  0.1315,  0.2498, -0.1281],\n",
      "         [-0.3770,  0.4038,  0.0877,  0.1298,  0.2461, -0.1317],\n",
      "         [-0.3798,  0.3970,  0.0960,  0.1322,  0.2314, -0.1349],\n",
      "         [-0.3878,  0.3883,  0.1088,  0.1359,  0.2115, -0.1431],\n",
      "         [-0.3949,  0.3911,  0.1078,  0.1335,  0.2252, -0.1521],\n",
      "         [-0.3929,  0.3807,  0.1187,  0.1401,  0.2050, -0.1546],\n",
      "         [-0.3982,  0.3840,  0.1160,  0.1369,  0.2192, -0.1618]],\n",
      "\n",
      "        [[-0.3663,  0.4274,  0.0439,  0.1573,  0.4143, -0.3325],\n",
      "         [-0.2349,  0.3073,  0.1398,  0.1812,  0.3786, -0.2512],\n",
      "         [-0.1056,  0.2505,  0.1552,  0.1798,  0.3654, -0.1657],\n",
      "         [-0.0024,  0.2186,  0.1545,  0.1713,  0.3460, -0.0789],\n",
      "         [ 0.0471,  0.2245,  0.1286,  0.1599,  0.3428, -0.0335],\n",
      "         [ 0.0641,  0.2421,  0.1012,  0.1514,  0.3505, -0.0177],\n",
      "         [ 0.0710,  0.2532,  0.0847,  0.1491,  0.3565, -0.0143],\n",
      "         [ 0.0729,  0.2589,  0.0758,  0.1493,  0.3588, -0.0152],\n",
      "         [ 0.0723,  0.2605,  0.0723,  0.1533,  0.3578, -0.0196],\n",
      "         [ 0.0784,  0.2498,  0.0782,  0.1587,  0.3459, -0.0216],\n",
      "         [ 0.0837,  0.2437,  0.0812,  0.1619,  0.3384, -0.0196],\n",
      "         [ 0.0881,  0.2376,  0.0854,  0.1654,  0.3307, -0.0188],\n",
      "         [ 0.0926,  0.2318,  0.0895,  0.1686,  0.3232, -0.0181],\n",
      "         [ 0.0961,  0.2281,  0.0920,  0.1709,  0.3178, -0.0174],\n",
      "         [ 0.0992,  0.2244,  0.0945,  0.1738,  0.3123, -0.0177],\n",
      "         [ 0.1060,  0.2170,  0.0982,  0.1798,  0.3023, -0.0188],\n",
      "         [ 0.1098,  0.2145,  0.0986,  0.1814,  0.2983, -0.0172],\n",
      "         [ 0.1118,  0.2114,  0.1004,  0.1843,  0.2934, -0.0186],\n",
      "         [ 0.1139,  0.2078,  0.1029,  0.1872,  0.2883, -0.0196],\n",
      "         [ 0.1153,  0.2047,  0.1056,  0.1903,  0.2832, -0.0211]],\n",
      "\n",
      "        [[ 0.0458,  0.1051,  0.2396,  0.1994,  0.1965, -0.0887],\n",
      "         [ 0.1330,  0.1297,  0.1845,  0.2053,  0.2261, -0.0160],\n",
      "         [ 0.1574,  0.1455,  0.1533,  0.2060,  0.2315, -0.0028],\n",
      "         [ 0.1617,  0.1557,  0.1389,  0.2083,  0.2325, -0.0054],\n",
      "         [ 0.1608,  0.1590,  0.1349,  0.2124,  0.2286, -0.0126],\n",
      "         [ 0.1594,  0.1588,  0.1354,  0.2181,  0.2223, -0.0206],\n",
      "         [ 0.1592,  0.1539,  0.1390,  0.2228,  0.2129, -0.0276],\n",
      "         [ 0.1597,  0.1489,  0.1436,  0.2274,  0.2049, -0.0324],\n",
      "         [ 0.1599,  0.1440,  0.1485,  0.2313,  0.1975, -0.0365],\n",
      "         [ 0.1616,  0.1372,  0.1538,  0.2362,  0.1882, -0.0404],\n",
      "         [ 0.1617,  0.1352,  0.1558,  0.2383,  0.1845, -0.0434],\n",
      "         [ 0.1593,  0.1357,  0.1558,  0.2373,  0.1840, -0.0467],\n",
      "         [ 0.1557,  0.1388,  0.1552,  0.2361,  0.1861, -0.0490],\n",
      "         [ 0.1549,  0.1389,  0.1560,  0.2389,  0.1841, -0.0523],\n",
      "         [ 0.1538,  0.1388,  0.1557,  0.2382,  0.1837, -0.0537],\n",
      "         [ 0.1521,  0.1405,  0.1549,  0.2374,  0.1855, -0.0545],\n",
      "         [ 0.1498,  0.1431,  0.1548,  0.2376,  0.1874, -0.0553],\n",
      "         [ 0.1488,  0.1445,  0.1541,  0.2378,  0.1885, -0.0565],\n",
      "         [ 0.1476,  0.1460,  0.1525,  0.2362,  0.1902, -0.0560],\n",
      "         [ 0.1506,  0.1429,  0.1539,  0.2381,  0.1871, -0.0547]],\n",
      "\n",
      "        [[ 0.0373,  0.1055,  0.2312,  0.2289,  0.1674, -0.1129],\n",
      "         [ 0.1607,  0.0963,  0.1980,  0.2325,  0.1752, -0.0225],\n",
      "         [ 0.1881,  0.1057,  0.1731,  0.2335,  0.1756, -0.0129],\n",
      "         [ 0.1893,  0.1120,  0.1640,  0.2370,  0.1733, -0.0223],\n",
      "         [ 0.1836,  0.1115,  0.1653,  0.2430,  0.1646, -0.0368],\n",
      "         [ 0.1770,  0.1106,  0.1680,  0.2456,  0.1596, -0.0479],\n",
      "         [ 0.1717,  0.1107,  0.1703,  0.2478,  0.1568, -0.0558],\n",
      "         [ 0.1632,  0.1157,  0.1686,  0.2470,  0.1598, -0.0624],\n",
      "         [ 0.1626,  0.1135,  0.1709,  0.2504,  0.1553, -0.0651],\n",
      "         [ 0.1590,  0.1159,  0.1699,  0.2489,  0.1578, -0.0668],\n",
      "         [ 0.1599,  0.1141,  0.1711,  0.2512,  0.1552, -0.0668],\n",
      "         [ 0.1549,  0.1199,  0.1676,  0.2481,  0.1622, -0.0666],\n",
      "         [ 0.1521,  0.1241,  0.1649,  0.2458,  0.1678, -0.0644],\n",
      "         [ 0.1496,  0.1288,  0.1616,  0.2443,  0.1733, -0.0619],\n",
      "         [ 0.1496,  0.1312,  0.1596,  0.2419,  0.1775, -0.0582],\n",
      "         [ 0.1510,  0.1320,  0.1577,  0.2424,  0.1785, -0.0570],\n",
      "         [ 0.1514,  0.1326,  0.1570,  0.2412,  0.1802, -0.0553],\n",
      "         [ 0.1504,  0.1358,  0.1555,  0.2371,  0.1857, -0.0513],\n",
      "         [ 0.1509,  0.1376,  0.1536,  0.2366,  0.1877, -0.0499],\n",
      "         [ 0.1483,  0.1423,  0.1511,  0.2330,  0.1940, -0.0472]]],\n",
      "       device='cuda:0'), (tensor([[[-5.2217e-01, -1.1236e-03, -1.2801e-02,  4.5314e-02,  1.0696e-02,\n",
      "           7.6920e-03,  1.3954e-01,  7.5384e-02],\n",
      "         [ 4.3892e-01, -7.2033e-03, -2.3726e-01, -6.5286e-02, -1.3376e-01,\n",
      "          -1.0229e-01,  1.7927e-01,  4.9708e-02],\n",
      "         [-5.1896e-01,  3.2933e-03,  3.6618e-02,  2.8058e-02, -9.3617e-02,\n",
      "           1.4323e-01,  4.9164e-01, -6.5861e-02],\n",
      "         [ 4.3159e-01,  4.0894e-04, -4.6276e-02, -5.5760e-02,  6.4458e-02,\n",
      "           1.4291e-02, -6.2669e-01,  6.7342e-02],\n",
      "         [ 4.4172e-02, -9.6873e-03, -1.7931e-01,  2.8432e-03, -1.5870e-01,\n",
      "           8.3298e-02,  5.2621e-01, -1.6443e-01],\n",
      "         [ 4.1071e-01, -2.4306e-03,  2.9700e-02,  5.3761e-02, -7.3411e-02,\n",
      "           3.3684e-02, -6.0949e-01,  4.5786e-02],\n",
      "         [-5.5558e-01,  1.8244e-03,  1.6906e-01, -5.9008e-04,  2.4987e-02,\n",
      "          -4.6794e-02,  4.3210e-01,  1.3903e-02],\n",
      "         [ 3.7426e-01,  1.6717e-03,  4.3125e-02,  3.6186e-02, -1.0372e-01,\n",
      "           1.0293e-01, -7.4226e-01, -1.8094e-02]],\n",
      "\n",
      "        [[ 3.0063e-01, -2.1729e-04, -1.4830e-02, -6.5788e-01,  4.3874e-03,\n",
      "          -1.6909e-02,  4.0584e-01, -8.7770e-03],\n",
      "         [ 1.1392e-01, -3.5901e-04, -1.0953e-03, -5.4127e-01,  1.1149e-02,\n",
      "          -3.5242e-02,  4.8017e-01, -5.6344e-02],\n",
      "         [ 3.8739e-01, -1.1109e-04, -1.5600e-02, -6.5556e-01, -3.7146e-03,\n",
      "          -5.0859e-02,  2.3491e-01,  2.2417e-02],\n",
      "         [ 1.0253e-01,  4.0264e-04,  8.4015e-02, -5.3595e-01, -1.0773e-02,\n",
      "           2.2031e-01, -3.8498e-01,  4.6772e-02],\n",
      "         [ 1.4269e-01, -3.0840e-04, -3.9566e-03, -6.4289e-01,  7.6703e-03,\n",
      "          -6.3565e-02,  4.7348e-01, -3.4137e-02],\n",
      "         [-1.4450e-01, -5.9369e-04,  1.2924e-01,  2.4726e-01, -1.1608e-02,\n",
      "          -1.0547e-01, -3.7662e-01, -1.2425e-02],\n",
      "         [-1.0781e-01, -3.3089e-04, -1.1632e-01,  1.9478e-01, -1.7184e-02,\n",
      "          -1.0187e-01, -2.6459e-01,  2.5443e-02],\n",
      "         [-1.1432e-01, -6.2426e-04,  1.2892e-01,  2.9334e-01, -1.2737e-02,\n",
      "          -1.0610e-01, -3.8267e-01, -1.0049e-02]],\n",
      "\n",
      "        [[ 1.7078e-01, -3.7921e-02, -8.7001e-02, -9.4889e-02, -5.6862e-01,\n",
      "           6.3925e-03,  4.1027e-01,  9.4136e-02],\n",
      "         [ 1.3294e-01, -1.1641e-02, -4.4392e-02, -6.6663e-02, -6.2991e-01,\n",
      "           4.6387e-03,  3.9057e-01,  1.0406e-01],\n",
      "         [-1.6559e-01, -7.0554e-02, -2.3218e-01, -1.3294e-01,  3.5105e-01,\n",
      "          -1.1598e-02, -1.7488e-01,  8.0153e-02],\n",
      "         [ 1.0182e-01,  4.7492e-02,  3.9469e-02, -1.6625e-02, -6.3354e-01,\n",
      "           3.7953e-04,  4.0383e-01, -2.1284e-02],\n",
      "         [ 6.0272e-02, -1.4368e-01, -1.4742e-01, -3.9993e-02,  3.9779e-01,\n",
      "           2.9805e-04, -3.5360e-01,  9.8486e-02],\n",
      "         [-2.0732e-01, -4.0423e-02,  5.6306e-02, -1.4748e-02, -2.9595e-01,\n",
      "          -3.4902e-02,  4.4113e-01, -8.2723e-02],\n",
      "         [-4.9601e-02, -4.3352e-02, -6.2432e-03, -4.3534e-03, -5.1146e-01,\n",
      "          -8.5033e-03,  4.3753e-01, -7.1027e-02],\n",
      "         [-8.8459e-02, -4.0524e-02,  4.9922e-02, -4.3955e-03, -4.8214e-01,\n",
      "          -2.3192e-02,  4.3794e-01, -6.9807e-02]]], device='cuda:0'), tensor([[[-2.1144e+00, -3.9284e-03, -4.1578e-02,  7.5421e-02,  1.8845e-02,\n",
      "           1.3149e-02,  1.6433e+00,  1.1641e-01],\n",
      "         [ 1.0656e+00, -1.0555e-02, -8.1226e-01, -1.1339e-01, -4.8479e-01,\n",
      "          -2.1765e-01,  1.9653e+00,  9.3539e-02],\n",
      "         [-1.9708e+00,  4.0186e-03,  8.7775e-02,  9.8506e-02, -2.6076e-01,\n",
      "           2.6518e-01,  1.5392e+00, -1.7510e-01],\n",
      "         [ 1.5980e+00,  6.9323e-04, -5.8963e-02, -8.8068e-02,  1.1541e-01,\n",
      "           6.1636e-02, -2.1320e+00,  1.9672e-01],\n",
      "         [ 9.7175e-02, -1.2258e-02, -9.0067e-01,  8.4514e-03, -2.5629e-01,\n",
      "           1.3809e-01,  2.2671e+00, -2.7336e-01],\n",
      "         [ 1.3658e+00, -3.2968e-03,  1.9855e-01,  8.7845e-02, -1.4006e-01,\n",
      "           9.4720e-02, -2.3353e+00,  6.9818e-02],\n",
      "         [-2.0751e+00,  3.5501e-03,  2.9532e-01, -1.3717e-03,  9.7392e-02,\n",
      "          -8.9750e-02,  1.6826e+00,  3.8214e-02],\n",
      "         [ 1.2702e+00,  2.1936e-03,  1.3879e-01,  8.0371e-02, -1.7104e-01,\n",
      "           2.4188e-01, -2.3249e+00, -3.2223e-02]],\n",
      "\n",
      "        [[ 7.6905e-01, -3.3661e-04, -9.8593e-02, -1.4729e+00,  7.9891e-03,\n",
      "          -4.0099e-02,  1.1594e+00, -1.7173e-02],\n",
      "         [ 1.6795e-01, -9.7107e-04, -9.5939e-03, -1.2147e+00,  2.2566e-02,\n",
      "          -7.1038e-02,  1.8186e+00, -1.1155e-01],\n",
      "         [ 1.0773e+00, -1.8978e-04, -8.7294e-02, -1.4115e+00, -6.3018e-03,\n",
      "          -9.8337e-02,  5.2174e-01,  4.4901e-02],\n",
      "         [ 4.2863e-01,  6.5274e-04,  2.6080e-01, -1.3025e+00, -2.5839e-02,\n",
      "           3.4538e-01, -1.0255e+00,  9.2975e-02],\n",
      "         [ 2.3009e-01, -7.0563e-04, -3.8305e-02, -1.2537e+00,  1.3578e-02,\n",
      "          -1.2142e-01,  1.8445e+00, -6.8556e-02],\n",
      "         [-4.1538e-01, -1.2048e-03,  1.6550e-01,  1.6261e+00, -2.8601e-02,\n",
      "          -2.0167e-01, -9.4624e-01, -2.4970e-02],\n",
      "         [-1.7487e-01, -6.6211e-04, -1.5328e-01,  1.7963e+00, -2.8164e-02,\n",
      "          -2.2492e-01, -6.0044e-01,  5.1205e-02],\n",
      "         [-3.8442e-01, -1.1477e-03,  1.6941e-01,  1.6131e+00, -3.1578e-02,\n",
      "          -2.0726e-01, -9.7236e-01, -2.0248e-02]],\n",
      "\n",
      "        [[ 2.4696e-01, -1.7208e-01, -3.4541e-01, -2.2653e-01, -1.4306e+00,\n",
      "           9.4850e-03,  1.2022e+00,  1.5235e-01],\n",
      "         [ 1.9610e-01, -4.3513e-02, -2.1215e-01, -1.8028e-01, -1.7042e+00,\n",
      "           7.4458e-03,  1.0747e+00,  1.5799e-01],\n",
      "         [-3.2858e-01, -4.7968e-01, -4.3529e-01, -1.9177e-01,  1.9190e+00,\n",
      "          -1.8955e-02, -3.5560e-01,  1.6233e-01],\n",
      "         [ 1.5224e-01,  1.3403e-01,  1.3743e-01, -4.6180e-02, -1.8176e+00,\n",
      "           5.0345e-04,  1.1873e+00, -4.6768e-02],\n",
      "         [ 1.4091e-01, -8.5326e-01, -2.9628e-01, -5.8831e-02,  1.6011e+00,\n",
      "           7.3917e-04, -8.2557e-01,  1.8131e-01],\n",
      "         [-4.0031e-01, -6.1539e-02,  1.1663e-01, -4.7155e-02, -5.3675e-01,\n",
      "          -4.9210e-02,  1.6315e+00, -1.5532e-01],\n",
      "         [-8.3223e-02, -7.7332e-02, -1.3573e-02, -1.3802e-02, -1.0932e+00,\n",
      "          -1.2443e-02,  1.5820e+00, -1.2399e-01],\n",
      "         [-1.5233e-01, -6.3871e-02,  1.1590e-01, -1.5403e-02, -1.0542e+00,\n",
      "          -3.2286e-02,  1.5652e+00, -1.3323e-01]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cuda_less_mem]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out3 = model_cuda_less_mem(inputs, hidden)\n",
    "    print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:35.075469Z",
     "start_time": "2019-02-09T06:29:35.063420Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.4017e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out3[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Backward Gradients\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:48.194093Z",
     "start_time": "2019-02-09T06:29:46.966041Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#backward-test",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7983, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True), torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True))\n",
    "\n",
    "inputs, targets = next(iter(fake_loader))\n",
    "inputs = inputs.to(device)\n",
    "inputs.requires_grad_()\n",
    "targets = targets.to(device)\n",
    "\n",
    "inputs_grads = []\n",
    "hidden_grads = []\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "    model.zero_grad()\n",
    "    loss = criterion(model(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    inputs_grads.append(inputs.grad.clone())\n",
    "    inputs.grad.zero_()\n",
    "    hidden_grads.append((hidden[0].grad.clone(), hidden[1].grad.clone()))\n",
    "    hidden[0].grad.zero_()\n",
    "    hidden[1].grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T05:56:54.541435Z",
     "start_time": "2019-02-09T05:56:54.439437Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    loss = criterion(model_cuda(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss, end='\\n\\n')\n",
    "    loss.backward()\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T03:15:29.602633Z",
     "start_time": "2019-02-09T03:15:26.112655Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    loss = criterion(model_cuda_less_mem(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss, end='\\n\\n')\n",
    "    loss.backward()\n",
    "except RuntimeError as e:\n",
    "    if \"\\n\\n\" in str(e):\n",
    "        print(\"\\n\\n\".join(str(e).split(\"\\n\\n\")[1:-1]))\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T03:35:43.053603Z",
     "start_time": "2019-02-09T03:35:42.729604Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"model_torch\")\n",
    "print(inputs_grads[0])\n",
    "print(hidden_grads[0])\n",
    "print(model_torch.lstm0.bias.grad)\n",
    "print(model_torch.lstm0.gamma_cell.grad)\n",
    "# print(model_torch.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T03:35:43.340604Z",
     "start_time": "2019-02-09T03:35:43.055604Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"model_cpp\")\n",
    "print(inputs_grads[1])\n",
    "print(hidden_grads[1])\n",
    "print(model_cpp.lstm0.bias.grad)\n",
    "print(model_cpp.lstm0.gamma_cell.grad)\n",
    "# print(model_cpp.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:29:58.583459Z",
     "start_time": "2019-02-09T06:29:58.573425Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.3940e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cpp.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T03:35:43.635604Z",
     "start_time": "2019-02-09T03:35:43.354605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"model_cuda\")\n",
    "print(inputs_grads[2])\n",
    "print(hidden_grads[2])\n",
    "print(model_cuda.lstm0.bias.grad)\n",
    "print(model_cuda.lstm0.gamma_cell.grad)\n",
    "# print(model_cuda.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:30:00.477895Z",
     "start_time": "2019-02-09T06:30:00.468892Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3450e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cuda.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T03:35:43.938607Z",
     "start_time": "2019-02-09T03:35:43.651608Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"model_cuda_less_mem\")\n",
    "print(inputs_grads[3])\n",
    "print(hidden_grads[3])\n",
    "print(model_cuda_less_mem.lstm0.bias.grad)\n",
    "print(model_cuda_less_mem.lstm0.gamma_cell.grad)\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cuda_less_mem.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:30:01.870210Z",
     "start_time": "2019-02-09T06:30:01.862213Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.3940e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cuda_less_mem.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:36:14.131005Z",
     "start_time": "2019-02-09T06:36:14.124020Z"
    },
    "tags": [
     "#forward-time-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_size = 1000 #Test 1000\n",
    "sequence_length = 20 #Test 20\n",
    "batch_size = 32 #Test 32\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "del model\n",
    "\n",
    "fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True)\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:32:09.435208Z",
     "start_time": "2019-02-09T06:30:51.239122Z"
    },
    "tags": [
     "#forward-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.91 s ± 177 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_torch(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:34:00.306832Z",
     "start_time": "2019-02-09T06:32:09.653210Z"
    },
    "scrolled": true,
    "tags": [
     "#forward-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.53 s ± 289 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cpp(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:34:28.224004Z",
     "start_time": "2019-02-09T06:34:00.307832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 s ± 51.4 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cuda(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:36:13.918002Z",
     "start_time": "2019-02-09T06:34:28.226007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.28 s ± 91.4 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cuda_less_mem(inputs, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +Backward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:36:14.146006Z",
     "start_time": "2019-02-09T06:36:14.133008Z"
    },
    "tags": [
     "=>forward-time-prep",
     "#overall-time-prep"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'executed'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\"executed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:41:15.392520Z",
     "start_time": "2019-02-09T06:36:14.323004Z"
    },
    "tags": [
     "#overall-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3 s ± 585 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_torch.zero_grad()\n",
    "    criterion(model_torch(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:44:49.722519Z",
     "start_time": "2019-02-09T06:41:15.600518Z"
    },
    "tags": [
     "#overall-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2 s ± 241 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cpp.zero_grad()\n",
    "    criterion(model_cpp(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:45:41.568505Z",
     "start_time": "2019-02-09T06:44:49.724522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.47 s ± 50.9 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cuda.zero_grad()\n",
    "    criterion(model_cuda(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:49:11.270975Z",
     "start_time": "2019-02-09T06:45:41.569506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.97 s ± 177 ms per loop (mean ± std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cuda_less_mem.zero_grad()\n",
    "    criterion(model_cuda_less_mem(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 807,
   "position": {
    "height": "548px",
    "left": "1116px",
    "right": "20px",
    "top": "99px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
