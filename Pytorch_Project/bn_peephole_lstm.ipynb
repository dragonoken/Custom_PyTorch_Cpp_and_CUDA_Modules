{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peephole LSTM Test & Performance Comparison (Speed & Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imports](#Importing-necessary-modules)\n",
    "* [Load & Definition](#Loading-and-defining-modules)\n",
    "    * [Autograd Functions](#Autograd-Functions)\n",
    "    * [Module Classes](#Module-classes-(C++,-CUDA,-PyTorch))\n",
    "* [Models](#Defining-models)\n",
    "    * [Definition](#Definition)\n",
    "    * [Instantiation](#Instantiation)\n",
    "    * [Parameter Synchronization](#Parameter-Synchronization)\n",
    "* [Fake Dataset](#Creating-a-fake-dataset)\n",
    "* [Sanity Check](#Sanity-check:-output-comparison)\n",
    "    * [Forward Outputs](#Forward-Outputs)\n",
    "    * [Backward Gradients](#Backward-Gradients)\n",
    "* [Forward Performance](#Forward-time-comparison)\n",
    "* [+Backward Performance](#+Backward-time-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.cpp_extension import load\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "from time import sleep\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and defining modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd Functions\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\0107w\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\cpp_extension.py:92: UserWarning: Error checking compiler version: Command '['c++']' returned non-zero exit status 1.\n",
      "  warnings.warn('Error checking compiler version: {}'.format(error))\n",
      "c:\\users\\0107w\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\cpp_extension.py:118: UserWarning: \n",
      "\n",
      "                               !! WARNING !!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Your compiler (c++) may be ABI-incompatible with PyTorch!\n",
      "Please use a compiler that is ABI-compatible with GCC 4.9 and above.\n",
      "See https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html.\n",
      "\n",
      "See https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6\n",
      "for instructions on how to install GCC 4.9 or higher.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "                              !! WARNING !!\n",
      "\n",
      "  warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))\n"
     ]
    }
   ],
   "source": [
    "_bn_peephole_lstm_layer_cpp = load('bn_peephole_lstm_layer', ['./bn_peephole_lstm_layer.cpp'])\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "class BNPeepholeLSTMFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias, gamma_ih, gamma_hh, gamma_ch, gamma_tanh_cell, beta_tanh_cell, running_mean_ih, running_mean_hh, running_mean_ch, running_mean_tanh_cell, running_var_ih, running_var_hh, running_var_ch, running_var_tanh_cell, old_h, old_cell, momentum, epsilon, dropout_p, training):\n",
    "        \n",
    "        outputs = _bn_peephole_lstm_layer_cpp.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                    gamma_ih, gamma_hh, gamma_ch, gamma_tanh_cell, beta_tanh_cell,\n",
    "                                                    running_mean_ih, running_mean_hh, running_mean_ch, running_mean_tanh_cell,\n",
    "                                                    running_var_ih, running_var_hh, running_var_ch, running_var_tanh_cell,\n",
    "                                                    old_h, old_cell,\n",
    "                                                    momentum, epsilon, dropout_p, training)\n",
    "        \n",
    "        (out, new_h, new_cell,\n",
    "         running_mean_ih.data, running_mean_hh.data, running_mean_ch.data, running_mean_tanh_cell.data,\n",
    "         running_var_ih.data, running_var_hh.data, running_var_ch.data, running_var_tanh_cell.data) = outputs[:11]\n",
    "        \n",
    "        variables = outputs[11:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                    gamma_ih, gamma_hh, gamma_ch, gamma_tanh_cell]\n",
    "        ctx.training = training # Boolean value stored this way since only tensors can be stored using save_for_backward\n",
    "        ctx.save_for_backward(*variables)\n",
    "\n",
    "        return out, new_h, new_cell\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "        outputs = _bn_peephole_lstm_layer_cpp.backward(\n",
    "            grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors, ctx.training)\n",
    "        \n",
    "        (d_old_h, d_old_cell, d_input,\n",
    "         d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "         d_gamma_ih, d_gamma_hh, d_gamma_ch, d_gamma_tanh_cell, d_beta_tanh_cell) = outputs\n",
    "        \n",
    "        return d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias, d_gamma_ih, d_gamma_hh, d_gamma_ch, d_gamma_tanh_cell, d_beta_tanh_cell, None, None, None, None, None, None, None, None, d_old_h, d_old_cell, None, None, None, None\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module classes (C++, CUDA, PyTorch)\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNPeepholeLSTMTorch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0., momentum=0.1, eps=1e-05):\n",
    "        if not 0 <= dropout <= 1:\n",
    "            raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "        if not 0 <= momentum <= 1:\n",
    "            raise ValueError(f\"Invalid momentum value : {momentum} momentum must be in range [0, 1].\")\n",
    "        super(BNPeepholeLSTMTorch, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = float(dropout)\n",
    "        self.momentum = float(momentum)\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "        self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "        self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size, hidden_size)))\n",
    "        self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "        \n",
    "        self.register_parameter('gamma_ih', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "        self.register_parameter('gamma_hh', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "        self.register_parameter('gamma_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "        self.register_parameter('gamma_tanh_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "        self.register_parameter('beta_tanh_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "        \n",
    "        self.register_buffer('running_mean_ih', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_mean_hh', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_mean_ch', torch.empty(3 * hidden_size))\n",
    "        self.register_buffer('running_mean_tanh_cell', torch.empty(hidden_size))\n",
    "        self.register_buffer('running_var_ih', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_var_hh', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_var_ch', torch.empty(3 * hidden_size))\n",
    "        self.register_buffer('running_var_tanh_cell', torch.empty(hidden_size))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.reset_running_stats()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "        self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "        self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "        self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "        \n",
    "        self.bias.data.zero_()\n",
    "        self.bias.data[:self.hidden_size].fill_(1.)\n",
    "        \n",
    "        self.gamma_ih.data.uniform_()\n",
    "        self.gamma_hh.data.uniform_()\n",
    "        self.gamma_ch.data.uniform_()\n",
    "        self.gamma_tanh_cell.data.uniform_()\n",
    "        self.beta_tanh_cell.data.zero_()\n",
    "    \n",
    "    def reset_running_stats(self):\n",
    "        self.running_mean_ih.data.zero_()\n",
    "        self.running_mean_hh.data.zero_()\n",
    "        self.running_mean_ch.data.zero_()\n",
    "        self.running_mean_tanh_cell.data.zero_()\n",
    "        self.running_var_ih.data.fill_(1.)\n",
    "        self.running_var_hh.data.fill_(1.)\n",
    "        self.running_var_ch.data.fill_(1.)\n",
    "        self.running_var_tanh_cell.data.fill_(1.)\n",
    "    \n",
    "    def forward(self, input, states):\n",
    "        assert input.dim() == 3\n",
    "        outputs = input.new_empty((input.size(0), input.size(1), self.hidden_size))\n",
    "        \n",
    "        h = states[0].clone()\n",
    "        c = states[1].clone()\n",
    "        \n",
    "        weight_ih = self.weight_ih.t()\n",
    "        weight_hh = self.weight_hh.t()\n",
    "        weight_ch = self.weight_ch.t()\n",
    "        \n",
    "        ih = torch.matmul(input.transpose(0, 1), weight_ih)\n",
    "        \n",
    "        for i in range(input.size(1)):\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "            \n",
    "            gates = (F.batch_norm(ih[i], self.running_mean_ih, self.running_var_ih, weight=self.gamma_ih, bias=None, training=self.training, momentum=self.momentum, eps=self.eps)\n",
    "                     + F.batch_norm(torch.mm(h, weight_hh), self.running_mean_hh, self.running_var_hh, weight=self.gamma_hh, bias=None, training=self.training, momentum=self.momentum, eps=self.eps)\n",
    "                     + self.bias)\n",
    "            \n",
    "            gates = torch.cat((gates[:, :3 * self.hidden_size].add(F.batch_norm(torch.mm(c, weight_ch), self.running_mean_ch, self.running_var_ch, weight=self.gamma_ch, bias=None, training=self.training, momentum=self.momentum, eps=self.eps)).sigmoid(), gates[:, 3 * self.hidden_size:].tanh()), dim=1).chunk(chunks=4, dim=1)\n",
    "            \n",
    "            c = torch.addcmul(gates[1] * gates[3], c, gates[0])\n",
    "            h = gates[2] * F.batch_norm(c.tanh(), self.running_mean_tanh_cell, self.running_var_tanh_cell, weight=self.gamma_tanh_cell, bias=self.beta_tanh_cell, training=self.training, momentum=self.momentum, eps=self.eps)\n",
    "            \n",
    "            outputs[:, i] = h\n",
    "        \n",
    "        outputs = torch.nn.functional.dropout(outputs, p=self.dropout, training=self.training)\n",
    "    \n",
    "        return outputs, (h, c)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"BNPeepholeLSTMTorch(input_size={self.input_size}, hidden_size={self.hidden_size}, dropout={self.dropout}, momentum={self.momentum}, eps={self.eps})\"\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "class BNPeepholeLSTMCPP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0., momentum=0.1, eps=1e-05):\n",
    "        if not 0 <= dropout <= 1:\n",
    "            raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "        if not 0 <= momentum <= 1:\n",
    "            raise ValueError(f\"Invalid momentum value : {momentum} momentum must be in range [0, 1].\")\n",
    "            \n",
    "        super(BNPeepholeLSTMCPP, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = float(dropout)\n",
    "        self.momentum = float(momentum)\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "        self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "        self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size, hidden_size)))\n",
    "        self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "        \n",
    "        self.register_parameter('gamma_ih', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "        self.register_parameter('gamma_hh', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "        self.register_parameter('gamma_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "        self.register_parameter('gamma_tanh_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "        self.register_parameter('beta_tanh_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "        \n",
    "        self.register_buffer('running_mean_ih', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_mean_hh', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_mean_ch', torch.empty(3 * hidden_size))\n",
    "        self.register_buffer('running_mean_tanh_cell', torch.empty(hidden_size))\n",
    "        self.register_buffer('running_var_ih', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_var_hh', torch.empty(4 * hidden_size))\n",
    "        self.register_buffer('running_var_ch', torch.empty(3 * hidden_size))\n",
    "        self.register_buffer('running_var_tanh_cell', torch.empty(hidden_size))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.reset_running_stats()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "        self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "        self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "        self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "        \n",
    "        self.bias.data.zero_()\n",
    "        self.bias.data[:self.hidden_size].fill_(1.)\n",
    "        \n",
    "        self.gamma_ih.data.uniform_()\n",
    "        self.gamma_hh.data.uniform_()\n",
    "        self.gamma_ch.data.uniform_()\n",
    "        self.gamma_tanh_cell.data.uniform_()\n",
    "        self.beta_tanh_cell.data.zero_()\n",
    "    \n",
    "    def reset_running_stats(self):\n",
    "        self.running_mean_ih.data.zero_()\n",
    "        self.running_mean_hh.data.zero_()\n",
    "        self.running_mean_ch.data.zero_()\n",
    "        self.running_mean_tanh_cell.data.zero_()\n",
    "        self.running_var_ih.data.fill_(1.)\n",
    "        self.running_var_hh.data.fill_(1.)\n",
    "        self.running_var_ch.data.fill_(1.)\n",
    "        self.running_var_tanh_cell.data.fill_(1.)\n",
    "        \n",
    "    def forward(self, input, state):\n",
    "        input = input.transpose(0, 1).contiguous()\n",
    "        \n",
    "        output, new_h, new_cell = BNPeepholeLSTMFunction.apply(input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias, self.gamma_ih, self.gamma_hh, self.gamma_ch, self.gamma_tanh_cell, self.beta_tanh_cell, self.running_mean_ih, self.running_mean_hh, self.running_mean_ch, self.running_mean_tanh_cell, self.running_var_ih, self.running_var_hh, self.running_var_ch, self.running_var_tanh_cell, state[0], state[1], self.momentum, self.eps, self.dropout, self.training)\n",
    "        \n",
    "        return output.transpose(0, 1).contiguous(), (new_h, new_cell)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"BNPeepholeLSTMCPP(input_size={self.input_size}, hidden_size={self.hidden_size}, dropout={self.dropout}, momentum={self.momentum}, eps={self.eps})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNPeepholeTorch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0, momentum=0.1, eps=1e-05):\n",
    "        super().__init__()\n",
    "        self.lstm0 = BNPeepholeLSTMTorch(input_size, hidden_size, dropout, momentum, eps)\n",
    "        self.lstm1 = BNPeepholeLSTMTorch(hidden_size, hidden_size, dropout, momentum, eps)\n",
    "        self.lstm2 = BNPeepholeLSTMTorch(hidden_size, hidden_size, dropout, momentum, eps)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, x, states):\n",
    "        hc1, hc2, hc3 = ((states[0][i], states[1][i]) for i in range(states[0].size(0)))\n",
    "        x, hc1 = self.lstm0(x, hc1)\n",
    "        x, hc2 = self.lstm1(x, hc2)\n",
    "        x, hc3 = self.lstm2(x, hc3)\n",
    "        x = self.fc(x)\n",
    "        new_states = (torch.cat((hc1[0], hc2[0], hc3[0])), torch.cat((hc1[1], hc2[1], hc3[1])))\n",
    "        return x, new_states\n",
    "\n",
    "########################################################################################################################\n",
    "    \n",
    "class BNPeepholeCPP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0, momentum=0.1, eps=1e-05):\n",
    "        super().__init__()\n",
    "        self.lstm0 = BNPeepholeLSTMCPP(input_size, hidden_size, dropout, momentum, eps)\n",
    "        self.lstm1 = BNPeepholeLSTMCPP(hidden_size, hidden_size, dropout, momentum, eps)\n",
    "        self.lstm2 = BNPeepholeLSTMCPP(hidden_size, hidden_size, dropout, momentum, eps)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, x, states):\n",
    "        hc1, hc2, hc3 = ((states[0][i], states[1][i]) for i in range(states[0].size(0)))\n",
    "        x, hc1 = self.lstm0(x, hc1)\n",
    "        x, hc2 = self.lstm1(x, hc2)\n",
    "        x, hc3 = self.lstm2(x, hc3)\n",
    "        x = self.fc(x)\n",
    "        new_states = (torch.cat((hc1[0], hc2[0], hc3[0])), torch.cat((hc1[1], hc2[1], hc3[1])))\n",
    "        return x, new_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cpu', 'cuda')[1]\n",
    "\n",
    "input_size = 5\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "dropout = 0.\n",
    "momentum = 0.1\n",
    "eps = 1e-05\n",
    "\n",
    "model_torch = BNPeepholeTorch(input_size, hidden_size, output_size, dropout, momentum, eps)\n",
    "model_cpp = BNPeepholeCPP(input_size, hidden_size, output_size, dropout, momentum, eps)\n",
    "\n",
    "model_torch.to(device)\n",
    "model_cpp.to(device)\n",
    "\n",
    "models = (model_torch, model_cpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Synchronization\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronized Parameters:\n",
      "\n",
      "\tlstm0.gamma_tanh_cell\n",
      "\tlstm1.weight_ih\n",
      "\tlstm1.gamma_ch\n",
      "\tlstm2.beta_tanh_cell\n",
      "\tlstm1.beta_tanh_cell\n",
      "\tfc.bias\n",
      "\tlstm0.weight_hh\n",
      "\tlstm1.bias\n",
      "\tlstm1.weight_hh\n",
      "\tlstm2.gamma_tanh_cell\n",
      "\tlstm1.gamma_hh\n",
      "\tlstm0.gamma_ch\n",
      "\tlstm2.gamma_ih\n",
      "\tlstm2.weight_ch\n",
      "\tlstm2.gamma_ch\n",
      "\tlstm1.weight_ch\n",
      "\tlstm1.gamma_ih\n",
      "\tlstm2.gamma_hh\n",
      "\tlstm2.weight_hh\n",
      "\tlstm0.beta_tanh_cell\n",
      "\tlstm0.gamma_hh\n",
      "\tlstm1.gamma_tanh_cell\n",
      "\tlstm0.weight_ch\n",
      "\tlstm0.gamma_ih\n",
      "\tlstm0.weight_ih\n",
      "\tlstm2.bias\n",
      "\tfc.weight\n",
      "\tlstm0.bias\n",
      "\tlstm2.weight_ih\n",
      "\n",
      "Exclusive Parameters (Not Synchronized):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "named_parameter_dicts = [\n",
    "    dict(model_torch.named_parameters()),\n",
    "    dict(model_cpp.named_parameters())\n",
    "]\n",
    "\n",
    "print(\"Synchronized Parameters:\\n\")\n",
    "for common_param_name in set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "    print(\"\\t{}\".format(common_param_name))\n",
    "    for i in range(1, len(named_parameter_dicts)):\n",
    "        if named_parameter_dicts[i][common_param_name].size() == named_parameter_dicts[0][common_param_name].size():\n",
    "            named_parameter_dicts[i][common_param_name].data = named_parameter_dicts[0][common_param_name].data\n",
    "        else:\n",
    "            raise RuntimeError(\"Size mismatch\\n0:{}\\n{i}:{}\".format(named_parameter_dicts[0][common_param_name].size(),\n",
    "                                                                    named_parameter_dicts[i][common_param_name].size()))\n",
    "print()\n",
    "print(\"Exclusive Parameters (Not Synchronized):\\n\")\n",
    "for exclusive_param_name in set.union(*(set(npd.keys()) for npd in named_parameter_dicts)) - set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "    print(\"\\t{}\".format(exclusive_param_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a fake dataset\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True):\n",
    "    fake_inputs = torch.randn(dataset_size, sequence_length, input_size)\n",
    "    fake_targets = torch.randint(high=output_size, size=(dataset_size, sequence_length), dtype=torch.int64)\n",
    "\n",
    "    fake_dataset = TensorDataset(fake_inputs, fake_targets)\n",
    "\n",
    "    fake_loader = DataLoader(fake_dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "    \n",
    "    return fake_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 5]) torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 1000\n",
    "sequence_length = 20\n",
    "batch_size = 32\n",
    "\n",
    "fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size)\n",
    "print(next(iter(fake_loader))[0].size(), next(iter(fake_loader))[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: output comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Outputs\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_torch]\n",
      "\n",
      "{partial output}\n",
      "tensor([[[ 0.1182, -0.1024, -0.0847,  0.4884, -0.3113, -0.1015, -0.4723],\n",
      "         [ 0.1088, -0.0691, -0.0678,  0.5072, -0.2716, -0.0872, -0.5118]],\n",
      "\n",
      "        [[ 0.7502, -0.1577, -0.0714, -0.1778,  0.1666,  0.1662,  0.2979],\n",
      "         [ 0.6923, -0.1450, -0.0882, -0.0734,  0.0916,  0.1482,  0.2066]],\n",
      "\n",
      "        [[ 0.0834, -0.0708,  0.1137,  0.5564, -0.1223, -0.2362, -0.5450],\n",
      "         [ 0.0620, -0.0354,  0.1041,  0.5649, -0.1621, -0.2186, -0.5781]],\n",
      "\n",
      "        [[ 0.1797, -0.1557,  0.1224,  0.4256, -0.1555, -0.2707, -0.2062],\n",
      "         [ 0.1927, -0.1282,  0.1652,  0.4314, -0.0964, -0.3142, -0.2469]]],\n",
      "       device='cuda:0')\n",
      "\n",
      "{partial running stat}\n",
      "tensor([-0.0036,  0.0050,  0.0042, -0.0065,  0.0267, -0.0185, -0.0233, -0.0079,\n",
      "         0.0011, -0.0031,  0.0053, -0.0020, -0.0084,  0.0053, -0.0012, -0.0055],\n",
      "       device='cuda:0')\n",
      "tensor([0.1303, 0.1333, 0.1307, 0.1311, 0.1347, 0.1334, 0.1297, 0.1307, 0.1301,\n",
      "        0.1240, 0.1294, 0.1267, 0.1269, 0.1254, 0.1344, 0.1342],\n",
      "       device='cuda:0')\n",
      "\n",
      "\n",
      "[model_cpp]\n",
      "\n",
      "{partial output}\n",
      "tensor([[[ 0.1182, -0.1024, -0.0847,  0.4884, -0.3113, -0.1015, -0.4723],\n",
      "         [ 0.1088, -0.0691, -0.0678,  0.5072, -0.2716, -0.0872, -0.5118]],\n",
      "\n",
      "        [[ 0.7502, -0.1577, -0.0714, -0.1778,  0.1666,  0.1662,  0.2979],\n",
      "         [ 0.6923, -0.1450, -0.0882, -0.0734,  0.0916,  0.1482,  0.2066]],\n",
      "\n",
      "        [[ 0.0834, -0.0708,  0.1137,  0.5564, -0.1223, -0.2362, -0.5450],\n",
      "         [ 0.0620, -0.0354,  0.1041,  0.5649, -0.1621, -0.2186, -0.5781]],\n",
      "\n",
      "        [[ 0.1797, -0.1557,  0.1224,  0.4256, -0.1555, -0.2707, -0.2062],\n",
      "         [ 0.1927, -0.1282,  0.1652,  0.4314, -0.0964, -0.3142, -0.2469]]],\n",
      "       device='cuda:0')\n",
      "\n",
      "{partial running stat}\n",
      "tensor([-0.0036,  0.0050,  0.0042, -0.0065,  0.0267, -0.0185, -0.0233, -0.0079,\n",
      "         0.0011, -0.0031,  0.0053, -0.0020, -0.0084,  0.0053, -0.0012, -0.0055],\n",
      "       device='cuda:0')\n",
      "tensor([0.1303, 0.1333, 0.1307, 0.1311, 0.1347, 0.1334, 0.1297, 0.1307, 0.1301,\n",
      "        0.1240, 0.1294, 0.1267, 0.1269, 0.1254, 0.1344, 0.1342],\n",
      "       device='cuda:0')\n",
      "\n",
      "tensor(0.0005, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "hidden = (torch.zeros(3, batch_size, hidden_size, device=device), torch.zeros(3, batch_size, hidden_size, device=device))\n",
    "\n",
    "inputs = next(iter(fake_loader))[0].to(device)\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"[model_torch]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out0 = model_torch(inputs, hidden)[0]\n",
    "    print(out0[:4, -2:, :7])\n",
    "    print(\"\\n{partial running stat}\")\n",
    "    print(model_torch.lstm0.running_mean_hh[:16])\n",
    "    print(model_torch.lstm0.running_var_hh[:16])\n",
    "    print(\"\\n\")\n",
    "    print(\"[model_cpp]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out1 = model_cpp(inputs, hidden)[0]\n",
    "    print(out1[:4, -2:, :7])\n",
    "    print(\"\\n{partial running stat}\")\n",
    "    print(model_cpp.lstm0.running_mean_hh[:16])\n",
    "    print(model_cpp.lstm0.running_var_hh[:16])\n",
    "    print()\n",
    "    print(out0.sub(out1).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Gradients\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "model_torch\n",
      "tensor([ 0.0019,  0.0054,  0.0018,  0.0015,  0.0043, -0.0001,  0.0013],\n",
      "       device='cuda:0')\n",
      "tensor([-2.6875e-04,  1.9579e-04, -1.4493e-04, -4.1025e-04,  4.9610e-04,\n",
      "        -5.6956e-05, -2.5199e-04,  5.6146e-04,  4.4483e-04,  4.4219e-04,\n",
      "         1.1264e-04,  3.3381e-04,  2.7544e-04, -3.4873e-04,  8.1574e-04,\n",
      "        -7.7577e-05, -9.7136e-04,  1.4679e-04,  1.6942e-04,  8.2287e-06,\n",
      "        -5.0800e-04,  4.3449e-05, -3.0350e-04, -5.9347e-05, -2.0256e-04],\n",
      "       device='cuda:0')\n",
      "\n",
      "\n",
      "model_cpp\n",
      "tensor([ 0.0019,  0.0054,  0.0018,  0.0015,  0.0043, -0.0001,  0.0013],\n",
      "       device='cuda:0')\n",
      "tensor([-2.6875e-04,  1.9579e-04, -1.4493e-04, -4.1025e-04,  4.9610e-04,\n",
      "        -5.6956e-05, -2.5199e-04,  5.6146e-04,  4.4483e-04,  4.4219e-04,\n",
      "         1.1264e-04,  3.3381e-04,  2.7544e-04, -3.4873e-04,  8.1574e-04,\n",
      "        -7.7577e-05, -9.7136e-04,  1.4679e-04,  1.6942e-04,  8.2287e-06,\n",
      "        -5.0800e-04,  4.3449e-05, -3.0350e-04, -5.9347e-05, -2.0256e-04],\n",
      "       device='cuda:0')\n",
      "\n",
      "\n",
      "tensor(3.2147e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "hidden = (torch.zeros(3, batch_size, hidden_size, device=device), torch.zeros(3, batch_size, hidden_size, device=device))\n",
    "\n",
    "inputs, targets = next(iter(fake_loader))\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "    model.zero_grad()\n",
    "    loss = criterion(model(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "print()\n",
    "print(\"model_torch\")\n",
    "# print(model_torch.lstm2.weight_ih.grad[:4, :7])\n",
    "print(model_torch.lstm2.beta_tanh_cell.grad[:7])\n",
    "print(model_torch.lstm2.bias.grad[:25])\n",
    "print(\"\\n\")\n",
    "print(\"model_cpp\")\n",
    "# print(model_cpp.lstm2.weight_ih.grad[:4, :7])\n",
    "print(model_cpp.lstm2.beta_tanh_cell.grad[:7])\n",
    "print(model_torch.lstm2.bias.grad[:25])\n",
    "print(\"\\n\")\n",
    "print(model_torch.lstm2.weight_ih.grad.sub(model_cpp.lstm2.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 1000\n",
    "sequence_length = 20\n",
    "batch_size = 32\n",
    "\n",
    "model_torch.train()\n",
    "model_cpp.train()\n",
    "\n",
    "fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True)\n",
    "\n",
    "hidden = (torch.zeros(3, batch_size, hidden_size, device=device), torch.zeros(3, batch_size, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12 s ± 117 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_torch(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.84 s ± 186 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cpp(inputs, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +Backward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.08 s ± 119 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_torch.zero_grad()\n",
    "    criterion(model_torch(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.9 s ± 185 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cpp.zero_grad()\n",
    "    criterion(model_cpp(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
