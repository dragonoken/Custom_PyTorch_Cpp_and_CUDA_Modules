{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peephole LSTM Test & Performance Comparison (Speed & Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imports](#Importing-necessary-modules)\n",
    "* [Load & Definition](#Loading-and-defining-modules)\n",
    "    * [Autograd Functions](#Autograd-Functions)\n",
    "    * [Module Classes](#Module-classes-(C++,-CUDA,-PyTorch))\n",
    "* [Models](#Defining-models)\n",
    "    * [Definition](#Definition)\n",
    "    * [Instantiation](#Instantiation)\n",
    "    * [Parameter Synchronization](#Parameter-Synchronization)\n",
    "* [Fake Dataset](#Creating-a-fake-dataset)\n",
    "* [Sanity Check](#Sanity-check:-output-comparison)\n",
    "* [Forward Performance](#Forward-time-comparison)\n",
    "* [+Backward Performance](#+Backward-time-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.cpp_extension import load\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "from time import sleep\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and defining modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\0107w\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\cpp_extension.py:92: UserWarning: Error checking compiler version: Command '['c++']' returned non-zero exit status 1.\n",
      "  warnings.warn('Error checking compiler version: {}'.format(error))\n",
      "c:\\users\\0107w\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\cpp_extension.py:118: UserWarning: \n",
      "\n",
      "                               !! WARNING !!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Your compiler (c++) may be ABI-incompatible with PyTorch!\n",
      "Please use a compiler that is ABI-compatible with GCC 4.9 and above.\n",
      "See https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html.\n",
      "\n",
      "See https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6\n",
      "for instructions on how to install GCC 4.9 or higher.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "                              !! WARNING !!\n",
      "\n",
      "  warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))\n"
     ]
    }
   ],
   "source": [
    "_peephole_lstm_cell = load('peephole_lstm_cell', ['./peephole_lstm_cell.cpp'])\n",
    "_peephole_lstm_cpp = load('peephole_lstm', ['./peephole_lstm.cpp'])\n",
    "_peephole_lstm_cuda = load('peephole_lstm_cuda', ['./peephole_lstm_cuda.cpp', './peephole_lstm_cuda_kernal.cu'])\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "class PeepholeLSTMCellFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias, old_h, old_cell):\n",
    "        outputs = _peephole_lstm_cell.forward(input, weight_ih, weight_hh, weight_ch, bias, old_h, old_cell)\n",
    "        new_h, new_cell = outputs[:2]\n",
    "        variables = [old_cell] + outputs[2:] + [weight_ih, weight_hh, weight_ch]\n",
    "        ctx.save_for_backward(*variables)\n",
    "\n",
    "        return new_h, new_cell\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_h, grad_cell):\n",
    "        outputs = _peephole_lstm_cell.backward(\n",
    "            grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_variables)\n",
    "        d_old_h, d_old_cell, d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias = outputs\n",
    "        return d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias, d_old_h, d_old_cell\n",
    "    \n",
    "########################################################################################################################\n",
    "    \n",
    "class PeepholeLSTMFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias, old_h, old_cell, dropout_p, training):\n",
    "        outputs = _peephole_lstm_cpp.forward(input, weight_ih, weight_hh, weight_ch, bias, old_h, old_cell, dropout_p, training)\n",
    "        out, new_h, new_cell = outputs[:3]\n",
    "        variables = outputs[3:] + [weight_ih, weight_hh, weight_ch]\n",
    "        ctx.save_for_backward(*variables)\n",
    "\n",
    "        return out, new_h, new_cell\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "        outputs = _peephole_lstm_cpp.backward(\n",
    "            grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_variables)\n",
    "        d_old_h, d_old_cell, d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias = outputs\n",
    "        return d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias, d_old_h, d_old_cell, None, None\n",
    "    \n",
    "########################################################################################################################\n",
    "    \n",
    "class PeepholeLSTMCUDAFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias, old_h, old_cell, dropout_p, training):\n",
    "        outputs = _peephole_lstm_cuda.forward(input, weight_ih, weight_hh, weight_ch, bias, old_h, old_cell, dropout_p, training)\n",
    "        out, new_h, new_cell = outputs[:3]\n",
    "        variables = outputs[3:] + [weight_ih, weight_hh, weight_ch]\n",
    "        ctx.save_for_backward(*variables)\n",
    "\n",
    "        return out, new_h, new_cell\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "        outputs = _peephole_lstm_cuda.backward(\n",
    "            grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_variables)\n",
    "        d_old_h, d_old_cell, d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias = outputs\n",
    "        return d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias, d_old_h, d_old_cell, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module classes (C++, CUDA, PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeepholeLSTMCellTorch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PeepholeLSTMCellTorch, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_ih = torch.nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
    "        self.weight_hh = torch.nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
    "        self.weight_ch = torch.nn.Parameter(torch.empty(3 * hidden_size, hidden_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(4 * hidden_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "        for param in self.parameters():\n",
    "            param.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, states):\n",
    "        gates = torch.addmm(self.bias, input, self.weight_ih.t())\n",
    "        gates = gates + torch.mm(states[0], self.weight_hh.t())\n",
    "        gates[:, :3 * self.hidden_size] = gates[:, :3 * self.hidden_size] + torch.mm(states[1], self.weight_ch.t())\n",
    "        gates = torch.cat((gates[:, :3*self.hidden_size].sigmoid(), gates[:, 3*self.hidden_size:].tanh()), dim=1).chunk(4, dim=1)\n",
    "    \n",
    "        new_cell = ( states[1] * gates[0] ) + ( gates[1] * gates[3] )\n",
    "        new_hidden = gates[2] * new_cell.tanh()\n",
    "    \n",
    "        return new_hidden, new_cell\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"PeepholeLSTMCellTorch(input_size={self.input_size}, hidden_size={self.hidden_size})\"\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "class PeepholeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PeepholeLSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_ih = torch.nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
    "        self.weight_hh = torch.nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
    "        self.weight_ch = torch.nn.Parameter(torch.empty(3 * hidden_size, hidden_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(4 * hidden_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, states):\n",
    "        return PeepholeLSTMCellFunction.apply(input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias, *states)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"PeepholeLSTMCell(input_size={self.input_size}, hidden_size={self.hidden_size})\"\n",
    "\n",
    "########################################################################################################################\n",
    "    \n",
    "class PeepholeLSTMTorch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.):\n",
    "        if not 0 <= dropout <= 1:\n",
    "            raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "        super(PeepholeLSTMTorch, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.weight_ih = torch.nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
    "        self.weight_hh = torch.nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
    "        self.weight_ch = torch.nn.Parameter(torch.empty(3 * hidden_size, hidden_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(4 * hidden_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "        for param in self.parameters():\n",
    "            param.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, states):\n",
    "        assert input.dim() == 3\n",
    "        outputs = input.new_empty((input.size(0), input.size(1), self.hidden_size))\n",
    "        \n",
    "        h = states[0].clone()\n",
    "        c = states[1].clone()\n",
    "        \n",
    "        weight_ih = self.weight_ih.t()\n",
    "        weight_hh = self.weight_hh.t()\n",
    "        weight_ch = self.weight_ch.t()\n",
    "        \n",
    "        ih = torch.matmul(input.transpose(0, 1), weight_ih)\n",
    "        \n",
    "        for i in range(input.size(1)):\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "            \n",
    "            gates = ih[i] + torch.addmm(self.bias, h, weight_hh)\n",
    "            gates[:, :3 * self.hidden_size] += torch.mm(c, weight_ch)\n",
    "            \n",
    "            gates = torch.cat((gates[:, :3 * self.hidden_size].sigmoid(), gates[:, 3 * self.hidden_size:].tanh()), dim=1).chunk(chunks=4, dim=1)\n",
    "            \n",
    "            c = torch.addcmul(gates[1] * gates[3], c, gates[0])\n",
    "            h = gates[2] * c.tanh()\n",
    "            \n",
    "            outputs[:, i] = h\n",
    "        \n",
    "        outputs = F.dropout(outputs, p=self.dropout, training=self.training)\n",
    "    \n",
    "        return outputs, (h, c)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"PeepholeLSTMTorch(input_size={self.input_size}, hidden_size={self.hidden_size}, dropout={self.dropout})\"\n",
    "    \n",
    "########################################################################################################################\n",
    "    \n",
    "class PeepholeLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.):\n",
    "        if not 0 <= dropout <= 1:\n",
    "            raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "        super(PeepholeLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = float(dropout)\n",
    "        self.weight_ih = torch.nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
    "        self.weight_hh = torch.nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
    "        self.weight_ch = torch.nn.Parameter(torch.empty(3 * hidden_size, hidden_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(4 * hidden_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, states):\n",
    "        dropout = self.dropout if self.training else 0.\n",
    "        input = input.transpose(0, 1).contiguous()\n",
    "        output, new_h, new_cell = PeepholeLSTMFunction.apply(input, self.weight_ih, self.weight_hh, self.weight_ch,\n",
    "                                                             self.bias, *states, dropout, self.training)\n",
    "        return output.transpose(0, 1).contiguous(), (new_h, new_cell)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"PeepholeLSTM(input_size={self.input_size}, hidden_size={self.hidden_size}, dropout={self.dropout})\"\n",
    "    \n",
    "########################################################################################################################\n",
    "    \n",
    "class PeepholeLSTMCUDA(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.):\n",
    "        if not 0 <= dropout <= 1:\n",
    "            raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "        super(PeepholeLSTMCUDA, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = float(dropout)\n",
    "        self.weight_ih = torch.nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
    "        self.weight_hh = torch.nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
    "        self.weight_ch = torch.nn.Parameter(torch.empty(3 * hidden_size, hidden_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(4 * hidden_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, states):\n",
    "        dropout = self.dropout if self.training else 0.\n",
    "        input = input.transpose(0, 1).contiguous()\n",
    "        output, new_h, new_cell = PeepholeLSTMCUDAFunction.apply(input, self.weight_ih, self.weight_hh, self.weight_ch,\n",
    "                                                                 self.bias, *states, dropout, self.training)\n",
    "        return output.transpose(0, 1).contiguous(), (new_h, new_cell)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"PeepholeLSTMCUDA(input_size={self.input_size}, hidden_size={self.hidden_size}, dropout={self.dropout})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeepholeTorch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm0 = PeepholeLSTMCellTorch(input_size, hidden_size)\n",
    "        self.lstm1 = PeepholeLSTMCellTorch(hidden_size, hidden_size)\n",
    "        self.lstm2 = PeepholeLSTMCellTorch(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, x, states):\n",
    "        output = x.new_empty(x.size(0), x.size(1), self.output_size)\n",
    "        hc1, hc2, hc3 = ((states[0][i], states[1][i]) for i in range(states[0].size(0)))\n",
    "        for i, seq_batch in enumerate(x.transpose(0, 1)):\n",
    "            hc1 = self.lstm0(seq_batch, hc1)\n",
    "            hc2 = self.lstm1(F.dropout(hc1[0], p=0, training=self.training), hc2)\n",
    "            hc3 = self.lstm2(F.dropout(hc2[0], p=0, training=self.training), hc3)\n",
    "            output[:, i, :] = self.fc(F.dropout(hc3[0], p=0, training=self.training))\n",
    "        new_states = (torch.cat((hc1[0], hc2[0], hc3[0])), torch.cat((hc1[1], hc2[1], hc3[1])))\n",
    "        return output, new_states\n",
    "\n",
    "########################################################################################################################\n",
    "    \n",
    "class PeepholeCPP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm0 = PeepholeLSTMCell(input_size, hidden_size)\n",
    "        self.lstm1 = PeepholeLSTMCell(hidden_size, hidden_size)\n",
    "        self.lstm2 = PeepholeLSTMCell(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, x, states):\n",
    "        output = x.new_empty(x.size(0), x.size(1), self.output_size)\n",
    "        hc1, hc2, hc3 = ((states[0][i], states[1][i]) for i in range(states[0].size(0)))\n",
    "        for i, seq_batch in enumerate(x.transpose(0, 1)):\n",
    "            hc1 = self.lstm0(seq_batch, hc1)\n",
    "            hc2 = self.lstm1(F.dropout(hc1[0], p=0, training=self.training), hc2)\n",
    "            hc3 = self.lstm2(F.dropout(hc2[0], p=0, training=self.training), hc3)\n",
    "            output[:, i, :] = self.fc(F.dropout(hc3[0], p=0, training=self.training))\n",
    "        new_states = (torch.cat((hc1[0], hc2[0], hc3[0])), torch.cat((hc1[1], hc2[1], hc3[1])))\n",
    "        return output, new_states\n",
    "    \n",
    "########################################################################################################################\n",
    "\n",
    "class PeepholeLoopTorch(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm0 = PeepholeLSTMTorch(input_size, hidden_size, dropout)\n",
    "        self.lstm1 = PeepholeLSTMTorch(hidden_size, hidden_size, dropout)\n",
    "        self.lstm2 = PeepholeLSTMTorch(hidden_size, hidden_size, dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, states):\n",
    "        hc1, hc2, hc3 = ((states[0][i], states[1][i]) for i in range(states[0].size(0)))\n",
    "        x, hc1 = self.lstm0(x, hc1)\n",
    "        print(x)\n",
    "        x, hc2 = self.lstm1(x, hc2)\n",
    "        print(x)\n",
    "        x, hc3 = self.lstm2(x, hc3)\n",
    "        print(x)\n",
    "        x = self.fc(x)\n",
    "        new_states = (torch.cat((hc1[0], hc2[0], hc3[0])), torch.cat((hc1[1], hc2[1], hc3[1])))\n",
    "        return x, new_states\n",
    "    \n",
    "########################################################################################################################\n",
    "\n",
    "class PeepholeLoopCPP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm0 = PeepholeLSTM(input_size, hidden_size, dropout)\n",
    "        self.lstm1 = PeepholeLSTM(hidden_size, hidden_size, dropout)\n",
    "        self.lstm2 = PeepholeLSTM(hidden_size, hidden_size, dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, states):\n",
    "        hc1, hc2, hc3 = ((states[0][i], states[1][i]) for i in range(states[0].size(0)))\n",
    "        x, hc1 = self.lstm0(x, hc1)\n",
    "        print(x)\n",
    "        x, hc2 = self.lstm1(x, hc2)\n",
    "        print(x)\n",
    "        x, hc3 = self.lstm2(x, hc3)\n",
    "        print(x)\n",
    "        x = self.fc(x)\n",
    "        new_states = (torch.cat((hc1[0], hc2[0], hc3[0])), torch.cat((hc1[1], hc2[1], hc3[1])))\n",
    "        return x, new_states\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "class PeepholeLoopCUDA(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm0 = PeepholeLSTMCUDA(input_size, hidden_size, dropout)\n",
    "        self.lstm1 = PeepholeLSTMCUDA(hidden_size, hidden_size, dropout)\n",
    "        self.lstm2 = PeepholeLSTMCUDA(hidden_size, hidden_size, dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, states):\n",
    "        hc1, hc2, hc3 = ((states[0][i], states[1][i]) for i in range(states[0].size(0)))\n",
    "        x, hc1 = self.lstm0(x, hc1)\n",
    "        x, hc2 = self.lstm1(x, hc2)\n",
    "        x, hc3 = self.lstm2(x, hc3)\n",
    "        x = self.fc(x)\n",
    "        new_states = (torch.cat((hc1[0], hc2[0], hc3[0])), torch.cat((hc1[1], hc2[1], hc3[1])))\n",
    "        return x, new_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cpu', 'cuda')[1]\n",
    "\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2\n",
    "dropout = 0.\n",
    "\n",
    "model_cell_torch = PeepholeTorch(input_size, hidden_size, output_size)\n",
    "model_cell_cpp = PeepholeCPP(input_size, hidden_size, output_size)\n",
    "\n",
    "model_loop_torch = PeepholeLoopTorch(input_size, hidden_size, output_size, dropout)\n",
    "model_loop_cpp = PeepholeLoopCPP(input_size, hidden_size, output_size, dropout)\n",
    "model_loop_cuda = PeepholeLoopCUDA(input_size, hidden_size, output_size, dropout)\n",
    "\n",
    "model_cell_torch.to(device)\n",
    "model_cell_cpp.to(device)\n",
    "model_loop_torch.to(device)\n",
    "model_loop_cpp.to(device)\n",
    "model_loop_cuda.to(device)\n",
    "\n",
    "models = (model_cell_torch, model_cell_cpp, model_loop_torch, model_loop_cpp, model_loop_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronized Parameters:\n",
      "\n",
      "\tlstm2.bias\n",
      "\tlstm1.weight_ih\n",
      "\tlstm0.weight_hh\n",
      "\tfc.bias\n",
      "\tlstm0.bias\n",
      "\tlstm2.weight_ch\n",
      "\tlstm1.weight_ch\n",
      "\tlstm2.weight_hh\n",
      "\tfc.weight\n",
      "\tlstm0.weight_ch\n",
      "\tlstm2.weight_ih\n",
      "\tlstm1.bias\n",
      "\tlstm1.weight_hh\n",
      "\tlstm0.weight_ih\n",
      "\n",
      "Exclusive Parameters (Not Synchronized):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "named_parameter_dicts = [\n",
    "    dict(model_cell_torch.named_parameters()),\n",
    "    dict(model_cell_cpp.named_parameters()),\n",
    "    dict(model_loop_torch.named_parameters()),\n",
    "    dict(model_loop_cpp.named_parameters()),\n",
    "    dict(model_loop_cuda.named_parameters()),\n",
    "]\n",
    "\n",
    "print(\"Synchronized Parameters:\\n\")\n",
    "for common_param_name in set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "    print(\"\\t{}\".format(common_param_name))\n",
    "    for i in range(1, len(named_parameter_dicts)):\n",
    "        if named_parameter_dicts[i][common_param_name].size() == named_parameter_dicts[0][common_param_name].size():\n",
    "            named_parameter_dicts[i][common_param_name].data = named_parameter_dicts[0][common_param_name].data\n",
    "        else:\n",
    "            raise RuntimeError(\"Size mismatch\\n0:{}\\n{i}:{}\".format(named_parameter_dicts[0][common_param_name].size(),\n",
    "                                                                    named_parameter_dicts[i][common_param_name].size()))\n",
    "print()\n",
    "print(\"Exclusive Parameters (Not Synchronized):\\n\")\n",
    "for exclusive_param_name in set.union(*(set(npd.keys()) for npd in named_parameter_dicts)) - set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "    print(\"\\t{}\".format(exclusive_param_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a fake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 1000\n",
    "sequence_length = 2\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "fake_inputs = torch.randn(dataset_size, sequence_length, input_size)\n",
    "fake_targets = torch.randint(high=output_size, size=(dataset_size, sequence_length), dtype=torch.int64)\n",
    "\n",
    "fake_dataset = TensorDataset(fake_inputs, fake_targets)\n",
    "\n",
    "fake_loader = DataLoader(fake_dataset, batch_size=batch_size)\n",
    "\n",
    "print(next(iter(fake_loader))[0].size(), next(iter(fake_loader))[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: output comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_loop_torch\n",
      "tensor([[[ 0.0227,  0.0768, -0.1173, -0.0336, -0.0224],\n",
      "         [-0.0090,  0.0725, -0.1446, -0.0626, -0.0410]],\n",
      "\n",
      "        [[ 0.0840, -0.0619, -0.0597,  0.1108, -0.0773],\n",
      "         [ 0.0905,  0.0711, -0.1619,  0.0355, -0.1084]]], device='cuda:0')\n",
      "tensor([[[ 0.0283,  0.0022,  0.0476,  0.0344, -0.0383],\n",
      "         [ 0.0462, -0.0004,  0.0721,  0.0518, -0.0589]],\n",
      "\n",
      "        [[ 0.0101,  0.0005,  0.0478,  0.0239, -0.0297],\n",
      "         [ 0.0233, -0.0092,  0.0814,  0.0407, -0.0466]]], device='cuda:0')\n",
      "tensor([[[-0.0061, -0.0423, -0.0019,  0.0481, -0.0220],\n",
      "         [-0.0140, -0.0626, -0.0015,  0.0762, -0.0364]],\n",
      "\n",
      "        [[-0.0064, -0.0419, -0.0012,  0.0490, -0.0224],\n",
      "         [-0.0150, -0.0619, -0.0001,  0.0780, -0.0369]]], device='cuda:0')\n",
      "tensor([[[ 0.4308, -0.1655],\n",
      "         [ 0.4319, -0.1565]],\n",
      "\n",
      "        [[ 0.4309, -0.1655],\n",
      "         [ 0.4321, -0.1563]]], device='cuda:0')\n",
      "\n",
      "\n",
      "model_loop_cpp\n",
      "tensor([[[ 0.0355,  0.1086, -0.1633, -0.0517, -0.0333],\n",
      "         [-0.0180,  0.0554, -0.1177, -0.0634, -0.0416]],\n",
      "\n",
      "        [[ 0.1237, -0.0858, -0.0902,  0.1641, -0.1211],\n",
      "         [ 0.0834,  0.1212, -0.1878, -0.0395, -0.1152]]], device='cuda:0')\n",
      "tensor([[[ 0.0421,  0.0000,  0.0735,  0.0553, -0.0564],\n",
      "         [ 0.0517, -0.0033,  0.0733,  0.0485, -0.0604]],\n",
      "\n",
      "        [[ 0.0020, -0.0061,  0.0755,  0.0327, -0.0377],\n",
      "         [ 0.0353, -0.0148,  0.0886,  0.0487, -0.0486]]], device='cuda:0')\n",
      "tensor([[[-0.0101, -0.0601, -0.0022,  0.0735, -0.0318],\n",
      "         [-0.0193, -0.0655, -0.0005,  0.0785, -0.0408]],\n",
      "\n",
      "        [[-0.0113, -0.0586,  0.0000,  0.0763, -0.0329],\n",
      "         [-0.0212, -0.0651,  0.0009,  0.0812, -0.0415]]], device='cuda:0')\n",
      "tensor([[[ 0.4318, -0.1567],\n",
      "         [ 0.4323, -0.1562]],\n",
      "\n",
      "        [[ 0.4320, -0.1565],\n",
      "         [ 0.4330, -0.1557]]], device='cuda:0')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden = (torch.zeros(3, batch_size, hidden_size, device=device), torch.zeros(3, batch_size, hidden_size, device=device))\n",
    "\n",
    "inputs, targets = next(iter(fake_loader))\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Output or Hidden\n",
    "i = {\"output\": 0, \"hidden\": 1}[\"output\"]\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "#     print(\"model_cell_torch\")\n",
    "#     print(model_cell_torch(inputs, hidden)[i])\n",
    "#     print(\"\\n\")\n",
    "#     print(\"model_cell_cpp\")\n",
    "#     print(model_cell_cpp(inputs, hidden)[i])\n",
    "#     print(\"\\n\")\n",
    "    print(\"model_loop_torch\")\n",
    "    print(model_loop_torch(inputs, hidden)[i])\n",
    "    print(\"\\n\")\n",
    "    print(\"model_loop_cpp\")\n",
    "    print(model_loop_cpp(inputs, hidden)[i])\n",
    "    print(\"\\n\")\n",
    "#     print(\"model_loop_cuda\")\n",
    "#     print(model_loop_cuda(inputs, hidden)[i])\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +Backward time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
